<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>yanliang&#39;s blog</title>
  
  
  <link href="https://gyl-coder.top/atom.xml" rel="self"/>
  
  <link href="https://gyl-coder.top/"/>
  <updated>2020-09-28T14:44:42.605Z</updated>
  <id>https://gyl-coder.top/</id>
  
  <author>
    <name>yanliang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>接口 vs 抽象类的区别？</title>
    <link href="https://gyl-coder.top/java/abstract_interface/"/>
    <id>https://gyl-coder.top/java/abstract_interface/</id>
    <published>2020-09-26T16:00:00.000Z</published>
    <updated>2020-09-28T14:44:42.605Z</updated>
    
    <content type="html"><![CDATA[<p>在面向对象编程中，抽象类和接口是两个经常被用到的语法概念，是面向对象四大特性，以及很多设计模式、设计思想、设计原则编程实现的基础。</p><p>比如：我们可以使用接口来实现面向对象的抽象特性、多态特性和基于接口而非实现的设计原则，使用抽象类来实现面向对象的继承特性和模板设计模式等。</p><a id="more"></a><h2 id="什么是抽象类和接口？-区别点在哪里？"><a class="header-anchor" href="#什么是抽象类和接口？-区别点在哪里？">¶</a>什么是抽象类和接口？ 区别点在哪里？</h2><p>马上更新…</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在面向对象编程中，抽象类和接口是两个经常被用到的语法概念，是面向对象四大特性，以及很多设计模式、设计思想、设计原则编程实现的基础。&lt;/p&gt;
&lt;p&gt;比如：我们可以使用接口来实现面向对象的抽象特性、多态特性和基于接口而非实现的设计原则，使用抽象类来实现面向对象的继承特性和模板设计模式等。&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="接口" scheme="https://gyl-coder.top/tags/%E6%8E%A5%E5%8F%A3/"/>
    
    <category term="抽象" scheme="https://gyl-coder.top/tags/%E6%8A%BD%E8%B1%A1/"/>
    
  </entry>
  
  <entry>
    <title>Java 集合总结</title>
    <link href="https://gyl-coder.top/java/collection/all/"/>
    <id>https://gyl-coder.top/java/collection/all/</id>
    <published>2020-07-05T16:00:00.000Z</published>
    <updated>2020-09-28T14:56:10.804Z</updated>
    
    <content type="html"><![CDATA[<p>集合中用到的数据结构有以下几种：</p><ul><li>**数组：**最常用的数据结构之一。数组的特点是长度固定，可以用下标索引，并且所有的元素的类型都是一致的。使用时尽量把数组封装在一个类里，防止数据被错误的操作弄乱。</li><li>**链表：**是一种由多个节点组成的数据结构，并且每个节点包含有数据以及指向下一个节点的引用，在双向链表里，还会有一个指向前一个节点的引用。例如，可以用单向链表和双向链表来实现堆栈和队列，因为链表的两端都是可以进行插入和删除的动作的。当然，也会有在链表的中间频繁插入和删除节点的场景。</li><li>**树：**是一种由节点组成的数据结构，每个节点都包含数据元素，并且有一个或多个子节点，每个子节点指向一个父节点可以表示层级关系或者数据元素的顺序关系。如果树的每个子节点最多有两个叶子节点，那么这种树被称为二叉树。二叉树是一种非常常用的树形结构， 因为它的这种结构使得节点的插入和删除都非常高效。树的边表示从一个节点到另外一个节点的快捷路径。</li><li>**堆栈：**只允许对最后插入的元素进行操作（也就是后进先出，Last In First Out – LIFO）。如果你移除了栈顶的元素，那么你可以操作倒数第二个元素，依次类推。这种后进先出的方式是通过仅有的peek(),push()和pop()这几个方法的强制性限制达到的。这种结构在很多场景下都非常实用，例如解析像(4+2)*3这样的数学表达式，把源码中的方法和异常按照他们出现的顺序放到堆栈中，检查你的代码看看小括号和花括号是不是匹配的，等等。</li><li>**队列：**和堆栈有些相似，不同之处在于在队列里第一个插入的元素也是第一个被删除的元素（即是先进先出）。这种先进先出的结构是通过只提供peek()，offer()和poll()这几个方法来访问数据进行限制来达到的。例如，排队等待公交车，银行或者超市里的等待列队等等，都是可以用队列来表示。</li></ul><a id="more"></a><h2 id="概览"><a class="header-anchor" href="#概览">¶</a>概览</h2><p>Java 容器主要包括 Collection 和 Map 两种，Collection存储着对象的集合，而Map存储着键值对（两个对象）的映射表。</p><h3 id="Collection"><a class="header-anchor" href="#Collection">¶</a>Collection</h3><div class="gallery ">              <p><img src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/collection1.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/collection1.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg" alt="image.png"></p>            </div><p><strong>Set</strong></p><ul><li><p>TreeSet（有序，唯一）：基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。</p></li><li><p>HashSet（无序，唯一）：基于Hashmap实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。</p></li><li><p>LinkedHashSet：<code>LinkedHashSet</code> 是 <code>HashSet</code> 的子类，并且其内部是通过 <code>LinkedHashMap</code> 来实现的。具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。</p></li></ul><p>List</p><ul><li>ArrayList：基于动态数组 Object[] 实现，支持随机访问。</li><li>Vector：和 ArrayList 类似，但它是线程安全的。</li><li>LinkedList：基于双向链表实现 (JDK1.6 之前为循环链表，JDK1.7 取消了循环)，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。</li></ul><p>Queue</p><ul><li>LinkedList：可以用它来实现双向队列。</li><li>PriorityQueue：基于堆结构实现，可以用它来实现优先队列。</li></ul><h3 id="Map"><a class="header-anchor" href="#Map">¶</a>Map</h3><div class="gallery ">              <p><img src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/collection3.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/collection3.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg" alt="image.png"></p>            </div><ul><li>**TreeMap：**基于红黑树实现。（自平衡的排序二叉树）</li><li>**HashMap：**JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间</li><li>**HashTable：**和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程同时写入 HashTable 不会导致数据不一致。它是遗留类，不应该去使用它，而是使用 ConcurrentHashMap 来支持线程安全，ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。</li><li>**LinkedHashMap：**LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。</li></ul><h3 id="迭代器-Iterator"><a class="header-anchor" href="#迭代器-Iterator">¶</a>迭代器 Iterator</h3><div class="gallery ">              <p><img src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/collection4.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/collection4.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg" alt="image.png"></p>            </div><p>Collection 继承了 Iterable 接口，其中的 iterator() 方法能够产生一个 Iterator 对象，通过这个对象就可以迭代遍历 Collection 中的元素。<br>从 JDK 1.5 之后可以使用 foreach 方法来遍历实现了 Iterable 接口的聚合对象。</p><pre><code class="language-java">public interface Iterator&lt;E&gt; &amp;#123;    //集合中是否还有元素    boolean hasNext();    //获得集合中的下一个元素    E next();    ......&amp;#125;</code></pre><p><code>Iterator</code> 对象称为迭代器（设计模式的一种），迭代器可以对集合进行遍历，但每一个集合内部的数据结构可能是不尽相同的，所以每一个集合存和取都很可能是不一样的，虽然我们可以人为地在每一个类中定义 <code>hasNext()</code> 和 <code>next()</code> 方法，但这样做会让整个集合体系过于臃肿。于是就有了迭代器。</p><p>迭代器是将这样的方法抽取出接口，然后在每个类的内部，定义自己迭代方式，这样做就规定了整个集合体系的遍历方式都是 <code>hasNext()</code>和<code>next()</code>方法，使用者不用管怎么实现的，会用即可。迭代器的定义为：提供一种方法访问一个容器对象中各个元素，而又不需要暴露该对象的内部细节。</p><h4 id="迭代器的作用"><a class="header-anchor" href="#迭代器的作用">¶</a>迭代器的作用</h4><p>Iterator 主要用于遍历集合，他的特点是安全。因为它可以确保，当前遍历的集合元素被更改时，抛出 ConcurrentModificationException 异常。</p><h4 id="如何使用"><a class="header-anchor" href="#如何使用">¶</a>如何使用</h4><pre><code class="language-java">Map&lt;Integer, String&gt; map = new HashMap();map.put(1, &quot;Java&quot;);map.put(2, &quot;C++&quot;);map.put(3, &quot;PHP&quot;);Iterator&lt;Map.Entry&lt;Integer, String&gt;&gt; iterator = map.entrySet().iterator();while (iterator.hasNext()) &amp;#123;  Map.Entry&lt;Integer, String&gt; entry = iterator.next();  System.out.println(entry.getKey() + entry.getValue());&amp;#125;</code></pre><h2 id="List"><a class="header-anchor" href="#List">¶</a>List</h2><h3 id="ArrayList"><a class="header-anchor" href="#ArrayList">¶</a>ArrayList</h3><p><a href="../ArrayList">查看专题文章</a></p><h4 id="ArrayList扩容"><a class="header-anchor" href="#ArrayList扩容">¶</a>ArrayList扩容</h4><p><a href="../ArrayList_grow">查看专题文章</a></p><h3 id="Vector"><a class="header-anchor" href="#Vector">¶</a>Vector</h3><p><a href="../Vector">查看专题文章</a></p><h3 id="LinkedList"><a class="header-anchor" href="#LinkedList">¶</a>LinkedList</h3><p><a href="../LinkedList">查看专题文章</a></p><h3 id="Arraylist-和-Vector-的区别"><a class="header-anchor" href="#Arraylist-和-Vector-的区别">¶</a>Arraylist 和 Vector 的区别?</h3><ol><li>ArrayList 是 List 的主要实现类，底层使用 Object[ ]存储，适用于频繁的查找工作，线程不安全 ；</li><li>Vector 是 List 的古老实现类，底层使用 Object[ ]存储，线程安全的。</li></ol><h3 id="Arraylist-与-LinkedList-区别"><a class="header-anchor" href="#Arraylist-与-LinkedList-区别">¶</a>Arraylist 与 LinkedList 区别?</h3><ol><li><strong>是否保证线程安全：</strong> <code>ArrayList</code> 和 <code>LinkedList</code> 都是不同步的，也就是不保证线程安全；</li><li><strong>底层数据结构：</strong> <code>Arraylist</code> 底层使用的是 <strong><code>Object</code> 数组</strong>；<code>LinkedList</code> 底层使用的是 <strong>双向链表</strong> 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）</li><li><strong>插入和删除是否受元素位置的影响：</strong> ① <strong><code>ArrayList</code> 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。</strong> 比如：执行<code>add(E e)</code>方法的时候， <code>ArrayList</code> 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（<code>add(int index, E element)</code>）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。 ② <strong><code>LinkedList</code> 采用链表存储，所以对于<code>add(E e)</code>方法的插入，删除元素时间复杂度不受元素位置的影响，近似 O(1)，如果是要在指定位置<code>i</code>插入和删除元素的话（<code>(add(int index, E element)</code>） 时间复杂度近似为<code>o(n))</code>因为需要先移动到指定位置再插入。</strong></li><li><strong>是否支持快速随机访问：</strong> <code>LinkedList</code> 不支持高效的随机元素访问，而 <code>ArrayList</code> 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于<code>get(int index)</code>方法)。</li><li><strong>内存空间占用：</strong> ArrayList 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。</li></ol><h2 id="Map-v2"><a class="header-anchor" href="#Map-v2">¶</a>Map</h2><p>Map与List、Set接口不同，它是由一系列键值对组成的集合，提供了key到Value的映射。同时它也没有继承Collection。在Map中它保证了key与value之间的一一对应关系。也就是说一个key对应一个value，所以它不能存在相同的key值，当然value值可以相同。key可以为空，但是只允许出现一个null。它的主要实现类有HashMap、HashTable、LinkedHashMap、TreeMap。</p><h3 id="HashMap"><a class="header-anchor" href="#HashMap">¶</a>HashMap</h3><p>HashMap 是 Map 的一个实现类，它代表的是一种键值对的数据存储形式。<br>大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。<br>HashMap最多只允许一条记录的键为null，允许多条记录的值为null。遇到key为null的时候，调用putForNullKey方法进行处理，而对value没有处理。不保证有序(比如插入的顺序)、也不保证序不随时间变化。<br>jdk 8 之前，其内部是由数组+链表来实现的，而 jdk 8 对于链表长度超过 8 的链表将转储为红黑树。<br>HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。<br>hash数组的默认大小是16，而且大小一定是2的指数</p><p><a href="../HashMapAnalysis">查看专题文章</a></p><h3 id="HashTable"><a class="header-anchor" href="#HashTable">¶</a>HashTable</h3><p>Hashtable和HashMap一样也是散列表，存储元素也是键值对，底层实现是一个Entry数组+链表。Hashtable继承于Dictionary类（Dictionary类声明了操作键值对的接口方法），实现Map接口（定义键值对接口）。HashTable是线程安全的，它的大部分类都被synchronized关键字修饰。key和value都不可为null。<br>hash数组默认大小是11，扩充方式是old*2+1</p><h3 id="LinkedHashMap"><a class="header-anchor" href="#LinkedHashMap">¶</a>LinkedHashMap</h3><p>LinkedHashMap继承自HashMap实现了Map接口。基本实现同HashMap一样（底层基于数组+链表+红黑树实现），不同之处在于LinkedHashMap保证了迭代的有序性。其内部维护了一个双向链表，解决了 HashMap不能随时保持遍历顺序和插入顺序一致的问题。除此之外，LinkedHashMap对访问顺序也提供了相关支持。在一些场景下，该特性很有用，比如缓存。<br>在实现上，LinkedHashMap很多方法直接继承自HashMap，仅为维护双向链表覆写了部分方法。<br>默认情况下，LinkedHashMap的迭代顺序是按照插入节点的顺序。也可以通过改变accessOrder参数的值，使得其遍历顺序按照访问顺序输出。</p><p><a href="../LinkedHashMap">查看专题文章</a></p><h3 id="TreeMap"><a class="header-anchor" href="#TreeMap">¶</a>TreeMap</h3><p>TreeMap集合是基于红黑树（Red-Black tree）的 NavigableMap实现。该集合最重要的特点就是可排序，该映射根据其键的自然顺序进行排序，或者根据创建映射时提供的 Comparator 进行排序，具体取决于使用的构造方法。</p><h2 id="Set"><a class="header-anchor" href="#Set">¶</a>Set</h2><p>Set接口继承了Collection接口。Set集合中不能包含重复的元素，每个元素必须是唯一的。你只需将元素加入set中，重复的元素会自动移除。有三种常见的Set实现——HashSet, TreeSet和LinkedHashSet。如果你需要一个访问快速的Set，你应该使用HashSet；当你需要一个排序的Set，你应该使用TreeSet；当你需要记录下插入时的顺序时，你应该使用LinedHashSet。</p><h3 id="HashSet"><a class="header-anchor" href="#HashSet">¶</a>HashSet</h3><p>HashSet是是基于 HashMap 实现的，底层采用 HashMap 来保存元素,所以它不保证set 的迭代顺序；特别是它不保证该顺序恒久不变。add()、remove()以及contains()等方法都是复杂度为O(1)的方法。由于HashMap中key不可重复，所以HashSet元素不可重复。可以存储null元素，是线程不安全的。</p><h3 id="TreeSet"><a class="header-anchor" href="#TreeSet">¶</a>TreeSet</h3><p>TreeSet是一个有序集，基于TreeMap实现，是线程不安全的。<br>TreeSet底层采用TreeMap存储，构造器启动时新建TreeMap。TreeSet存储元素实际为TreeMap存储的键值对为&lt;key,PRESENT&gt;的key;，PRESENT为固定对象：private static final Object PRESENT = new Object().<br>TreeSet支持两种两种排序方式，通过不同构造器调用实现</p><pre><code class="language-java">自然排序：public TreeSet() &amp;#123;   // 新建TreeMap，自然排序   this(new TreeMap&lt;E,Object&gt;());&amp;#125;Comparator排序：public TreeSet(Comparator&lt;? super E&gt; comparator) &amp;#123;   // 新建TreeMap，传入自定义比较器comparator   this(new TreeMap&lt;&gt;(comparator));&amp;#125;TreeSet支持正向/反向迭代器遍历和foreach遍历// 顺序TreeSet：迭代器实现Iterator iter = set.iterator();while (iter.hasNext()) &amp;#123;   System.out.println(iter.next());&amp;#125;// 顺序遍历TreeSet：foreach实现for (Integer i : set) &amp;#123;   System.out.println(i);&amp;#125;// 逆序遍历TreeSet：反向迭代器实现Iterator iter1 = set.descendingIterator();while (iter1.hasNext()) &amp;#123;   System.out.println(iter1.next());&amp;#125;</code></pre><h3 id="LinkedHashSet"><a class="header-anchor" href="#LinkedHashSet">¶</a>LinkedHashSet</h3><p>LinkedHashSet介于HashSet和TreeSet之间。哈希表和链接列表实现。基本方法的复杂度为O(1)。<br>LinkedHashSet 是 Set 的一个具体实现，其维护着一个运行于所有条目的双重链接列表。此链接列表定义了迭代顺序，该迭代顺序可为插入顺序或是访问顺序。<br>LinkedHashSet 继承于 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 Hashmap 实现的一样。<br>如果我们需要迭代的顺序为插入顺序或者访问顺序，那么 LinkedHashSet 是需要你首先考虑的。<br>LinkedHashSet 底层使用 LinkedHashMap 来保存所有元素，因为继承于 HashSet，所有的方法操作上又与 HashSet 相同，因此 LinkedHashSet 的实现上非常简单，只提供了四个构造方法，并通过传递一个标识参数，调用父类的构造器，底层构造一个 LinkedHashMap 来实现，在相关操作上与父类 HashSet 的操作相同，直接调用父类 HashSet 的方法即可。</p><pre><code class="language-java">package java.util;public class LinkedHashSet&lt;E&gt;   extends HashSet&lt;E&gt;   implements Set&lt;E&gt;, Cloneable, java.io.Serializable &amp;#123;   private static final long serialVersionUID = -2851667679971038690L;  /**   * 构造一个带有指定初始容量和加载因子的空链表哈希set。   *   * 底层会调用父类的构造方法，构造一个有指定初始容量和加载因子的LinkedHashMap实例。   * @param initialCapacity 初始容量。   * @param loadFactor 加载因子。   */   public LinkedHashSet(int initialCapacity, float loadFactor) &amp;#123;     super(initialCapacity, loadFactor, true);   &amp;#125;  /**    * 构造一个指定初始容量和默认加载因子0.75的新链表哈希set。    *    * 底层会调用父类的构造方法，构造一个指定初始容量和默认加载因子0.75的LinkedHashMap实例。    * @param initialCapacity 初始容量。    */     public LinkedHashSet(int initialCapacity) &amp;#123;     super(initialCapacity, .75f, true);   &amp;#125;  /**    * 构造一个默认初始容量16和加载因子0.75的新链表哈希set。    *    * 底层会调用父类的构造方法，构造一个默认初始容量16和加载因子0.75的LinkedHashMap实例。    */     public LinkedHashSet() &amp;#123;     super(16, .75f, true);   &amp;#125;  /**    * 构造一个与指定collection中的元素相同的新链表哈希set。    *     * 底层会调用父类的构造方法，构造一个足以包含指定collection    * 中所有元素的初始容量和加载因子为0.75的LinkedHashMap实例。    * @param c 其中的元素将存放在此set中的collection。    */     public LinkedHashSet(Collection&lt;? extends E&gt; c) &amp;#123;     super(Math.max(2*c.size(), 11), .75f, true);     addAll(c);   &amp;#125;   @Override   public Spliterator&lt;E&gt; spliterator() &amp;#123;     return Spliterators.spliterator(this, Spliterator.DISTINCT | Spliterator.ORDERED);   &amp;#125;&amp;#125;</code></pre><p>通过观察<a href="../HashMapAnalysis">HashMap的源码</a>我们可以发现:<br>Hash Map的前三个构造函数，即访问权限为public类型的构造函数均是以HashMap作为实现。而以LinkedHashMap作为实现的构造函数的访问权限是默认访问权限，即包内访问权限。</p><p>即：在java编程中，通过new创建的HashSet对象均是以HashMap作为实现基础。只有在jdk中java.util包内的源代码才可能创建以LinkedHashMap作为实现的HashSet(LinkedHashSet就是通过封装一个以LinkedHashMap为实现的HashSet来实现的)。<br>只有包含三个参数的构造函数才是采用的LinkedHashMap作为实现。</p><h3 id="无序性和不可重复性的含义是什么"><a class="header-anchor" href="#无序性和不可重复性的含义是什么">¶</a>无序性和不可重复性的含义是什么</h3><p>1、什么是无序性？无序性不等于随机性 ，无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。<br>2、什么是不可重复性？不可重复性是指添加的元素按照 equals()判断时 ，返回 false，需要同时重写 equals()方法和 HashCode()方法。</p><h3 id="比较-HashSet、LinkedHashSet-和-TreeSet-三者的异同"><a class="header-anchor" href="#比较-HashSet、LinkedHashSet-和-TreeSet-三者的异同">¶</a>比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同</h3><p>HashSet 是 Set 接口的主要实现类 ，HashSet 的底层是 HashMap，线程不安全的，可以存储 null 值；<br>LinkedHashSet 是 HashSet 的子类，能够按照添加的顺序遍历；<br>TreeSet 底层使用红黑树，能够按照添加元素的顺序进行遍历，排序的方式有自然排序和定制排序。</p><h3 id="Set中的元素不能重复，如何实现？"><a class="header-anchor" href="#Set中的元素不能重复，如何实现？">¶</a>Set中的元素不能重复，如何实现？</h3><p>在Java的Set体系中，根据实现方式不同主要分为两大类。HashSet和TreeSet。</p><p>TreeSet 是二叉树实现的,Treeset中的数据是自动排好序的，不允许放入null值 2、HashSet 是哈希表实现的,HashSet中的数据是无序的，可以放入null，但只能放入一个null，两者中的值都不能重复，就如数据库中唯一约束</p><p>在HashSet中，基本的操作都是有HashMap底层实现的，因为HashSet底层是用HashMap存储数据的。当向HashSet中添加元素的时候，首先计算元素的hashcode值，然后通过扰动计算和按位与的方式计算出这个元素的存储位置，如果这个位置位空，就将元素添加进去；如果不为空，则用equals方法比较元素是否相等，相等就不添加，否则找一个空位添加。</p><p>TreeSet的底层是TreeMap的keySet()，而TreeMap是基于红黑树实现的，红黑树是一种平衡二叉查找树，它能保证任何一个节点的左右子树的高度差不会超过较矮的那棵的一倍。</p><p>TreeMap是按key排序的，元素在插入TreeSet时compareTo()方法要被调用，所以TreeSet中的元素要实现Comparable接口。TreeSet作为一种Set，它不允许出现重复元素。TreeSet是用compareTo()来判断重复元素的。</p><p>Set大多都用的Map接口的实现类来实现的（HashSet基于HashMap实现，TreeSet基于TreeMap实现，LinkedHashSet基于LinkedHashMap实现）在HashMap中通过如下实现来保证key值唯一</p><pre><code class="language-java"> // 1. 如果key 相等  if (p.hash == hash &amp;&amp;   ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))   e = p;// 2. 修改对应的value  if (e != null) &amp;#123; // existing mapping for key     V oldValue = e.value;     if (!onlyIfAbsent || oldValue == null)       e.value = value;     afterNodeAccess(e);     return oldValue;  &amp;#125;</code></pre><p>添加元素的时候，如果key(也对应的Set集合的元素)相等，那么则修改value值。而在Set集合中，value值仅仅是一个Object对象罢了(该对象对Set本身而言是无用的)。<br>也就是说：Set集合如果添加的元素相同时，是根本没有插入的(仅修改了一个无用的value值)。从源码(HashMap)中也看出来，==和equals()方法都有使用！</p><h3 id="comparable-和-Comparator-的区别"><a class="header-anchor" href="#comparable-和-Comparator-的区别">¶</a>comparable 和 Comparator 的区别</h3><ul><li><code>comparable</code> 接口实际上是出自<code>java.lang</code>包 它有一个 <code>compareTo(Object obj)</code>方法用来排序</li><li><code>comparator</code>接口实际上是出自 java.util 包它有一个<code>compare(Object obj1, Object obj2)</code>方法用来排序</li></ul><p>一般我们需要对一个集合使用自定义排序时，我们就要重写<code>compareTo()</code>方法或<code>compare()</code>方法，当我们需要对某一个集合实现两种排序方式，比如一个 song 对象中的歌名和歌手名分别采用一种排序方法的话，我们可以重写<code>compareTo()</code>方法和使用自制的<code>Comparator</code>方法或者以两个 Comparator 来实现歌名排序和歌星名排序，第二种代表我们只能使用两个参数版的 <code>Collections.sort()</code>.</p><h4 id="Comparator-定制排序"><a class="header-anchor" href="#Comparator-定制排序">¶</a>Comparator 定制排序</h4><pre><code class="language-java">        ArrayList&lt;Integer&gt; arrayList = new ArrayList&lt;Integer&gt;();        arrayList.add(-1);        arrayList.add(3);        arrayList.add(3);        arrayList.add(-5);        arrayList.add(7);        arrayList.add(4);        arrayList.add(-9);        arrayList.add(-7);        System.out.println(&quot;原始数组:&quot;);        System.out.println(arrayList);        // void reverse(List list)：反转        Collections.reverse(arrayList);        System.out.println(&quot;Collections.reverse(arrayList):&quot;);        System.out.println(arrayList);        // void sort(List list),按自然排序的升序排序        Collections.sort(arrayList);        System.out.println(&quot;Collections.sort(arrayList):&quot;);        System.out.println(arrayList);        // 定制排序的用法        Collections.sort(arrayList, new Comparator&lt;Integer&gt;() &amp;#123;            @Override            public int compare(Integer o1, Integer o2) &amp;#123;                return o2.compareTo(o1);            &amp;#125;        &amp;#125;);        System.out.println(&quot;定制排序后：&quot;);        System.out.println(arrayList);OutPut :原始数组:[-1, 3, 3, -5, 7, 4, -9, -7]Collections.reverse(arrayList):[-7, -9, 4, 7, -5, 3, 3, -1]Collections.sort(arrayList):[-9, -7, -5, -1, 3, 3, 4, 7]定制排序后：[7, 4, 3, 3, -1, -5, -7, -9]</code></pre><h4 id="重写-compareTo（）方法实现按年龄排序"><a class="header-anchor" href="#重写-compareTo（）方法实现按年龄排序">¶</a>重写 compareTo（）方法实现按年龄排序</h4><pre><code class="language-java">// person对象没有实现Comparable接口，所以必须实现，这样才不会出错，才可以使treemap中的数据按顺序排列// 前面一个例子的String类已经默认实现了Comparable接口，详细可以查看String类的API文档，另外其他// 像Integer类等都已经实现了Comparable接口，所以不需要另外实现了public  class Person implements Comparable&lt;Person&gt; &amp;#123;    private String name;    private int age;    public Person(String name, int age) &amp;#123;        super();        this.name = name;        this.age = age;    &amp;#125;    public String getName() &amp;#123;        return name;    &amp;#125;    public void setName(String name) &amp;#123;        this.name = name;    &amp;#125;    public int getAge() &amp;#123;        return age;    &amp;#125;    public void setAge(int age) &amp;#123;        this.age = age;    &amp;#125;    /**     * T重写compareTo方法实现按年龄来排序     */    @Override    public int compareTo(Person o) &amp;#123;        if (this.age &gt; o.getAge()) &amp;#123;            return 1;        &amp;#125;        if (this.age &lt; o.getAge()) &amp;#123;            return -1;        &amp;#125;        return 0;    &amp;#125;&amp;#125;    public static void main(String[] args) &amp;#123;        TreeMap&lt;Person, String&gt; pdata = new TreeMap&lt;Person, String&gt;();        pdata.put(new Person(&quot;张三&quot;, 30), &quot;zhangsan&quot;);        pdata.put(new Person(&quot;李四&quot;, 20), &quot;lisi&quot;);        pdata.put(new Person(&quot;王五&quot;, 10), &quot;wangwu&quot;);        pdata.put(new Person(&quot;小红&quot;, 5), &quot;xiaohong&quot;);        // 得到key的值的同时得到key所对应的值        Set&lt;Person&gt; keys = pdata.keySet();        for (Person key : keys) &amp;#123;            System.out.println(key.getAge() + &quot;-&quot; + key.getName());        &amp;#125;    &amp;#125;OutPut :5-小红10-王五20-李四30-张三</code></pre><h2 id="其他"><a class="header-anchor" href="#其他">¶</a>其他</h2><h3 id="说说List、Set、Map的区别"><a class="header-anchor" href="#说说List、Set、Map的区别">¶</a>说说List、Set、Map的区别</h3><p>List 存储元素有序，可重复。<br>Set 存储元素无序，不可重复。<br>Map 使用键值对（kye-value）存储，类似于数学上的函数 y=f(x)，“x”代表 key，&quot;y&quot;代表 value，Key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。</p><h3 id="如何选用集合"><a class="header-anchor" href="#如何选用集合">¶</a>如何选用集合?</h3><p>主要根据集合的特点来选用，比如我们需要根据键值获取到元素值时就选用 <code>Map</code> 接口下的集合，需要排序时选择 <code>TreeMap</code>,不需要排序时就选择 <code>HashMap</code>,需要保证线程安全就选用 <code>ConcurrentHashMap</code>。</p><p>当我们只需要存放元素值时，就选择实现<code>Collection</code> 接口的集合，需要保证元素唯一时选择实现 <code>Set</code> 接口的集合比如 <code>TreeSet</code> 或 <code>HashSet</code>，不需要就选择实现 <code>List</code> 接口的比如 <code>ArrayList</code> 或 <code>LinkedList</code>，然后再根据实现这些接口的集合的特点来选用。</p><h3 id="为什么要使用集合？"><a class="header-anchor" href="#为什么要使用集合？">¶</a>为什么要使用集合？</h3><p>当我们需要保存一组类型相同的数据的时候，我们应该是用一个容器来保存，这个容器就是数组，但是，使用数组存储对象具有一定的弊端， 因为我们在实际开发中，存储的数据的类型是多种多样的，于是，就出现了“集合”，集合同样也是用来存储多个数据的。</p><p>数组的缺点是一旦声明之后，长度就不可变了；同时，声明数组时的数据类型也决定了该数组存储的数据的类型；而且，数组存储的数据是有序的、可重复的，特点单一。 但是集合提高了数据存储的灵活性，Java 集合不仅可以用来存储不同类型不同数量的对象，还可以保存具有映射关系的数据</p><h3 id="有哪些集合是线程不安全的？怎么解决呢？"><a class="header-anchor" href="#有哪些集合是线程不安全的？怎么解决呢？">¶</a>有哪些集合是线程不安全的？怎么解决呢？</h3><p>我们常用的 <code>Arraylist</code> ,<code>LinkedList</code>,<code>Hashmap</code>,<code>HashSet</code>,<code>TreeSet</code>,<code>TreeMap</code>，<code>PriorityQueue</code> 都不是线程安全的。解决办法很简单，可以使用线程安全的集合来代替。<br>如果你要使用线程安全的集合的话， <code>java.util.concurrent</code> 包中提供了很多并发容器供你使用：</p><ol><li><code>ConcurrentHashMap</code>: 可以看作是线程安全的 <code>HashMap</code></li><li><code>CopyOnWriteArrayList</code>:可以看作是线程安全的 <code>ArrayList</code>，在读多写少的场合性能非常好，远远好于 <code>Vector</code>.</li><li><code>ConcurrentLinkedQueue</code>:高效的并发队列，使用链表实现。可以看做一个线程安全的 <code>LinkedList</code>，这是一个非阻塞队列。</li><li><code>BlockingQueue</code>: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。</li><li><code>ConcurrentSkipListMap</code> :跳表的实现。这是一个<code>Map</code>，使用跳表的数据结构进行快速查找。</li></ol><h3 id="fail-fast"><a class="header-anchor" href="#fail-fast">¶</a>fail-fast</h3><p>fail-fast 机制是java集合(Collection)中的一种错误机制。当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件。<br><strong>快速失败（fail—fast）</strong><br>在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。<br>**原理：**迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。<br>注意：这里异常的抛出条件是检测到 modCount！=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。<br>场景：java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。<br><strong>安全失败（fail—safe）</strong><br>采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。<br>**原理：**由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。<br>缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。<br>场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。</p><h3 id="Vector和ArrayList"><a class="header-anchor" href="#Vector和ArrayList">¶</a>Vector和ArrayList</h3><p>**相同点：**这两个类都实现了List接口，他们都是有序的集合（储存有序），底层都用数组实现。可以通过索引来获取某个元素。允许元素重复和出现null值。ArrayList和Vector的迭代器实现都是fail-fast的。<br>**不同点：**vector是线程同步的，所以它也是线程安全的，而arraylist是线程异步的，是不安全的。如果不考虑到线程的安全因素，一般用arraylist效率比较高。<br>扩容时，arraylist扩容1.5倍，vector扩容2倍（或者扩容指定的大小）<br>ArrayList 和Vector是采用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，都允许直接序号索引元素，但是插入数据要设计到数组元素移动等内存操作，所以索引数据快插入数据慢，Vector由于使用了synchronized方法（线程安全）所以性能上比ArrayList要差，LinkedList使用双向链表实现存储，按序号索引数据需要进行向前或向后遍历，但是插入数据时只需要记录本项的前后项即可，所以插入数度较快！</p><h3 id="Aarraylist和Linkedlist"><a class="header-anchor" href="#Aarraylist和Linkedlist">¶</a>Aarraylist和Linkedlist</h3><p>ArrayList是基于数组实现的，LinkedList基于双向链表实现的。<br>ArrayList它支持以下标位置进行索引出对应的元素(随机访问)，而LinkedList则需要遍历整个链表来获取对应的元素。因此一般来说ArrayList的访问速度是要比LinkedList要快的<br>ArrayList由于是数组，对于删除和修改而言消耗是比较大(复制和移动数组实现)，LinkedList是双向链表删除和修改只需要修改对应的指针即可，消耗是很小的。因此一般来说LinkedList的增删速度是要比ArrayList要快的<br>LinkedList比ArrayList消耗更多的内存，因为LinkedList中的每个节点存储了前后节点的引用。<br><strong>对于增加/删除元素操作</strong><br>如果增删都是在末尾来操作（每次调用的都是remove()和add()），此时ArrayList就不需要移动和复制数组来进行操作了。如果数据量有百万级的时，速度是会比LinkedList要快的。<br>如果删除操作的位置是在中间。由于LinkedList的消耗主要是在遍历上，ArrayList的消耗主要是在移动和复制上(底层调用的是arraycopy()方法，是native方法)。LinkedList的遍历速度是要慢于ArrayList的复制移动速度的如果数据量有百万级的时，还是ArrayList要快。</p><h3 id="哪些集合类提供对元素的随机访问？"><a class="header-anchor" href="#哪些集合类提供对元素的随机访问？">¶</a>哪些集合类提供对元素的随机访问？</h3><p>ArrayList、HashMap、TreeMap和HashTable类提供对元素的随机访问。</p><h3 id="Enumeration和Iterator接口的区别"><a class="header-anchor" href="#Enumeration和Iterator接口的区别">¶</a>Enumeration和Iterator接口的区别</h3><p>Enumeration的速度是Iterator的两倍，也使用更少的内存。Enumeration是非常基础的，也满足了基础的需要。但是，与Enumeration相比，Iterator更加安全，因为当一个集合正在被遍历的时候，它会阻止其它线程去修改集合。<br>Iterator的方法名比Enumeration更科学Iterator有fail-fast机制，比Enumeration更安全Iterator能够删除元素，Enumeration并不能删除元素</p><h3 id="Iterater和ListIterator之间有什么区别？"><a class="header-anchor" href="#Iterater和ListIterator之间有什么区别？">¶</a>Iterater和ListIterator之间有什么区别？</h3><p>我们可以使用Iterator来遍历Set和List集合，而ListIterator只能遍历List。Iterator只可以向前遍历，而LIstIterator可以双向遍历。ListIterator从Iterator接口继承，然后添加了一些额外的功能，比如添加一个元素、替换一个元素、获取前面或后面元素的索引位置。</p><h3 id="Java中HashMap的key值要是为类对象则该类需要满足什么条件？"><a class="header-anchor" href="#Java中HashMap的key值要是为类对象则该类需要满足什么条件？">¶</a>Java中HashMap的key值要是为类对象则该类需要满足什么条件？</h3><p>需要同时重写该类的hashCode()方法和它的equals()方法。<br>从源码可以得知，在插入元素的时候是先算出该对象的hashCode。如果hashcode相等话的。那么表明该对象是存储在同一个位置上的。如果调用equals()方法，两个key相同，则替换元素如果调用equals()方法，两个key不相同，则说明该hashCode仅仅是碰巧相同，此时是散列冲突，将新增的元素放在桶子上<br>重写了equals()方法，就要重写hashCode()的方法。因为equals()认定了这两个对象相同，而同一个对象调用hashCode()方法时，是应该返回相同的值的！</p><h3 id="HashSet与HashMap"><a class="header-anchor" href="#HashSet与HashMap">¶</a>HashSet与HashMap</h3><p>HashSet 实现了 Set 接口，它不允许集合中有重复的值，当我们提到 HashSet 时，第一件事情就是在将对象存储在 HashSet 之前，要先确保对象重写 equals()和 hashCode()方法，这样才能比较对象的值是否相等，以确保set中没有储存相等的对象。如果我们没有重写这两个方法，将会使用这个方法的默认实现。<br>public boolean add(Object o)方法用来在 Set 中添加元素，当元素值重复时则会立即返回 false，如果成功添加的话会返回 true。<br>HashMap 实现了 Map 接口，Map 接口对键值对进行映射。Map 中不允许重复的键。Map 接口有两个基本的实现，HashMap 和 TreeMap。TreeMap 保存了对象的排列次序，而 HashMap 则不能。HashMap 允许键和值为 null。HashMap 是非 synchronized 的，但 collection 框架提供方法能保证 HashMap synchronized，这样多个线程同时访问 HashMap 时，能保证只有一个线程更改 Map。<br>public Object put(Object Key,Object value)方法用来将元素添加到 map 中。</p><table><thead><tr><th>HashMap</th><th>HashSet</th></tr></thead><tbody><tr><td>HashMap实现了Map接口</td><td>HashSet实现了Set接口</td></tr><tr><td>HashMap储存键值对</td><td>HashSet仅仅存储对象</td></tr><tr><td>使用put()方法将元素放入map中</td><td>使用add()方法将元素放入set中</td></tr><tr><td>HashMap中使用键对象来计算hashcode值</td><td>HashSet使用成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()方法用来判断对象的相等性，如果两个对象不同的话，那么返回false</td></tr></tbody></table><h3 id="hashtable与hashmap"><a class="header-anchor" href="#hashtable与hashmap">¶</a>hashtable与hashmap</h3><p>**相同点：**储存结构和实现基本相同，都是是实现的Map接口<br>**不同点：**HashTable是同步的，HashMap是非同步的，需要同步的时候可以ConcurrentHashMap方法<br>HashMap允许为null，HashTable不允许为null<br>继承不同，HashMap继承的是AbstractMap，HashTable继承的是Dictionary<br>HashMap提供对key的Set进行遍历，因此它是fail-fast的，但HashTable提供对key的Enumeration进行遍历，它不支持fail-fast。<br>HashTable是一个遗留类，如果需要保证线程安全推荐使用CocurrentHashMap</p><h3 id="HashMap与TreeMap"><a class="header-anchor" href="#HashMap与TreeMap">¶</a>HashMap与TreeMap</h3><p>HashMap通过hashcode对其内容进行快速查找，而TreeMap中所有的元素都保持着某种固定的顺序，如果你需要得到一个有序的结果你就应该使用TreeMap（HashMap中元素的排列顺序是不固定的）。HashMap中元素的排列顺序是不固定的）。<br>在Map 中插入、删除和定位元素，HashMap 是最好的选择。但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。使用HashMap要求添加的键类明确定义了hashCode()和 equals()的实现。 这个TreeMap没有调优选项，因为该树总处于平衡状态。</p><h3 id="集合框架中的泛型有什么优点？"><a class="header-anchor" href="#集合框架中的泛型有什么优点？">¶</a>集合框架中的泛型有什么优点？</h3><p>Java1.5引入了泛型，所有的集合接口和实现都大量地使用它。泛型允许我们为集合提供一个可以容纳的对象类型，因此，如果你添加其它类型的任何元素，它会在编译时报错。这避免了在运行时出现ClassCastException，因为你将会在编译时得到报错信息。泛型也使得代码整洁，我们不需要使用显式转换和instanceOf操作符。它也给运行时带来好处，因为不会产生类型检查的字节码指令。</p><h3 id="comparable-和-comparator的不同之处？"><a class="header-anchor" href="#comparable-和-comparator的不同之处？">¶</a>comparable 和 comparator的不同之处？</h3><p>comparable接口实际上是出自java.lang包它有一个 compareTo(Object obj)方法来将objects排序comparator接口实际上是出自 java.util 包它有一个compare(Object obj1, Object obj2)方法来将objects排序</p><h3 id="如何保证一个集合线程安全？"><a class="header-anchor" href="#如何保证一个集合线程安全？">¶</a>如何保证一个集合线程安全？</h3><p>Vector, Hashtable, Properties 和 Stack 都是同步的类，所以它们都线程安全的，可以被使用在多线程环境中使用Collections.synchronizedList(list)) 方法，可以保证list类是线程安全的使用java.util.Collections.synchronizedSet()方法可以保证set类是线程安全的。</p><h3 id="TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort-方法如何比较元素？"><a class="header-anchor" href="#TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort-方法如何比较元素？">¶</a>TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？</h3><p>TreeSet要求存放的对象所属的类必须实现Comparable接口，该接口提供了比较元素的compareTo()方法，当插入元素时会回调该方法比较元素的大小。<br>TreeMap要求存放的键值对映射的键必须实现Comparable接口从而根据键对元素进行排序。<br>Collections工具类的sort方法有两种重载的形式，<strong>第一种</strong>要求传入的待排序容器中存放的对象比较实现Comparable接口以实现元素的比较；<strong>第二种</strong>不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是Comparator接口的子类型（需要重写compare方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java中对函数式编程的支持）。</p><h3 id="什么是Java优先级队列？"><a class="header-anchor" href="#什么是Java优先级队列？">¶</a>什么是Java优先级队列？</h3><p>Java PriorityQueue是一个数据结构，它是Java集合框架的一部分。 它是一个队列的实现，其中元素的顺序将根据每个元素的优先级来决定。 实例化PriorityQueue时，可以在构造函数中提供比较器。 该比较器将决定PriorityQueue集合实例中元素的排序顺序。</p><h3 id="Java-hashCode（）和equals（）方法。"><a class="header-anchor" href="#Java-hashCode（）和equals（）方法。">¶</a>Java hashCode（）和equals（）方法。</h3><p>equals（）方法用于确定两个Java对象的相等性。 当我们有一个自定义类时，我们需要重写equals（）方法并提供一个实现，以便它可以用来找到它的两个实例之间的相等性。 通过Java规范，equals（）和hashCode（）之间有一个契约。 它说，“如果两个对象相等，即obj1.equals（obj2）为true，那么obj1.hashCode（）和obj2.hashCode（）必须返回相同的整数”<br>无论何时我们选择重写equals（），我们都必须重写hashCode（）方法。 hashCode（）用于计算位置存储区和key。</p><h3 id="Enumeration和Iterator区别"><a class="header-anchor" href="#Enumeration和Iterator区别">¶</a>Enumeration和Iterator区别</h3><p>函数接口不同</p><ul><li>Enumeration只有2个函数接口。通过Enumeration，我们只能读取集合的数据，而不能对数据进行修改。</li><li>Iterator只有3个函数接口。Iterator除了能读取集合的数据之外，也能数据进行删除操作。</li></ul><p>Iterator支持fail-fast机制，而Enumeration不支持。</p><ul><li>Enumeration 是JDK 1.0添加的接口。使用到它的函数包括Vector、Hashtable等类，这些类都是JDK 1.0中加入的，Enumeration存在的目的就是为它们提供遍历接口。Enumeration本身并没有支持同步，而在Vector、Hashtable实现Enumeration时，添加了同步。</li><li>而Iterator 是JDK 1.2才添加的接口，它也是为了HashMap、ArrayList等集合提供遍历接口。Iterator是支持fail-fast机制的：当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。</li></ul><p>注意：Enumeration迭代器只能遍历Vector、Hashtable这种古老的集合，因此通常不要使用它，除非在某些极端情况下，不得不使用Enumeration，否则都应该选择Iterator迭代器。</p><h3 id="HashMap-和-ConcurrentHashMap-的区别？"><a class="header-anchor" href="#HashMap-和-ConcurrentHashMap-的区别？">¶</a>HashMap 和 ConcurrentHashMap 的区别？</h3><p>ConcurrentHashMap和HashMap的实现方式不一样，虽然都是使用桶数组实现的，但是还是有区别，ConcurrentHashMap对桶数组进行了分段，而HashMap并没有。</p><p>ConcurrentHashMap在每一个分段上都用锁进行了保护。HashMap没有锁机制。所以，前者线程安全的，后者不是线程安全的。</p><h3 id="HashMap中hash方法的原理"><a class="header-anchor" href="#HashMap中hash方法的原理">¶</a>HashMap中hash方法的原理</h3><p><a href="https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/hash-in-hashmap">https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/hash-in-hashmap</a></p><h3 id="为什么HashMap的默认容量设置成16"><a class="header-anchor" href="#为什么HashMap的默认容量设置成16">¶</a>为什么HashMap的默认容量设置成16</h3><p><a href="https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/hashmap-default-capacity">https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/hashmap-default-capacity</a></p><h3 id="为什么HashMap的默认负载因子设置成0-75"><a class="header-anchor" href="#为什么HashMap的默认负载因子设置成0-75">¶</a>为什么HashMap的默认负载因子设置成0.75</h3><p><a href="https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/hashmap-default-loadfactor">https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/hashmap-default-loadfactor</a></p><h3 id="Java-8中stream相关用法"><a class="header-anchor" href="#Java-8中stream相关用法">¶</a>Java 8中stream相关用法</h3><p><a href="https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/stream">https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/stream</a></p><h3 id="Apache集合处理工具类的使用"><a class="header-anchor" href="#Apache集合处理工具类的使用">¶</a>Apache集合处理工具类的使用</h3><p><a href="https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/apache-collections">https://hollischuang.github.io/toBeTopJavaer/#/basics/java-basic/apache-collections</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;集合中用到的数据结构有以下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;**数组：**最常用的数据结构之一。数组的特点是长度固定，可以用下标索引，并且所有的元素的类型都是一致的。使用时尽量把数组封装在一个类里，防止数据被错误的操作弄乱。&lt;/li&gt;
&lt;li&gt;**链表：**是一种由多个节点组成的数据结构，并且每个节点包含有数据以及指向下一个节点的引用，在双向链表里，还会有一个指向前一个节点的引用。例如，可以用单向链表和双向链表来实现堆栈和队列，因为链表的两端都是可以进行插入和删除的动作的。当然，也会有在链表的中间频繁插入和删除节点的场景。&lt;/li&gt;
&lt;li&gt;**树：**是一种由节点组成的数据结构，每个节点都包含数据元素，并且有一个或多个子节点，每个子节点指向一个父节点可以表示层级关系或者数据元素的顺序关系。如果树的每个子节点最多有两个叶子节点，那么这种树被称为二叉树。二叉树是一种非常常用的树形结构， 因为它的这种结构使得节点的插入和删除都非常高效。树的边表示从一个节点到另外一个节点的快捷路径。&lt;/li&gt;
&lt;li&gt;**堆栈：**只允许对最后插入的元素进行操作（也就是后进先出，Last In First Out – LIFO）。如果你移除了栈顶的元素，那么你可以操作倒数第二个元素，依次类推。这种后进先出的方式是通过仅有的peek(),push()和pop()这几个方法的强制性限制达到的。这种结构在很多场景下都非常实用，例如解析像(4+2)*3这样的数学表达式，把源码中的方法和异常按照他们出现的顺序放到堆栈中，检查你的代码看看小括号和花括号是不是匹配的，等等。&lt;/li&gt;
&lt;li&gt;**队列：**和堆栈有些相似，不同之处在于在队列里第一个插入的元素也是第一个被删除的元素（即是先进先出）。这种先进先出的结构是通过只提供peek()，offer()和poll()这几个方法来访问数据进行限制来达到的。例如，排队等待公交车，银行或者超市里的等待列队等等，都是可以用队列来表示。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="集合" scheme="https://gyl-coder.top/tags/%E9%9B%86%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>LinkedHashMap 底层实现原理分析</title>
    <link href="https://gyl-coder.top/java/collection/LinkedHashMap/"/>
    <id>https://gyl-coder.top/java/collection/LinkedHashMap/</id>
    <published>2020-07-04T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<p>LinkedHashMap继承自HashMap实现了Map接口。基本实现同HashMap一样，不同之处在于LinkedHashMap保证了迭代的有序性。其内部维护了一个双向链表，解决了 HashMap不能随时保持遍历顺序和插入顺序一致的问题。除此之外，LinkedHashMap对访问顺序也提供了相关支持。在一些场景下，该特性很有用，比如缓存。</p><p>在实现上，LinkedHashMap很多方法直接继承自<a href="../HashMapAnalysis">HashMap</a>，仅为维护双向链表覆写了部分方法。所以，要看懂 LinkedHashMap 的源码，需要先看懂 <a href="../HashMapAnalysis">HashMap</a> 的源码。</p><p>默认情况下，LinkedHashMap的迭代顺序是按照插入节点的顺序。也可以通过改变accessOrder参数的值，使得其遍历顺序按照访问顺序输出。</p><p>这里我们只讨论LinkedHashMap和HashMap的不同之处，LinkedHashMap的其他操作和特性具体请参考<a href="../HashMapAnalysis">HashMap</a></p><p>我们先来看下两者的区别：</p><a id="more"></a><pre><code class="language-java">import java.util.HashMap;import java.util.Iterator;import java.util.LinkedHashMap;import java.util.Map;public class Test04 &amp;#123;    public static void main(String[] args) &amp;#123;        Map&lt;String, String&gt; map = new LinkedHashMap&lt;String, String&gt;();        map.put(&quot;ahdjkf&quot;, &quot;1&quot;);        map.put(&quot;ifjdj&quot;, &quot;2&quot;);        map.put(&quot;giafdja&quot;, &quot;3&quot;);        map.put(&quot;agad&quot;, &quot;4&quot;);        map.put(&quot;ahdjkge&quot;, &quot;5&quot;);        map.put(&quot;iegnj&quot;, &quot;6&quot;);        System.out.println(&quot;LinkedHashMap的迭代顺序(accessOrder=false)：&quot;);        Iterator iterator = map.entrySet().iterator();        while (iterator.hasNext()) &amp;#123;            Map.Entry entry = (Map.Entry) iterator.next();            System.out.println(entry.getKey() + &quot;=&quot; + entry.getValue());        &amp;#125;                Map&lt;String, String&gt; map1 = new LinkedHashMap&lt;String, String&gt;(16,0.75f,true);        map1.put(&quot;ahdjkf&quot;, &quot;1&quot;);        map1.put(&quot;ifjdj&quot;, &quot;2&quot;);        map1.put(&quot;giafdja&quot;, &quot;3&quot;);        map1.put(&quot;agad&quot;, &quot;4&quot;);        map1.put(&quot;ahdjkge&quot;, &quot;5&quot;);        map1.put(&quot;iegnj&quot;, &quot;6&quot;);                map1.get(&quot;ahdjkf&quot;);        map1.get(&quot;ifjdj&quot;);        System.out.println(&quot;LinkedHashMap的迭代顺序(accessOrder=true)：&quot;);        Iterator iterator1 = map1.entrySet().iterator();        while (iterator1.hasNext()) &amp;#123;            Map.Entry entry = (Map.Entry) iterator1.next();            System.out.println(entry.getKey() + &quot;=&quot; + entry.getValue());        &amp;#125;                Map&lt;String, String&gt; map2 = new HashMap&lt;&gt;();        map2.put(&quot;ahdjkf&quot;, &quot;1&quot;);        map2.put(&quot;ifjdj&quot;, &quot;2&quot;);        map2.put(&quot;giafdja&quot;, &quot;3&quot;);        map2.put(&quot;agad&quot;, &quot;4&quot;);        map2.put(&quot;ahdjkge&quot;, &quot;5&quot;);        map2.put(&quot;iegnj&quot;, &quot;6&quot;);                System.out.println(&quot;HashMap的迭代顺序：&quot;);            Iterator iterator2 = map2.entrySet().iterator();        while (iterator2.hasNext()) &amp;#123;            Map.Entry aMap = (Map.Entry) iterator2.next();            System.out.println(aMap.getKey() + &quot;=&quot; + aMap.getValue());        &amp;#125;    &amp;#125;&amp;#125;Output：LinkedHashMap的迭代顺序(accessOrder=false)：ahdjkf=1ifjdj=2giafdja=3agad=4ahdjkge=5iegnj=6LinkedHashMap的迭代顺序(accessOrder=true)：giafdja=3agad=4ahdjkge=5iegnj=6ahdjkf=1ifjdj=2HashMap的迭代顺序：iegnj=6giafdja=3ifjdj=2agad=4ahdjkf=1ahdjkge=5</code></pre><p>可以看到 LinkedHashMap在每次插入数据，访问、修改数据时都会调整链表的节点顺序。以决定迭代时输出的顺序。</p><p>下面我们来看LinkedHashMap具体是怎么实现的：</p><p>LinkedHashMap继承了HashMap，内部静态类Entry继承了HashMap的Entry，但是LinkedHashMap.Entry多了两个字段：before和after，before表示在本节点之前添加到LinkedHashMap的那个节点，after表示在本节点之后添加到LinkedHashMap的那个节点，这里的之前和之后指时间上的先后顺序。</p><pre><code class="language-java">static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &amp;#123;    Entry&lt;K,V&gt; before, after;    Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &amp;#123;        super(hash, key, value, next);    &amp;#125;&amp;#125;</code></pre><p>同时类里有两个成员变量head和tail,分别指向内部双向链表的表头、表尾。</p><pre><code class="language-java">//双向链表的头结点transient LinkedHashMap.Entry&lt;K,V&gt; head;//双向链表的尾节点transient LinkedHashMap.Entry&lt;K,V&gt; tail;</code></pre><p>我们通过两张图来看下LinkedHashMap的存储结构</p><div class="gallery ">              <p><img src="https://cdn.nlark.com/yuque/0/2020/png/420470/1594858298550-74cd2f4d-fbd7-4fb1-9137-66e8cabfa0c9.png#align=left&amp;display=inline&amp;height=481&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=481&amp;originWidth=496&amp;size=130674&amp;status=done&amp;style=none&amp;width=496" class="lazyload placeholder" data-srcset="https://cdn.nlark.com/yuque/0/2020/png/420470/1594858298550-74cd2f4d-fbd7-4fb1-9137-66e8cabfa0c9.png#align=left&amp;display=inline&amp;height=481&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=481&amp;originWidth=496&amp;size=130674&amp;status=done&amp;style=none&amp;width=496" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/420470/1594858311210-4fcaece5-e472-42a2-a273-afc99b9ed033.png#align=left&amp;display=inline&amp;height=459&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=459&amp;originWidth=684&amp;size=177299&amp;status=done&amp;style=none&amp;width=684" class="lazyload placeholder" data-srcset="https://cdn.nlark.com/yuque/0/2020/png/420470/1594858311210-4fcaece5-e472-42a2-a273-afc99b9ed033.png#align=left&amp;display=inline&amp;height=459&amp;margin=%5Bobject%20Object%5D&amp;name=image.png&amp;originHeight=459&amp;originWidth=684&amp;size=177299&amp;status=done&amp;style=none&amp;width=684" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg" alt="image.png"></p>            </div><p>图片来自：<a href="https://segmentfault.com/u/coolblog">coolblog</a></p><p>将LinkedHashMap的accessOrder字段设置为true后，每次访问哈希表中的节点都将该节点移到链表的末尾，表示该节点是最新访问的节点。即循环双向链表的头部存放的是最久访问的节点或最先插入的节点，尾部为最近访问的或最近插入的节点。</p><p>由于增加了一个accessOrder属性，LinkedHashMap相对HashMap来说增加了一个构造方法用来控制迭代顺序。</p><pre><code class="language-java">final boolean accessOrder;public LinkedHashMap() &amp;#123;    super();    accessOrder = false;&amp;#125;//指定初始化时的容量，public LinkedHashMap(int initialCapacity) &amp;#123;    super(initialCapacity);    accessOrder = false;&amp;#125;//指定初始化时的容量，和扩容的加载因子public LinkedHashMap(int initialCapacity, float loadFactor) &amp;#123;    super(initialCapacity, loadFactor);    accessOrder = false;&amp;#125;//指定初始化时的容量，和扩容的加载因子，以及迭代输出节点的顺序public LinkedHashMap(int initialCapacity,                     float loadFactor,                     boolean accessOrder) &amp;#123;    super(initialCapacity, loadFactor);    this.accessOrder = accessOrder;&amp;#125;//利用另一个Map 来构建public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) &amp;#123;    super();    accessOrder = false;    //该方法上文分析过，批量插入一个map中的所有数据到 本集合中。    putMapEntries(m, false);&amp;#125;</code></pre><h2 id="添加元素"><a class="header-anchor" href="#添加元素">¶</a>添加元素</h2><p>LinkedHashMap在添加元素的时候，依旧使用的是HashMap中的put方法。不同的是LinkedHashMap重写了newNode()方法在每次构建新节点时，通过linkNodeLast§;将新节点链接在内部双向链表的尾部。</p><pre><code class="language-java">//将新增的节点，连接在链表的尾部private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &amp;#123;    LinkedHashMap.Entry&lt;K,V&gt; last = tail;    tail = p;    //如果集合之前是空的    if (last == null)        head = p;    else &amp;#123;//将新节点连接在链表的尾部        p.before = last;        last.after = p;    &amp;#125;&amp;#125;</code></pre><h2 id="删除元素"><a class="header-anchor" href="#删除元素">¶</a>删除元素</h2><p>LinkedHashMap并没有重写HashMap的remove()方法，但是他重写了afterNodeRemoval()方法，这个方法的作用是在删除一个节点时，同步将该节点从双向链表中删除。该方法将会在remove中被回调。</p><pre><code class="language-java">//在删除节点e时，同步将e从双向链表上删除void afterNodeRemoval(Node&lt;K,V&gt; e) &amp;#123; // unlink    LinkedHashMap.Entry&lt;K,V&gt; p =        (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;    //将待删除节点 p 的前置后置节点都置空    p.before = p.after = null;    //如果前置节点是null，则说明现在的头结点应该是后置节点a    if (b == null)        head = a;    else//否则将前置节点b的后置节点指向a        b.after = a;    //同理如果后置节点时null ，则尾节点应是b    if (a == null)        tail = b;    else//否则更新后置节点a的前置节点为b        a.before = b;&amp;#125;</code></pre><p>删除过程总的来说可以分为三步：</p><ol><li>根据 hash 定位到桶位置</li><li>遍历链表或调用红黑树相关的删除方法</li><li>回调afterNodeRemoval，从 LinkedHashMap 维护的双链表中移除要删除的节点</li></ol><h2 id="更新元素"><a class="header-anchor" href="#更新元素">¶</a>更新元素</h2><pre><code class="language-java">// 清除节点时要将头尾节点一起清除 public void clear() &amp;#123;    super.clear();    head = tail = null;&amp;#125;</code></pre><h2 id="查找元素"><a class="header-anchor" href="#查找元素">¶</a>查找元素</h2><p>LinkedHashMap重写了get()和getOrDefault()方法<br>默认情况下，LinkedHashMap是按插入顺序维护链表。不过如果我们在初始化 LinkedHashMap时，指定 accessOrder参数为 true，即可让它按访问顺序维护链表。访问顺序的原理是，当我们调用get/getOrDefault/replace等方法时，会将这些方法访问的节点移动到链表的尾部。</p><pre><code class="language-java">public V get(Object key) &amp;#123;    Node&lt;K,V&gt; e;    if ((e = getNode(hash(key), key)) == null)        return null;    if (accessOrder)  // 回调afterNodeAccess(Node&lt;K,V&gt; e)        afterNodeAccess(e);  // 将节点e移至双向链表的尾部（保证迭代顺序）    return e.value;&amp;#125;public V getOrDefault(Object key, V defaultValue) &amp;#123;   Node&lt;K,V&gt; e;   if ((e = getNode(hash(key), key)) == null)       return defaultValue;   if (accessOrder)       afterNodeAccess(e);    // 作用同上   return e.value;&amp;#125;void afterNodeAccess(Node&lt;K,V&gt; e) &amp;#123; // move node to last    LinkedHashMap.Entry&lt;K,V&gt; last;//原尾节点    //如果accessOrder 是true ，且原尾节点不等于e    if (accessOrder &amp;&amp; (last = tail) != e) &amp;#123;        //节点e强转成双向链表节点p        LinkedHashMap.Entry&lt;K,V&gt; p =            (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;        //p现在是尾节点， 后置节点一定是null        p.after = null;        //如果p的前置节点是null，则p以前是头结点，所以更新现在的头结点是p的后置节点a        if (b == null)            head = a;        else//否则更新p的前直接点b的后置节点为 a            b.after = a;        //如果p的后置节点不是null，则更新后置节点a的前置节点为b        if (a != null)            a.before = b;        else//如果原本p的后置节点是null，则p就是尾节点。 此时 更新last的引用为 p的前置节点b            last = b;        if (last == null) //原本尾节点是null  则，链表中就一个节点            head = p;        else &amp;#123;//否则 更新 当前节点p的前置节点为 原尾节点last， last的后置节点是p            p.before = last;            last.after = p;        &amp;#125;        //尾节点的引用赋值成p        tail = p;        //修改modCount。        ++modCount;    &amp;#125;&amp;#125;// 因为LinkedHashMap中维护了一个双向链表所以相对于HashMap中的双重循环遍历这个方法要优化很多LinkedHashMappublic boolean containsValue(Object value) &amp;#123;         for (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != null; e = e.after) &amp;#123;   // 通过双向链表来遍历        V v = e.value;        if (v == value || (value != null &amp;&amp; value.equals(v)))            return true;    &amp;#125;    return false;&amp;#125;HashMappublic boolean containsValue(Object value) &amp;#123;    Node&lt;K,V&gt;[] tab; V v;    if ((tab = table) != null &amp;&amp; size &gt; 0) &amp;#123;        for (int i = 0; i &lt; tab.length; ++i) &amp;#123;            for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &amp;#123;                if ((v = e.value) == value ||                    (value != null &amp;&amp; value.equals(v)))                    return true;            &amp;#125;        &amp;#125;    &amp;#125;    return false;&amp;#125;</code></pre><h2 id="其他方法"><a class="header-anchor" href="#其他方法">¶</a>其他方法</h2><p>LinkedHashMap还有一个比较神奇的存在。</p><pre><code class="language-java">void afterNodeInsertion(boolean evict) &amp;#123; // possibly remove eldest    LinkedHashMap.Entry&lt;K,V&gt; first;    // 根据条件判断是否移除最近最少被访问的节点    if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &amp;#123;        K key = first.key;        removeNode(hash(key), key, null, false, true);    &amp;#125;&amp;#125;// 移除最近最少被访问条件之一，通过覆盖此方法可实现不同策略的缓存protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &amp;#123;    return false;&amp;#125;</code></pre><p>上面的方法一般不会被执行，但是当我们基于 LinkedHashMap 实现缓存时，通过覆写removeEldestEntry方法可以实现自定义策略的 LRU 缓存。比如我们可以根据节点数量判断是否移除最近最少被访问的节点，或者根据节点的存活时间判断是否移除该节点等。</p><h3 id="迭代器"><a class="header-anchor" href="#迭代器">¶</a>迭代器</h3><pre><code class="language-java">public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &amp;#123;        Set&lt;Map.Entry&lt;K,V&gt;&gt; es;        //返回LinkedEntrySet        return (es = entrySet) == null ? (entrySet = new LinkedEntrySet()) : es;    &amp;#125;    final class LinkedEntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &amp;#123;        public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &amp;#123;            return new LinkedEntryIterator();        &amp;#125;    &amp;#125;final class LinkedEntryIterator extends LinkedHashIterator        implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; &amp;#123;        public final Map.Entry&lt;K,V&gt; next() &amp;#123; return nextNode(); &amp;#125;    &amp;#125;    abstract class LinkedHashIterator &amp;#123;        //下一个节点        LinkedHashMap.Entry&lt;K,V&gt; next;        //当前节点        LinkedHashMap.Entry&lt;K,V&gt; current;        int expectedModCount;        LinkedHashIterator() &amp;#123;            //初始化时，next 为 LinkedHashMap内部维护的双向链表的扁头            next = head;            //记录当前modCount，以满足fail-fast            expectedModCount = modCount;            //当前节点为null            current = null;        &amp;#125;        //判断是否还有next        public final boolean hasNext() &amp;#123;            //就是判断next是否为null，默认next是head  表头            return next != null;        &amp;#125;        //nextNode() 就是迭代器里的next()方法 。        //该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。        final LinkedHashMap.Entry&lt;K,V&gt; nextNode() &amp;#123;            //记录要返回的e。            LinkedHashMap.Entry&lt;K,V&gt; e = next;            //判断fail-fast            if (modCount != expectedModCount)                throw new ConcurrentModificationException();            //如果要返回的节点是null，异常            if (e == null)                throw new NoSuchElementException();            //更新当前节点为e            current = e;            //更新下一个节点是e的后置节点            next = e.after;            //返回e            return e;        &amp;#125;        //删除方法 最终还是调用了HashMap的removeNode方法        public final void remove() &amp;#123;            Node&lt;K,V&gt; p = current;            if (p == null)                throw new IllegalStateException();            if (modCount != expectedModCount)                throw new ConcurrentModificationException();            current = null;            K key = p.key;            removeNode(hash(key), key, null, false, false);            expectedModCount = modCount;        &amp;#125;    &amp;#125;</code></pre><p>该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。而双链表节点的顺序在LinkedHashMap的增、删、改、查时都会更新。以满足按照插入顺序输出，还是访问顺序输出。</p><h2 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h2><p>在日常开发中LinkedHashMap 的使用频率没有HashMap高，但它也个重要的实现。<br>在 Java 集合框架中，HashMap、LinkedHashMap 和 TreeMap 三个映射类基于不同的数据结构，并实现了不同的功能。<br>HashMap 底层基于拉链式的散列结构，并在 JDK 1.8 中引入红黑树优化过长链表的问题。基于这样结构，HashMap 可提供高效的增删改查操作。<br>LinkedHashMap 在其之上，通过维护一条双向链表，实现了散列数据结构的有序遍历。<br>TreeMap 底层基于红黑树实现，利用红黑树的性质，实现了键值对排序功能。具体实现我们下次分析。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;LinkedHashMap继承自HashMap实现了Map接口。基本实现同HashMap一样，不同之处在于LinkedHashMap保证了迭代的有序性。其内部维护了一个双向链表，解决了 HashMap不能随时保持遍历顺序和插入顺序一致的问题。除此之外，LinkedHashMap对访问顺序也提供了相关支持。在一些场景下，该特性很有用，比如缓存。&lt;/p&gt;
&lt;p&gt;在实现上，LinkedHashMap很多方法直接继承自&lt;a href=&quot;../HashMapAnalysis&quot;&gt;HashMap&lt;/a&gt;，仅为维护双向链表覆写了部分方法。所以，要看懂 LinkedHashMap 的源码，需要先看懂 &lt;a href=&quot;../HashMapAnalysis&quot;&gt;HashMap&lt;/a&gt; 的源码。&lt;/p&gt;
&lt;p&gt;默认情况下，LinkedHashMap的迭代顺序是按照插入节点的顺序。也可以通过改变accessOrder参数的值，使得其遍历顺序按照访问顺序输出。&lt;/p&gt;
&lt;p&gt;这里我们只讨论LinkedHashMap和HashMap的不同之处，LinkedHashMap的其他操作和特性具体请参考&lt;a href=&quot;../HashMapAnalysis&quot;&gt;HashMap&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我们先来看下两者的区别：&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="集合" scheme="https://gyl-coder.top/tags/%E9%9B%86%E5%90%88/"/>
    
    <category term="LinkedHashMap" scheme="https://gyl-coder.top/tags/LinkedHashMap/"/>
    
  </entry>
  
  <entry>
    <title>LinkedList 底层实现原理分析</title>
    <link href="https://gyl-coder.top/java/collection/LinkedList/"/>
    <id>https://gyl-coder.top/java/collection/LinkedList/</id>
    <published>2020-07-03T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<ul><li>在Java.util包下</li><li>继承自AbstractSequentialList</li><li>实现 List 接口，能对它进行队列操作。</li><li>实现 Deque 接口，即能将LinkedList当作双端队列使用。</li><li>实现了Cloneable接口，即覆盖了函数clone()，能克隆。</li><li>实现java.io.Serializable接口，这意味着LinkedList支持序列化，能通过序列化去传输。</li><li>允许包含null值</li><li>迭代器可以快速报错</li><li>非线程安全的，如果在多线程中使用（修改），需要在外部作同步处理。</li></ul><p>LinkedList是一种可以在任何位置进行高效地插入和移除操作的有序序列，它是基于双向链表实现的。内部有三个变量，size表示链表中元素的个数， first指向链表头部，last指向链表尾部。 结构图如下图所示</p><a id="more"></a><div class="gallery ">              <p><img src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/collection2.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/collection2.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg" alt=""></p>            </div><p>下面是LinkedList中Node节点的定义，Node类是LinkedList的静态内部类。</p><pre><code class="language-java">private static class Node&lt;E&gt; &amp;#123;    E item;          // 当前节点所存数据    Node&lt;E&gt; next;    // 当前节点的下一个节点    Node&lt;E&gt; prev;    // 当前节点的前一个节点    Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &amp;#123;        this.item = element;        this.next = next;        this.prev = prev;    &amp;#125;&amp;#125;</code></pre><h2 id="构造方法（Construction-method）"><a class="header-anchor" href="#构造方法（Construction-method）">¶</a>构造方法（Construction method）</h2><p>LinkedList提供了两种种方式的构造器，构造一个空列表、以及构造一个包含指定collection的元素的列表，这些元素按照该collection的迭代器返回的顺序排列的。</p><pre><code class="language-java">public LinkedList() &amp;#123;&amp;#125;public LinkedList(Collection&lt;? extends E&gt; c) &amp;#123;    this();    addAll(c);   // 调用addAll方法，构建一个包含指定集合c的列表&amp;#125;</code></pre><h2 id="添加元素"><a class="header-anchor" href="#添加元素">¶</a>添加元素</h2><p>因为LinkedList即实现了List接口，又实现了Deque接口，所以LinkedList既可以添加将元素添加到尾部，也可以将元素添加到指定索引位置，还可以添加添加整个集合；另外既可以在头部添加，又可以在尾部添加。</p><pre><code class="language-java">//添加元素作为第一个元素public void addFirst(E e) &amp;#123;    linkFirst(e);&amp;#125;//店家元素作为最后一个元素public void addLast(E e) &amp;#123;    linkLast(e);&amp;#125;//使用对应参数作为第一个节点，内部使用private void linkFirst(E e) &amp;#123;    final Node&lt;E&gt; f = first;//得到首节点    final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f);//创建一个节点    first = newNode;        //更新首节点    if (f == null)        last = newNode;     //如果之前首节点为空(size==0)，那么尾节点就是首节点    else        f.prev = newNode;   //如果之前首节点不为空，之前的首节点的前一个节点为当前首节点    size++;                 //长度+1    modCount++;             //修改次数+1&amp;#125;//使用对应参数作为尾节点void linkLast(E e) &amp;#123;    final Node&lt;E&gt; l = last; //得到尾节点    final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null);//使用参数创建一个节点    last = newNode;         //设置尾节点    if (l == null)        first = newNode;    //如果之前尾节点为空(size==0)，首节点即尾节点    else        l.next = newNode;   //如果之前尾节点不为空，之前的尾节点的后一个就是当前的尾节点    size++;    modCount++;&amp;#125;//在非空节点succ之前插入元素E。void linkBefore(E e, Node&lt;E&gt; succ) &amp;#123;    final Node&lt;E&gt; pred = succ.prev;//获取前一个节点    final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ);//使用参数创建新的节点    succ.prev = newNode;//当前节点指向新的节点    if (pred == null)        first = newNode;//如果前一个节点为null，新的节点就是首节点    else        pred.next = newNode;//如果存在前节点，那么前节点的向后指向新节点    size++;    modCount++;&amp;#125;//添加指定集合的元素到列表，默认从最后开始添加public boolean addAll(Collection&lt;? extends E&gt; c) &amp;#123;    return addAll(size, c);//size表示最后一个位置&amp;#125;/*从指定位置（而不是下标！下标即索引从0开始，位置可以看做从1开始，其实也是0）后面添加指定集合的元素到列表中，只要有至少一次添加就会返回trueindex换成position应该会更好理解，所以也就是从索引为index(position)的元素的前面索引为index-1的后面添加！当然位置可以为0啊，为0的时候就是从位置0(虽然它不存在)后面开始添加嘛，所以理所当然就是添加到第一个位置（位置1的前面）的前面比如列表：0 1 2 3，如果此处index=4(实际索引为3)，就是在元素3后面添加；如果index=3(实际索引为2)，就在元素2后面添加。*/public boolean addAll(int index, Collection&lt;? extends E&gt; c) &amp;#123;    checkPositionIndex(index);  //检查索引是否正确（0&lt;=index&lt;=size）    Object[] a = c.toArray();   //得到元素数组    int numNew = a.length;      //得到元素个数    if (numNew == 0)            //若没有元素要添加，直接返回false        return false;    Node&lt;E&gt; pred, succ;    if (index == size) &amp;#123;    //如果是在末尾开始添加，当前节点后一个节点初始化为null，前一个节点为尾节点        succ = null;        //这里可以看做node(index)，不过index=size了（index最大只能是size-1），所以这里的succ只能=null，也方便后面判断        pred = last;            &amp;#125; else &amp;#123;                //如果不是从末尾开始添加，当前位置的节点为指定位置的节点，前一个节点为要添加的节点的前一个节点        succ = node(index); //添加好元素后(整个新加的)的后一个节点        pred = succ.prev;       &amp;#125;    //遍历数组并添加到列表中    for (Object o : a) &amp;#123;        @SuppressWarnings(&quot;unchecked&quot;) E e = (E) o;        Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null);//创建一个节点，向前指向上面得到的前节点        if (pred == null)            first = newNode;    //若当前节点为null，则新加的节点为首节点        else            pred.next = newNode;//如果存在前节点，前节点会向后指向新加的节点        pred = newNode;         //新加的节点成为前一个节点    &amp;#125;    if (succ == null) &amp;#123;        //pred.next = null  //加上这句也可以更好的理解        last = pred;        //如果是从最后开始添加的，则最后添加的节点成为尾节点    &amp;#125; else &amp;#123;        pred.next = succ;   //如果不是从最后开始添加的，则最后添加的节点向后指向之前得到的后续第一个节点        succ.prev = pred;   //当前，后续的第一个节点也应改为向前指向最后一个添加的节点    &amp;#125;    size += numNew;    modCount++;    return true;&amp;#125;//将指定的元素(E element)插入到列表的指定位置(index)public void add(int index, E element) &amp;#123;    checkPositionIndex(index); //index &gt;= 0 &amp;&amp; index &lt;= size    if (index == size)         linkLast(element); //尾插入    else        linkBefore(element, node(index));  //中间插入&amp;#125;</code></pre><p><strong>linkBefore的添加步骤：</strong></p><ol><li>创建newNode节点，将newNode的后继指针指向succ，前驱指针指向pred</li><li>将succ的前驱指针指向newNode</li><li>根据pred是否为null，进行不同操作。</li></ol><ul><li>如果pred为null，说明该节点插入在头节点之前，要重置first头节点</li><li>如果pred不为null，那么直接将pred的后继指针指向newNode即可</li></ul><p><strong>addAll的添加步骤：</strong></p><ol><li>检查index索引范围</li><li>得到集合数据</li><li>得到插入位置的前驱和后继节点</li><li>遍历数据，将数据插入到指定位置</li></ol><h2 id="删除元素"><a class="header-anchor" href="#删除元素">¶</a>删除元素</h2><p>同样的LinkedList也提供了很多方法来删除元素</p><pre><code class="language-java">// 删除首节点并返回删除前首节点的值，内部使用 (f == first &amp;&amp; f != null)private E unlinkFirst(Node&lt;E&gt; f) &amp;#123;    final E element = f.item;      // 获取首节点的值     final Node&lt;E&gt; next = f.next;   // 获取首节点的后一个节点    f.item = null;    f.next = null; // help GC    first = next;                 // 更新首节点    if (next == null)             //如果不存在下一个节点，则首尾都为null        last = null;    else        next.prev = null;        //如果存在下一个节点，那它的前指针为null    size--;    modCount++;    return element;&amp;#125;// 删除尾节点，并返回尾节点的元素 （assert l == last &amp;&amp; l != null）private E unlinkLast(Node&lt;E&gt; l) &amp;#123;    final E element = l.item;//获取尾节点的值    final Node&lt;E&gt; prev = l.prev;//获取尾节点前一个节点    l.item = null;    l.prev = null;   // help GC    last = prev;        //前一个节点成为新的尾节点    if (prev == null)        first = null;   //如果前一个节点不存在，则首尾都为null    else        prev.next = null;//如果前一个节点存在，先后指向null    size--;    modCount++;    return element;&amp;#125;// 删除指定节点x并返回节点的值（x != null）E unlink(Node&lt;E&gt; x) &amp;#123;    //获取当前值和前后节点    final E element = x.item;    final Node&lt;E&gt; next = x.next;    final Node&lt;E&gt; prev = x.prev;    if (prev == null) &amp;#123;        first = next;   //如果前一个节点为空(如当前节点为首节点)，后一个节点成为新的首节点    &amp;#125; else &amp;#123;        prev.next = next;//如果前一个节点不为空，那么他先后指向当前的下一个节点        x.prev = null;  //help  GC    &amp;#125;    if (next == null) &amp;#123;        last = prev;    //如果后一个节点为空(如当前节点为尾节点)，当前节点前一个成为新的尾节点    &amp;#125; else &amp;#123;        next.prev = prev;//如果后一个节点不为空，后一个节点向前指向当前的前一个节点        x.next = null;  //help  GC    &amp;#125;    x.item = null;   //help  GC    size--;    modCount++;    return element;&amp;#125;//删除第一个元素并返回删除的元素public E removeFirst() &amp;#123;    final Node&lt;E&gt; f = first;//得到第一个节点    if (f == null)          //如果为空，抛出异常        throw new NoSuchElementException();    return unlinkFirst(f);&amp;#125;//删除最后一个元素并返回删除的值public E removeLast() &amp;#123;    final Node&lt;E&gt; l = last;//得到最后一个节点    if (l == null)          //如果为空，抛出异常        throw new NoSuchElementException();    return unlinkLast(l);&amp;#125;</code></pre><h2 id="序列化方法"><a class="header-anchor" href="#序列化方法">¶</a>序列化方法</h2><pre><code class="language-java">private static final long serialVersionUID = 876323262645176354L;//序列化：将linkedList的“大小，所有的元素值”都写入到输出流中private void writeObject(java.io.ObjectOutputStream s)    throws java.io.IOException &amp;#123;    s.defaultWriteObject();    s.writeInt(size);    for (Node&lt;E&gt; x = first; x != null; x = x.next)        s.writeObject(x.item);&amp;#125;//反序列化：先将LinkedList的“大小”读出，然后将“所有的元素值”读出@SuppressWarnings(&quot;unchecked&quot;)private void readObject(java.io.ObjectInputStream s)    throws java.io.IOException, ClassNotFoundException &amp;#123;    s.defaultReadObject();    int size = s.readInt();    for (int i = 0; i &lt; size; i++)        linkLast((E)s.readObject());  //以尾插入的方式&amp;#125;</code></pre><h2 id="队列操作"><a class="header-anchor" href="#队列操作">¶</a>队列操作</h2><pre><code class="language-java">//提供普通队列和双向队列的功能，当然，也可以实现栈，FIFO，FILO//出队（从前端），获得第一个元素，不存在会返回null，不会删除元素（节点）public E peek() &amp;#123;    final Node&lt;E&gt; f = first;    return (f == null) ? null : f.item;&amp;#125;//出队（从前端），不删除元素，若为null会抛出异常而不是返回nullpublic E element() &amp;#123;    return getFirst();&amp;#125;//出队（从前端），如果不存在会返回null，存在的话会返回值并移除这个元素（节点）public E poll() &amp;#123;    final Node&lt;E&gt; f = first;    return (f == null) ? null : unlinkFirst(f);&amp;#125;//出队（从前端），如果不存在会抛出异常而不是返回null，存在的话会返回值并移除这个元素（节点）public E remove() &amp;#123;    return removeFirst();&amp;#125;//入队（从后端），始终返回truepublic boolean offer(E e) &amp;#123;    return add(e);&amp;#125;//入队（从前端），始终返回truepublic boolean offerFirst(E e) &amp;#123;    addFirst(e);    return true;&amp;#125;//入队（从后端），始终返回truepublic boolean offerLast(E e) &amp;#123;    addLast(e);//linkLast(e)    return true;&amp;#125;//出队（从前端），获得第一个元素，不存在会返回null，不会删除元素（节点）public E peekFirst() &amp;#123;    final Node&lt;E&gt; f = first;    return (f == null) ? null : f.item; &amp;#125;//出队（从后端），获得最后一个元素，不存在会返回null，不会删除元素（节点）public E peekLast() &amp;#123;    final Node&lt;E&gt; l = last;    return (l == null) ? null : l.item;&amp;#125;//出队（从前端），获得第一个元素，不存在会返回null，会删除元素（节点）public E pollFirst() &amp;#123;    final Node&lt;E&gt; f = first;    return (f == null) ? null : unlinkFirst(f);&amp;#125;//出队（从后端），获得最后一个元素，不存在会返回null，会删除元素（节点）public E pollLast() &amp;#123;    final Node&lt;E&gt; l = last;    return (l == null) ? null : unlinkLast(l);&amp;#125;//入栈，从前面添加public void push(E e) &amp;#123;    addFirst(e);&amp;#125;//出栈，返回栈顶元素，从前面移除（会删除）public E pop() &amp;#123;    return removeFirst();&amp;#125;</code></pre><h2 id="迭代器"><a class="header-anchor" href="#迭代器">¶</a>迭代器</h2><pre><code class="language-java">//返回迭代器public Iterator&lt;E&gt; descendingIterator() &amp;#123;    return new DescendingIterator();&amp;#125;//迭代器private class DescendingIterator implements Iterator&lt;E&gt; &amp;#123;    private final ListItr itr = new ListItr(size());    public boolean hasNext() &amp;#123;        return itr.hasPrevious();    &amp;#125;    public E next() &amp;#123;        return itr.previous();    &amp;#125;    public void remove() &amp;#123;        itr.remove();    &amp;#125;&amp;#125;public ListIterator&lt;E&gt; listIterator(int index) &amp;#123;        checkPositionIndex(index);        return new ListItr(index);&amp;#125;private class ListItr implements ListIterator&lt;E&gt; &amp;#123;    private Node&lt;E&gt; lastReturned;    private Node&lt;E&gt; next;    private int nextIndex;    private int expectedModCount = modCount;//保存当前modCount，确保fail-fast机制    ListItr(int index) &amp;#123;        next = (index == size) ? null : node(index);//得到当前索引指向的next节点        nextIndex = index;    &amp;#125;    public boolean hasNext() &amp;#123;   // 判断后面是否还有元素        return nextIndex &lt; size;    &amp;#125;        public E next() &amp;#123;     //获取下一个节点        checkForComodification();        if (!hasNext())            throw new NoSuchElementException();        lastReturned = next;        next = next.next;        nextIndex++;        return lastReturned.item;    &amp;#125;    public boolean hasPrevious() &amp;#123;        return nextIndex &gt; 0;    &amp;#125;    //获取前一个节点，将next节点向前移    public E previous() &amp;#123;        checkForComodification();        if (!hasPrevious())            throw new NoSuchElementException();        lastReturned = next = (next == null) ? last : next.prev;        nextIndex--;        return lastReturned.item;    &amp;#125;    public int nextIndex() &amp;#123;        return nextIndex;    &amp;#125;    public int previousIndex() &amp;#123;        return nextIndex - 1;    &amp;#125;    public void remove() &amp;#123;        checkForComodification();        if (lastReturned == null)            throw new IllegalStateException();        Node&lt;E&gt; lastNext = lastReturned.next;        unlink(lastReturned);        if (next == lastReturned)            next = lastNext;        else            nextIndex--;        lastReturned = null;        expectedModCount++;    &amp;#125;    public void set(E e) &amp;#123;        if (lastReturned == null)            throw new IllegalStateException();        checkForComodification();        lastReturned.item = e;    &amp;#125;    public void add(E e) &amp;#123;        checkForComodification();        lastReturned = null;        if (next == null)            linkLast(e);        else            linkBefore(e, next);        nextIndex++;        expectedModCount++;    &amp;#125;    public void forEachRemaining(Consumer&lt;? super E&gt; action) &amp;#123;        Objects.requireNonNull(action);        while (modCount == expectedModCount &amp;&amp; nextIndex &lt; size) &amp;#123;            action.accept(next.item);            lastReturned = next;            next = next.next;            nextIndex++;        &amp;#125;        checkForComodification();    &amp;#125;    final void checkForComodification() &amp;#123;        if (modCount != expectedModCount)            throw new ConcurrentModificationException();    &amp;#125;&amp;#125;</code></pre><p>在ListIterator的构造器中，得到了当前位置的节点，就是变量next。next()方法返回当前节点的值并将next指向其后继节点，previous()方法返回当前节点的前一个节点的值并将next节点指向其前驱节点。</p><p>由于Node是一个双向节点，所以这用了一个节点就可以实现从前向后迭代和从后向前迭代。另外在ListIterator初始时，exceptedModCount保存了当前的modCount，如果在迭代期间，有操作改变了链表的底层结构，那么再操作迭代器的方法时将会抛出ConcurrentModificationException。</p><h2 id="其他方法"><a class="header-anchor" href="#其他方法">¶</a>其他方法</h2><pre><code class="language-java">//获取第一个元素public E getFirst() &amp;#123;    final Node&lt;E&gt; f = first;//得到首节点    if (f == null)          //如果为空，抛出异常        throw new NoSuchElementException();    return f.item;&amp;#125;//获取最后一个元素public E getLast() &amp;#123;    final Node&lt;E&gt; l = last;//得到尾节点    if (l == null)          //如果为空，抛出异常        throw new NoSuchElementException();    return l.item;&amp;#125;//检查是否包含某个元素，返回boolpublic boolean contains(Object o) &amp;#123;    return indexOf(o) != -1;//返回指定元素的索引位置，不存在就返回-1，然后比较返回bool值&amp;#125;//返回列表长度public int size() &amp;#123;    return size;&amp;#125;//清空表public void clear() &amp;#123;     // help GC    for (Node&lt;E&gt; x = first; x != null; ) &amp;#123;        Node&lt;E&gt; next = x.next;        x.item = null;        x.next = null;        x.prev = null;        x = next;    &amp;#125;    first = last = null;    size = 0;    modCount++;&amp;#125;//获取指定索引的节点的值public E get(int index) &amp;#123;    checkElementIndex(index);    return node(index).item;&amp;#125;//修改指定索引的值并返回之前的值public E set(int index, E element) &amp;#123;    checkElementIndex(index);    // 检查下标是否合法    Node&lt;E&gt; x = node(index);    E oldVal = x.item;    x.item = element;    return oldVal;&amp;#125;//获取指定位置的节点Node&lt;E&gt; node(int index) &amp;#123;    if (index &lt; (size &gt;&gt; 1)) &amp;#123;//如果位置索引小于列表长度的一半(或一半减一)，从前面开始遍历；        Node&lt;E&gt; x = first;//index==0时不会循环，直接返回first        for (int i = 0; i &lt; index; i++)            x = x.next;        return x;    &amp;#125; else &amp;#123;                 // 否则，从后面开始遍历        Node&lt;E&gt; x = last;        for (int i = size - 1; i &gt; index; i--)            x = x.prev;        return x;    &amp;#125;&amp;#125;//获取指定元素从first开始的索引位置，不存在就返回-1//这里不能按条件双向找了，所以通常根据索引获得元素的速度比通过元素获得索引的速度快public int indexOf(Object o) &amp;#123;    int index = 0;    if (o == null) &amp;#123;        for (Node&lt;E&gt; x = first; x != null; x = x.next) &amp;#123;            if (x.item == null)                return index;            index++;        &amp;#125;    &amp;#125; else &amp;#123;        for (Node&lt;E&gt; x = first; x != null; x = x.next) &amp;#123;            if (o.equals(x.item))                return index;            index++;        &amp;#125;    &amp;#125;    return -1;&amp;#125;//获取指定元素从first开始最后出现的索引，不存在就返回-1//但实际查找是从last开始的public int lastIndexOf(Object o) &amp;#123;    int index = size;    if (o == null) &amp;#123;        for (Node&lt;E&gt; x = last; x != null; x = x.prev) &amp;#123;            index--;            if (x.item == null)                return index;        &amp;#125;    &amp;#125; else &amp;#123;        for (Node&lt;E&gt; x = last; x != null; x = x.prev) &amp;#123;            index--;            if (o.equals(x.item))                return index;        &amp;#125;    &amp;#125;    return -1;&amp;#125;//返回此 LinkedList实例的浅拷贝public Object clone() &amp;#123;    LinkedList&lt;E&gt; clone = superClone();    clone.first = clone.last = null;    clone.size = 0;    clone.modCount = 0;    for (Node&lt;E&gt; x = first; x != null; x = x.next)        clone.add(x.item);    return clone;&amp;#125;//返回一个包含LinkedList中所有元素值的数组public Object[] toArray() &amp;#123;    Object[] result = new Object[size];    int i = 0;    for (Node&lt;E&gt; x = first; x != null; x = x.next)        result[i++] = x.item;    return result;&amp;#125;//如果给定的参数数组长度足够，则将ArrayList中所有元素按序存放于参数数组中，并返回//如果给定的参数数组长度小于LinkedList的长度，则返回一个新分配的、长度等于LinkedList长度的、包含LinkedList中所有元素的新数组@SuppressWarnings(&quot;unchecked&quot;)public &lt;T&gt; T[] toArray(T[] a) &amp;#123;    if (a.length &lt; size)        a = (T[])java.lang.reflect.Array.newInstance(                            a.getClass().getComponentType(), size);    int i = 0;    Object[] result = a;    for (Node&lt;E&gt; x = first; x != null; x = x.next)        result[i++] = x.item;    if (a.length &gt; size)        a[size] = null;    return a;&amp;#125;</code></pre>]]></content>
    
    
    <summary type="html">&lt;ul&gt;
&lt;li&gt;在Java.util包下&lt;/li&gt;
&lt;li&gt;继承自AbstractSequentialList&lt;/li&gt;
&lt;li&gt;实现 List 接口，能对它进行队列操作。&lt;/li&gt;
&lt;li&gt;实现 Deque 接口，即能将LinkedList当作双端队列使用。&lt;/li&gt;
&lt;li&gt;实现了Cloneable接口，即覆盖了函数clone()，能克隆。&lt;/li&gt;
&lt;li&gt;实现java.io.Serializable接口，这意味着LinkedList支持序列化，能通过序列化去传输。&lt;/li&gt;
&lt;li&gt;允许包含null值&lt;/li&gt;
&lt;li&gt;迭代器可以快速报错&lt;/li&gt;
&lt;li&gt;非线程安全的，如果在多线程中使用（修改），需要在外部作同步处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;LinkedList是一种可以在任何位置进行高效地插入和移除操作的有序序列，它是基于双向链表实现的。内部有三个变量，size表示链表中元素的个数， first指向链表头部，last指向链表尾部。 结构图如下图所示&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="集合" scheme="https://gyl-coder.top/tags/%E9%9B%86%E5%90%88/"/>
    
    <category term="LinkedList" scheme="https://gyl-coder.top/tags/LinkedList/"/>
    
  </entry>
  
  <entry>
    <title>Vector 底层实现原理分析</title>
    <link href="https://gyl-coder.top/java/collection/Vector/"/>
    <id>https://gyl-coder.top/java/collection/Vector/</id>
    <published>2020-07-02T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<p><code>Vector</code>，一个可变长的数组，底层实现与 <a href="../ArrayList">ArrayList</a> 大同小异，但<code>Vector</code>是同步的（线程安全），<code>Vector</code>的很多方法之前都加了关键字<code>synchronized</code>，所以是线程安全的。</p><p>由于Vector的实现和ArrayList的实现大同小异，这里就不再逐一分析Vector中的方法，主要分析一下和ArrayList不同的方法。</p><p>首先我们还是来看以下Vector中定义的变量</p><a id="more"></a><pre><code class="language-java">public class Vector&lt;E&gt;    extends AbstractList&lt;E&gt;    implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&amp;#123;    protected Object[] elementData;      // 存储Vector中元素     protected int elementCount;          // Vector中的元素个数    protected int capacityIncrement;     // Vector的增长系数    private static final long serialVersionUID = -2767605614048989439L;     // Vector的序列版本号      private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;       // 能够分配元素数量的最大值&amp;#125;</code></pre><h2 id="构造方法"><a class="header-anchor" href="#构造方法">¶</a>构造方法</h2><p><code>Vector</code>有四个构造方法，其内部有两个重要的参数，一个是<code>elementCount</code>代表当前元素个数，一个是<code>capacityIncrement</code>代表当列表元素满了之后增加的容量。如果不设置<code>capacityIncrement</code>，那么<code>Vector</code>容量扩展时默认将扩展两倍，在<a href="../ArrayList">ArrayList源码分析</a>中，我们可以知道<code>ArrayList</code>在扩容时默认将扩展1.5倍。<br><code>ector</code>初始时容量为<strong>10</strong>，而<code>ArrayList</code>初始容量为<strong>0</strong>。</p><pre><code class="language-java">// Vector构造函数。默认容量是10。    public Vector() &amp;#123;        this(10);    &amp;#125;    // 指定Vector容量大小的构造函数    public Vector(int initialCapacity) &amp;#123;        this(initialCapacity, 0);    &amp;#125;    // 指定Vector&quot;容量大小&quot;和&quot;增长系数&quot;的构造函数    public Vector(int initialCapacity, int capacityIncrement) &amp;#123;        super();        if (initialCapacity &lt; 0)            throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+                                               initialCapacity);        // 新建一个数组，数组容量是initialCapacity        this.elementData = new Object[initialCapacity];        // 设置容量增长系数        this.capacityIncrement = capacityIncrement;    &amp;#125;    // 指定集合的Vector构造函数。    public Vector(Collection&lt;? extends E&gt; c) &amp;#123;        // 获取“集合(c)”的数组，并将其赋值给elementData        elementData = c.toArray();        // 设置数组长度        elementCount = elementData.length;        // c.toArray might (incorrectly) not return Object[] (see 6260652)        if (elementData.getClass() != Object[].class)            elementData = Arrays.copyOf(elementData, elementCount, Object[].class);    &amp;#125;</code></pre><p><code>Vector</code>中的构造器和<code>ArrayList</code>中的基本相同，只不过<code>Vector</code>中多了一个可以自定义增长系数的构造器<strong>public Vector(int initialCapacity, int capacityIncrement)</strong></p><h2 id="扩容机制"><a class="header-anchor" href="#扩容机制">¶</a>扩容机制</h2><p><code>Vector</code>中的添加元素和<code>ArrayList</code>中的大同小异，这里不再具体分析，这里只分析下Vector的扩容机制</p><pre><code class="language-java">/** * 增加vector容量 * 如果vector当前容量小于至少需要的容量，它的容量将增加。 * 新的容量将在旧的容量的基础上加上capacityIncrement，除非capacityIncrement小于等于0，在这种情况下，容量将会增加一倍。 * 增加后，如果新的容量还是小于至少需要的容量，那就将容量扩容至至少需要的容量。 */public synchronized void ensureCapacity(int minCapacity) &amp;#123;    if (minCapacity &gt; 0) &amp;#123;        modCount++;        ensureCapacityHelper(minCapacity);    &amp;#125;&amp;#125;/** * ensureCapacity()方法的unsynchronized实现。 * ensureCapacity()是同步的，它可以调用本方法来扩容，而不用承受同步带来的消耗 */private void ensureCapacityHelper(int minCapacity) &amp;#123;    // 如果至少需要的容量 &gt; 数组缓冲区当前的长度，就进行扩容    if (minCapacity - elementData.length &gt; 0)        grow(minCapacity);&amp;#125;/** * 分派给arrays的最大容量 * 为什么要减去8呢？ * 因为某些VM会在数组中保留一些头字，尝试分配这个最大存储容量，可能会导致array容量大于VM的limit，最终导致OutOfMemoryError。 */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/*** 扩容，保证vector至少能存储minCapacity个元素。* 首次扩容时，newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ?capacityIncrement : oldCapacity);即如果capacityIncrement&gt;0，就加capacityIncrement，如果不是就增加一倍。* 如果第一次扩容后，容量还是小于minCapacity，就直接将容量增为minCapacity。*/private void grow(int minCapacity) &amp;#123;    // 获取当前数组的容量    int oldCapacity = elementData.length;    //计算目标容量，如果指定了每次扩展的量，直接增加，如果没有就直接翻倍    int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ?                                     capacityIncrement : oldCapacity);    //如果自动扩容的容量无法满足用户指定的容量，则直接扩容到用户指定的容量    if (newCapacity - minCapacity &lt; 0)        newCapacity = minCapacity;    ///如果扩容后的容量大于临界值，则进行大容量分配    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)        newCapacity = hugeCapacity(minCapacity);    elementData = Arrays.copyOf(elementData, newCapacity);&amp;#125;// 进行大容量分配private static int hugeCapacity(int minCapacity) &amp;#123;    //数据溢出，抛出异常    if (minCapacity &lt; 0) // overflow        throw new OutOfMemoryError();    //如果想要的容量大于MAX_ARRAY_SIZE，则分配Integer.MAX_VALUE，否则分配MAX_ARRAY_SIZE    return (minCapacity &gt; MAX_ARRAY_SIZE) ?        Integer.MAX_VALUE :        MAX_ARRAY_SIZE;&amp;#125;</code></pre><h2 id="其他方法"><a class="header-anchor" href="#其他方法">¶</a>其他方法</h2><p><code>Vector</code>中添加一个枚举方法</p><pre><code class="language-java">// 返回一个枚举类型的对象public Enumeration&lt;E&gt; elements() &amp;#123;    return new Enumeration&lt;E&gt;() &amp;#123;        int count = 0;        public boolean hasMoreElements() &amp;#123;    // 判断后面是否还有数据            return count &lt; elementCount;        &amp;#125;        public E nextElement() &amp;#123;       // 返回一个数据            synchronized (Vector.this) &amp;#123;                if (count &lt; elementCount) &amp;#123;                    return elementData(count++);                &amp;#125;            &amp;#125;            throw new NoSuchElementException(&quot;Vector Enumeration&quot;);        &amp;#125;    &amp;#125;;&amp;#125;</code></pre><p>其他类同方法请参考<a href="../ArrayList">ArrayList源码分析</a><br><code>Vector</code>与<code>ArrayList</code>的最大区别就是<code>Vector</code>是线程安全的，而<code>ArrayList</code>不是线程安全的。另外区别还有：</p><ul><li><p><code>ArrayList</code>不可以设置扩展的容量，默认<strong>1.5</strong>倍；<code>Vector</code>可以设置扩展的容量，如果没有设置，默认<strong>2</strong>倍</p></li><li><p><code>ArrayList</code>的无参构造方法中初始容量为<strong>0</strong>，而<code>Vector</code>的无参构造方法中初始容量为<strong>10</strong>。</p></li></ul><p>下面我们再来分析下Vector的子类Stack方法。</p><h2 id="Stack"><a class="header-anchor" href="#Stack">¶</a>Stack</h2><p>Stack类代表最先进先出（LIFO）堆栈的对象。 它扩展了Vector五个操作，允许一个vector被视为堆栈。<br>五个方法分别是：</p><div class='checkbox'><input type="radio" />            <p>push() 添加元素到堆栈的顶部</p>            </div><div class='checkbox'><input type="radio" />            <p>pop() 删除堆栈顶部元素</p>            </div><div class='checkbox'><input type="radio" />            <p>peek() 查看堆栈顶部元素</p>            </div><div class='checkbox'><input type="radio" />            <p>empty() 判断堆栈是否为空</p>            </div><div class='checkbox'><input type="radio" />            <p>search() 返回元素所在位置</p>            </div><pre><code class="language-java">package java.util;publicclass Stack&lt;E&gt; extends Vector&lt;E&gt; &amp;#123;    /**     * Creates an empty Stack.     */    public Stack() &amp;#123;    &amp;#125;    public E push(E item) &amp;#123;        addElement(item);        // 调用vector中的方法在栈顶添加一个元素        return item;    &amp;#125;    public synchronized E pop() &amp;#123;        E       obj;        int     len = size();        obj = peek();        removeElementAt(len - 1);        // 调用vector中的方法删除栈顶的元素        return obj;    &amp;#125;    public synchronized E peek() &amp;#123;        int     len = size();        // 返回栈顶元素        if (len == 0)            throw new EmptyStackException();        return elementAt(len - 1);    &amp;#125;    public boolean empty() &amp;#123;        return size() == 0;    &amp;#125;    public synchronized int search(Object o) &amp;#123;        int i = lastIndexOf(o);        // 因为LIFO  所以选择从后往前遍历        if (i &gt;= 0) &amp;#123;            return size() - i;        &amp;#125;        return -1;    &amp;#125;    /** use serialVersionUID from JDK 1.0.2 for interoperability */    private static final long serialVersionUID = 1224463164541339165L;&amp;#125;</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;Vector&lt;/code&gt;，一个可变长的数组，底层实现与 &lt;a href=&quot;../ArrayList&quot;&gt;ArrayList&lt;/a&gt; 大同小异，但&lt;code&gt;Vector&lt;/code&gt;是同步的（线程安全），&lt;code&gt;Vector&lt;/code&gt;的很多方法之前都加了关键字&lt;code&gt;synchronized&lt;/code&gt;，所以是线程安全的。&lt;/p&gt;
&lt;p&gt;由于Vector的实现和ArrayList的实现大同小异，这里就不再逐一分析Vector中的方法，主要分析一下和ArrayList不同的方法。&lt;/p&gt;
&lt;p&gt;首先我们还是来看以下Vector中定义的变量&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="集合" scheme="https://gyl-coder.top/tags/%E9%9B%86%E5%90%88/"/>
    
    <category term="Vector" scheme="https://gyl-coder.top/tags/Vector/"/>
    
  </entry>
  
  <entry>
    <title>ArrayList动态扩容机制</title>
    <link href="https://gyl-coder.top/java/collection/ArrayList_grow/"/>
    <id>https://gyl-coder.top/java/collection/ArrayList_grow/</id>
    <published>2020-07-01T16:00:00.000Z</published>
    <updated>2020-09-28T14:57:05.367Z</updated>
    
    <content type="html"><![CDATA[<p>我们通过一个具体的例子看一下ArrayList的扩容效果<br>先看一下ArrayList的初始容量</p><pre><code class="language-java">ArrayList&lt;Integer&gt; array = new ArrayList&lt;&gt;();Integer capacity = getCapacity(array);int size = array.size();System.out.println(&quot;容量：&quot;+capacity);System.out.println(&quot;大小：&quot;+size);容量：0大小：0</code></pre><p>getCapacity（）方法是用来获取集合容量的，ArrayList通过一个elementData对象数组储存数据，也就是说ArrayList的容量就是该数组的长度。所以我们只要得到了elementData数组就可以知道ArrayList的实际容量。</p><a id="more"></a><p>由于elementData是私有的无法直接得到，但是我们可以通过<strong>反射</strong>的方式获取。</p><p>代码如下：</p><pre><code class="language-java">public static Integer getCapacity(ArrayList list) &amp;#123;    Integer length = null;    Class c = ((Object)list).getClass();    Field f;    try &amp;#123;        f = c.getDeclaredField(&quot;elementData&quot;);        f.setAccessible(true);                Object[] o = (Object[]) f.get(list);        length = o.length;    &amp;#125; catch (NoSuchFieldException ex) &amp;#123;        Logger.getLogger(CollectionDemo.class.getName()).log(Level.SEVERE, null, ex);    &amp;#125; catch (SecurityException ex) &amp;#123;        Logger.getLogger(CollectionDemo.class.getName()).log(Level.SEVERE, null, ex);    &amp;#125; catch (IllegalArgumentException ex) &amp;#123;        Logger.getLogger(CollectionDemo.class.getName()).log(Level.SEVERE, null, ex);    &amp;#125; catch (IllegalAccessException ex) &amp;#123;        Logger.getLogger(CollectionDemo.class.getName()).log(Level.SEVERE, null, ex);    &amp;#125;    return length;&amp;#125;</code></pre><p>接下来，我们向ArrayList中添加一个元素</p><pre><code class="language-java">ArrayList&lt;Integer&gt; array = new ArrayList&lt;&gt;();array.add(1);Integer capacity = getCapacity(array);int size = array.size();System.out.println(&quot;容量：&quot;+capacity);System.out.println(&quot;大小：&quot;+size);容量：10大小：1</code></pre><p>向ArrayList中添加11个元素</p><pre><code class="language-java">ArrayList&lt;Integer&gt; array = new ArrayList&lt;&gt;();for (int i = 0; i &lt; 11; i ++) &amp;#123;    array.add(i);&amp;#125;Integer capacity = getCapacity(array);int size = array.size();System.out.println(&quot;容量：&quot;+capacity);System.out.println(&quot;大小：&quot;+size);容量：15大小：11</code></pre><blockquote><p>我们发现，当向array中添加11个元素之后，array的容量扩大到原来的1.5倍。</p></blockquote><p><strong>Why does it expansion 1.5 times?</strong></p><p>具体为什么，下面我们看一下源码：</p><pre><code class="language-java">/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &amp;#123;@link Collection#add&amp;#125;) */public boolean add(E e) &amp;#123;    ensureCapacityInternal(size + 1);  // Increments modCount!!    elementData[size++] = e;    return true;&amp;#125;</code></pre><p>add方法是通过在array的尾部追加元素的方法，添加数据的。其中，调用ensureCapacityInternal方法用来判断是否需要扩容.</p><pre><code class="language-java">private void ensureCapacityInternal(int minCapacity) &amp;#123;    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &amp;#123;        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);    &amp;#125;    ensureExplicitCapacity(minCapacity);&amp;#125;private void ensureExplicitCapacity(int minCapacity) &amp;#123;    modCount++;     // overflow-conscious code    if (minCapacity - elementData.length &gt; 0)        grow(minCapacity);&amp;#125;</code></pre><p>参数传的是当前需要的最小容量，方法首先确认当前ArrayList实例是否为空，如果为空则比较所需容量和默认容量，取其较大值作为所需最小容量值。然后执行ensureExplicitCapacity进一步确定容量，以及是否需要扩容。当所需最小容量大于当前elementData数组长度时，要进行扩容操作。<br>modCount是fail fast机制，不了解也不影响，<a href="http://blog.csdn.net/badguy_gao/article/details/78989637">如果想了解可以看这里</a>,如果minCapacity的值大于添加数据之前的大小，就调用<strong>grow</strong>方法，进行扩容，否则什么也不做。</p><h3 id="发生扩容的条件"><a class="header-anchor" href="#发生扩容的条件">¶</a>发生扩容的条件</h3><p>根据传入的最小需要容量minCapacity来和数组的容量长度对比，若minCapactity大于或等于数组容量，则需要进行扩容。(如果实际存储数组是空数组，则最小需要容量就是默认容量)<br>以上只是真实容量和所需容量的比较，其目的是计算出array的最终容量。真正实现扩容的方法是grow方法。下面具体来了解扩容机制的增长规则</p><pre><code class="language-java">/** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */private void grow(int minCapacity) &amp;#123;    // overflow-conscious code    int oldCapacity = elementData.length;    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);    if (newCapacity - minCapacity &lt; 0)        newCapacity = minCapacity;    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)        newCapacity = hugeCapacity(minCapacity);    // minCapacity is usually close to size, so this is a win:    elementData = Arrays.copyOf(elementData, newCapacity);&amp;#125;</code></pre><p>这里传过来的minCapacity的值是array的size+1添加一个元素，首先计算当前的array所需最小的容量大小，判断是否需要扩容等。当需要扩容时：</p><ol><li>得到当前的ArrayList的容量(oldCapacity)。</li><li>计算除扩容后的新容量(newCapacity)，其值(oldCapacity + (oldCapacity &gt;&gt;1))约是oldCapacity 的1.5倍。</li><li>这里采用的是移位运算。为什么采用这种方法呢？应该是出于效率的考虑。</li><li>当newCapacity小于所需最小容量，那么将所需最小容量赋值给newCapacity。</li><li>newCapacity大于ArrayList的所允许的最大容量,处理。进行数据的复制，完成向ArrayList实例添加元素操作。</li></ol><div class="note "><p>每次array的size到达当前的容量最大值后，再插入数据就会造成扩容。</p></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们通过一个具体的例子看一下ArrayList的扩容效果&lt;br&gt;
先看一下ArrayList的初始容量&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;ArrayList&amp;lt;Integer&amp;gt; array = new ArrayList&amp;lt;&amp;gt;();
Integer capacity = getCapacity(array);
int size = array.size();
System.out.println(&amp;quot;容量：&amp;quot;+capacity);
System.out.println(&amp;quot;大小：&amp;quot;+size);
容量：0
大小：0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;getCapacity（）方法是用来获取集合容量的，ArrayList通过一个elementData对象数组储存数据，也就是说ArrayList的容量就是该数组的长度。所以我们只要得到了elementData数组就可以知道ArrayList的实际容量。&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="集合" scheme="https://gyl-coder.top/tags/%E9%9B%86%E5%90%88/"/>
    
    <category term="ArrayList" scheme="https://gyl-coder.top/tags/ArrayList/"/>
    
  </entry>
  
  <entry>
    <title>ArrayList 底层实现原理分析</title>
    <link href="https://gyl-coder.top/java/collection/ArrayList/"/>
    <id>https://gyl-coder.top/java/collection/ArrayList/</id>
    <published>2020-06-30T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.802Z</updated>
    
    <content type="html"><![CDATA[<p>ArrayList是List接口的 可变数组的实现。实现了所有可选列表操作，并允许包括 null 在内的所有元素。除了实现 List接口外，此类还提供一些方法来操作内部用来存储列表的数组的大小。ArrayList继承自 AbstractList，这是一个抽象类对一些基础的list操作做了一些封装.实现了RandomAccess 标记接口，表明可以实现快速随机访问.实现了Cloneable接口的实现表示该容器具有Clone函数操作，Serializable是序列化。</p><p>每个ArrayList实例都有一个容量，该容量是指用来存储列表元素的数组的大小。它总是至少等于列表的大小。随着向ArrayList中不断添加元素，其容量也自动增长。自动增长会带来数据向新数组的重新拷贝，因此，如果可预知数据量的大小，就可在构造ArrayList实例时指定其容量。</p><p>在添加大量元素前，应用程序也可以使用ensureCapacity操作来增加ArrayList实例的容量，这可以减少递增式再分配的数量。</p><p>注意，此实现不是同步的。如果多个线程同时访问一个ArrayList实例，而其中至少一个线程从结构上修改了列表，那么它必须保持外部同步。</p><blockquote><p>ArrayList这个数据结构比较简单，总体来说，ArrayList底层结构是数组，他的很多方法都是从数组上面演变而来的。</p></blockquote><p>下面我们先来看一下ArrayList中的一些初始值</p><a id="more"></a><pre><code class="language-java">//通过ArrayList实现的接口可知，其支持随机访问，能被克隆，支持序列化public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;        implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&amp;#123;    //序列版本号    private static final long serialVersionUID = 8683452581122892189L;  //默认初始容量    private static final int DEFAULT_CAPACITY = 10;    //空实例的共享空数组实例    private static final Object[] EMPTY_ELEMENTDATA = &amp;#123;&amp;#125;;    //被用于默认大小的空实例的共享数组实例。    //与EMPTY_ELEMENTDATA的区别是：当我们向数组中添加第一个元素时，知道数组该扩充多少。    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &amp;#123;&amp;#125;;    /**     * Object[]类型的数组，保存了添加到ArrayList中的元素。ArrayList的容量是该Object[]类型数组的长度     * 当第一个元素被添加时，任何空ArrayList中的elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA将会被     * 扩充到DEFAULT_CAPACITY（默认容量）。     */     transient Object[] elementData; //没有被私有化是为了简化内部类访问    // ArrayList的大小（指其所含的元素个数）    private int size;        // 记录被修改的次数      protected transient int modCount = 0;          // 数组的最大值      private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8  &amp;#125;</code></pre><p>elementData 是&quot;Object[] 类型的数组&quot;，它保存了添加到ArrayList中的元素。实际上，elementData是个动态数组，我们能通过构造函数 ArrayList(intinitialCapacity)来执行它的初始容量为initialCapacity；如果通过不含参数的构造函数ArrayList()来创建ArrayList，则elementData的容量默认是10。elementData数组的大小会根据ArrayList容量的增长而动态的增长。</p><h2 id="构造函数"><a class="header-anchor" href="#构造函数">¶</a>构造函数</h2><p>ArrayList提供了三种方式的构造器。可以构造一个默认初始容量为10的空列表、构造一个指定初始容量的空列表以及构造一个包含指定collection的元素的列表。</p><p>这些元素按照该collection的迭代器返回的顺序排列的。</p><pre><code class="language-java">// 构造一个指定初始容量的空列表public ArrayList(int initialCapacity) &amp;#123;    if (initialCapacity &gt; 0) &amp;#123;        this.elementData = new Object[initialCapacity];    &amp;#125; else if (initialCapacity == 0) &amp;#123;        this.elementData = EMPTY_ELEMENTDATA;    &amp;#125; else &amp;#123;              // 如果给定的初始容量为负值        throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+                                           initialCapacity);    &amp;#125;&amp;#125;// 构造一个默认初始容量为10的空列表public ArrayList() &amp;#123;   //这里并没有初始化，jdk 1.8之后是在进行add操作后初始化     this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&amp;#125;// 构造一个包含指定collection的元素的列表，这些元素按照该collection的迭代器返回的顺序排列的public ArrayList(Collection&lt;? extends E&gt; c) &amp;#123;    elementData = c.toArray();    if ((size = elementData.length) != 0) &amp;#123;         // c.toArray()可能不会正确地返回一个 Object[]数组，那么使用Arrays.copyOf()方法        if (elementData.getClass() != Object[].class)            elementData = Arrays.copyOf(elementData, size, Object[].class);    &amp;#125; else &amp;#123;     // 如果指定的collection为空        this.elementData = EMPTY_ELEMENTDATA;    &amp;#125;&amp;#125;</code></pre><p>使用无参构造器，默认初始容量为什么是10？</p><ol><li>初始时：this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};  size = 0;</li><li>向数组中添加第一个元素时，add(E e)方法中调用了ensureCapacityInternal(size + 1)方法，即ensureCapacityInternal(1)；</li><li>在ensureCapacityInternal(int minCapacity)方法中，minCapacity=DEFAULT_CAPACITY=10，然后再调用ensureExplicitCapacity(minCapacity)方法，即ensureExplicitCapacity(10)；</li><li>在ensureExplicitCapacity(minCapacity)方法中调用grow(minCapacity)方法，即grow(10)，此处为真正具体的数组扩容的算法，在此方法中，通过elementData = Arrays.copyOf(elementData, 10)具体实现了elementData数组初始容量为10的构造。</li></ol><h2 id="添加元素"><a class="header-anchor" href="#添加元素">¶</a>添加元素</h2><pre><code class="language-java">// 在数组末尾加上一个元素public boolean add(E e) &amp;#123;    ensureCapacityInternal(size + 1);  // 进行扩容检查    elementData[size++] = e;    return true;&amp;#125;// 在数组的指定位置添加元素public void add(int index, E element) &amp;#123;    rangeCheckForAdd(index);   // 检查index是否越界    ensureCapacityInternal(size + 1);  // 进行扩容检查        // 对数据进行复制操作，空出index位置，并插入element，将源数组中从index位置开始后的size-index个元素统一后移一位    System.arraycopy(elementData, index, elementData, index + 1, size - index);    elementData[index] = element;    size++;    // 元素个数加1&amp;#125;// 按照指定collection集合的迭代器所返回的元素顺序，将该collection中的所有元素添加到列表的尾部public boolean addAll(Collection&lt;? extends E&gt; c) &amp;#123;    Object[] a = c.toArray();      // 将collection转换为数组类型    int numNew = a.length;         // collection中的元素个数    ensureCapacityInternal(size + numNew);  // 进行扩容检查    System.arraycopy(a, 0, elementData, size, numNew);    // 将数组a[0,...,numNew-1]复制到数组elementData[size,...,size+numNew-1]    size += numNew;    return numNew != 0;&amp;#125;// 按照指定collection集合的迭代器所返回的元素顺序，将该collection中的所有元素添加到列表的指定位置public boolean addAll(int index, Collection&lt;? extends E&gt; c) &amp;#123;    rangeCheckForAdd(index);    // 检查index是否越界    Object[] a = c.toArray();    int numNew = a.length;    ensureCapacityInternal(size + numNew);  // 进行扩容检查    // 将数组elementData[index,...,index+numMoved-1]复制到elementData[index+numMoved,...,index+2*numMoved-1]    //将源数组中从index位置开始的后numMoved个元素统一后移numNew位    int numMoved = size - index;    if (numMoved &gt; 0)            System.arraycopy(elementData, index, elementData, index + numNew,                         numMoved);    // 将数组a[0,...,numNew-1]复制到数组elementData[index,...,index+numNew-1]完成数据的插入                         System.arraycopy(a, 0, elementData, index, numNew);    size += numNew;    return numNew != 0;&amp;#125;</code></pre><h2 id="扩容相关"><a class="header-anchor" href="#扩容相关">¶</a>扩容相关</h2><pre><code class="language-java">// 用于自定义设置ArrayList的容量public void ensureCapacity(int minCapacity) &amp;#123;    int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA)        ? 0        : DEFAULT_CAPACITY;    if (minCapacity &gt; minExpand) &amp;#123;        ensureExplicitCapacity(minCapacity);    &amp;#125;&amp;#125;// 进行扩容检查private void ensureCapacityInternal(int minCapacity) &amp;#123;    //第一次add操作初始化，如果为空ArrayList，那么初始化容量为10    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &amp;#123;        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);    &amp;#125;    //判断是否需要扩容    ensureExplicitCapacity(minCapacity);&amp;#125;//判断是否需要扩容private void ensureExplicitCapacity(int minCapacity) &amp;#123;    //modCount这个参数运用到了 fail-fast 机制    modCount++;        if (minCapacity - elementData.length &gt; 0)        grow(minCapacity);   // 扩容&amp;#125;// 扩容private void grow(int minCapacity) &amp;#123;    int oldCapacity = elementData.length;    //newCapacity为以前的1.5倍    int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);    if (newCapacity - minCapacity &lt; 0)        newCapacity = minCapacity;    //判断容量是否到达long int 最大临界值    if (newCapacity - MAX_ARRAY_SIZE &gt; 0)        newCapacity = hugeCapacity(minCapacity);    // 对数组进行复制处理    elementData = Arrays.copyOf(elementData, newCapacity);&amp;#125;// 检查是否超过最大容量 0x7fffffff ，是否抛出异常private static int hugeCapacity(int minCapacity) &amp;#123;    if (minCapacity &lt; 0) // overflow        throw new OutOfMemoryError();    return (minCapacity &gt; MAX_ARRAY_SIZE) ?        Integer.MAX_VALUE :        MAX_ARRAY_SIZE;&amp;#125;</code></pre><h2 id="删除元素"><a class="header-anchor" href="#删除元素">¶</a>删除元素</h2><pre><code class="language-java">// 删除指定位置的元素public E remove(int index) &amp;#123;    rangeCheck(index);    //数组越界检查    modCount++;    E oldValue = elementData(index);    int numMoved = size - index - 1;      //计算数组需要复制的数量    if (numMoved &gt; 0)   //将index后的数据都向前移一位        System.arraycopy(elementData, index+1, elementData, index,                         numMoved);    elementData[--size] = null;   //help  GC    return oldValue;&amp;#125;// 删除指定内容的元素（只删除第一个匹配成功的）public boolean remove(Object o) &amp;#123;    if (o == null) &amp;#123;        for (int index = 0; index &lt; size; index++)            if (elementData[index] == null) &amp;#123;                fastRemove(index);                return true;            &amp;#125;    &amp;#125; else &amp;#123;        for (int index = 0; index &lt; size; index++)            if (o.equals(elementData[index])) &amp;#123;                fastRemove(index);                return true;            &amp;#125;    &amp;#125;    return false;&amp;#125;//找到对应的元素后，删除。删除元素后的元素都向前移动一位private void fastRemove(int index) &amp;#123;    modCount++;    int numMoved = size - index - 1;    if (numMoved &gt; 0)     // 将index后面的元素整体向前移动一位        System.arraycopy(elementData, index+1, elementData, index,                         numMoved);    elementData[--size] = null; // help GC&amp;#125;//清空ArrayList，将全部的元素设为nullpublic void clear() &amp;#123;    modCount++;    for (int i = 0; i &lt; size; i++)    // help  GC        elementData[i] = null;    size = 0;&amp;#125;//删除ArrayList中从fromIndex到toIndex（区间--左闭右开）之间所有的元素protected void removeRange(int fromIndex, int toIndex) &amp;#123;    modCount++;    int numMoved = size - toIndex;  //需向前移动的元素的个数    System.arraycopy(elementData, toIndex, elementData, fromIndex,                     numMoved);    // help GC    int newSize = size - (toIndex-fromIndex);    for (int i = newSize; i &lt; size; i++) &amp;#123;        elementData[i] = null;    &amp;#125;    size = newSize;&amp;#125;//删除ArrayList中包含在指定容器c中的所有元素public boolean removeAll(Collection&lt;?&gt; c) &amp;#123;    Objects.requireNonNull(c);  //检查指定的对象c是否为空    return batchRemove(c, false);&amp;#125;//移除ArrayList中不包含在指定容器c中的所有元素，与removeAll(Collection&lt;?&gt; c)正好相反public boolean retainAll(Collection&lt;?&gt; c) &amp;#123;    Objects.requireNonNull(c);     //检查指定的对象c是否为空    return batchRemove(c, true);&amp;#125;// 根据complement的值删除元素private boolean batchRemove(Collection&lt;?&gt; c, boolean complement) &amp;#123;    final Object[] elementData = this.elementData;    int r = 0, w = 0;    //读写双指针  w是重新存元素时的索引，r是原来的索引    boolean modified = false;    try &amp;#123;        //遍历数组，并检查这个集合是否包含对应的值，移动要保留的值到数组前面，w最后值为要保留的元素的数量        //简单点：若保留，就将相同元素移动到前段；若删除，就将不同元素移动到前段        for (; r &lt; size; r++)            if (c.contains(elementData[r]) == complement)  //判断指定容器c中是否含有elementData[r]元素                elementData[w++] = elementData[r];    &amp;#125;finally &amp;#123;//确保异常抛出前的部分可以完成期望的操作，而未被遍历的部分会被接到后面        //r!=size表示可能出错了：c.contains(elementData[r])抛出异常        if (r != size) &amp;#123;            System.arraycopy(elementData, r,elementData, w,size - r);            w += size - r;        &amp;#125;        //如果w==size：表示全部元素都保留了，所以也就没有删除操作发生，所以会返回false；反之，返回true，并更改数组        //而w!=size的时候，即使try块抛出异常，也能正确处理异常抛出前的操作，因为w始终为要保留的前段部分的长度，数组也不会因此乱序        if (w != size) &amp;#123;            for (int i = w; i &lt; size; i++)                elementData[i] = null;            modCount += size - w;//改变的次数            size = w;   //新的大小为保留的元素的个数            modified = true;        &amp;#125;    &amp;#125;    return modified;&amp;#125;</code></pre><p>removeAll和retainAll方法：实现删除或保留ArrayList中包含Collection c中的的元素。</p><p>这两个方法都用到batchRemove方法（boolean complement使得batchRemove方法得到了重用）</p><p>下面以removeAll为例，分析batchRemove(c, false)<br>a. 遍历elementData<br>b. 如果集合c中包含elementData的元素e，即c.contains(elementData[r])为true，if不成立，if结束；如果c不包含elementData的元素e，则if成立，将此元素e赋值给elementData[w++] （即elementData保留了c中没有的元素，也就是删除了c中存在的所有元素。）<br>c. 执行finally<br>d. finally是不管try中结果如何都会执行的。if(r!=size)，则将elementData未参加比较的元素arraycopy到elementData后面；新索引w加上刚arraycopy的数目；if (w != size)，此时w还不等于size，则将w后的元素移除.只有执行了if (w != size)（事实上只要c中含有elementData的元素，w肯定不等于size），才令modified = true，才说明remove成功，返回true，否则返回false。</p><p>ArrayList中还有一个用于节约数组内存空间，缩小容量的方法</p><pre><code class="language-java">// 因为容量常常会大于实际元素的数量。内存紧张时，可以调用该方法删除预留的位置，调整容量为元素实际数量。// 如果确定不会再有元素添加进来时也可以调用该方法来节约空间public void trimToSize() &amp;#123;    modCount++;    // length是数组长度，size表示数组内元素个数      // size&lt;length那么就说明数组内有空元素，进行缩小容量操作      if (size &lt; elementData.length) &amp;#123;        elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size);    &amp;#125;&amp;#125;</code></pre><p>去掉预留元素的位置。返回一个新数组，新数组不含null，数组的size和elementData.length相等，以节省空间。此函数可避免size很小但elementData.length很大的情况。</p><p>ArrayList会每次增长会预申请多一点空间，1.5倍，这样就会出现当size() = 10的时候，ArrayList已经申请了15空间， trimToSize就是删除多余的5，只留10。</p><p>或许有人会有疑问：调用Arrays.copyOf复制size长度的元素到elementData，而且由源码看应该是从0复制到size处，那么如果我之前调用过add(int index, E element)呢？比如，list={1，2，3，null，null，4，null，null}，如果调用trimToSize返回的应该是list={1，2，3，null}（因为size=4）。其实上面这种情况不会发生的，因为调用add(int index, E element)时，会检查index的合法性，所以list的元素肯定是相邻的，而不会出现上述这种中间出现null的情况。</p><h2 id="修改元素"><a class="header-anchor" href="#修改元素">¶</a>修改元素</h2><pre><code class="language-java">// 将指定位置的元素改为指定的值 public E set(int index, E element) &amp;#123;    rangeCheck(index);    // 检查index是否越界    E oldValue = elementData(index);    elementData[index] = element;    return oldValue;&amp;#125;</code></pre><h2 id="查找元素"><a class="header-anchor" href="#查找元素">¶</a>查找元素</h2><pre><code class="language-java">//判断ArrayList中是否包含Object(o)public boolean contains(Object o) &amp;#123;    return indexOf(o) &gt;= 0;&amp;#125;//返回一个值在数组首次出现的位置，会根据是否为null使用不同方式判断。不存在就返回-1。时间复杂度为O(N)public int indexOf(Object o) &amp;#123;    if (o == null) &amp;#123;        for (int i = 0; i &lt; size; i++)                             if (elementData[i]==null)                return i;    &amp;#125; else &amp;#123;        for (int i = 0; i &lt; size; i++)            if (o.equals(elementData[i]))                return i;    &amp;#125;    return -1;&amp;#125;//返回一个值在数组最后一次出现的位置，不存在就返回-1。时间复杂度为O(N)public int lastIndexOf(Object o) &amp;#123;    if (o == null) &amp;#123;        for (int i = size-1; i &gt;= 0; i--)            if (elementData[i]==null)                return i;    &amp;#125; else &amp;#123;        for (int i = size-1; i &gt;= 0; i--)            if (o.equals(elementData[i]))                return i;    &amp;#125;    return -1;&amp;#125;//返回指定位置的值，因为是数组，所以速度特别快@SuppressWarnings(&quot;unchecked&quot;)E elementData(int index) &amp;#123;    return (E) elementData[index];&amp;#125;//返回指定位置的值，但是会检查这个位置数否超出数组长度public E get(int index) &amp;#123;    rangeCheck(index);    return elementData(index); //实质上return (E) elementData[index]&amp;#125;</code></pre><h2 id="序列化"><a class="header-anchor" href="#序列化">¶</a>序列化</h2><pre><code class="language-java">//保存数组实例的状态到一个流（即它序列化）。写入过程数组被更改会抛出异常private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&amp;#123;    int expectedModCount = modCount;    s.defaultWriteObject(); //执行默认的反序列化/序列化过程。将当前类的非静态和非瞬态字段写入此流    // 写入大小    s.writeInt(size);    // 按顺序写入所有元素    for (int i=0; i&lt;size; i++) &amp;#123;        s.writeObject(elementData[i]);    &amp;#125;    if (modCount != expectedModCount) &amp;#123;        throw new ConcurrentModificationException();    &amp;#125;&amp;#125;//上面是写，这个就是读了。private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &amp;#123;    elementData = EMPTY_ELEMENTDATA;    // 执行默认的序列化/反序列化过程    s.defaultReadObject();    // 读入数组长度    s.readInt();    if (size &gt; 0) &amp;#123;        ensureCapacityInternal(size);        Object[] a = elementData;        //读入所有元素        for (int i=0; i&lt;size; i++) &amp;#123;            a[i] = s.readObject();        &amp;#125;    &amp;#125;&amp;#125;</code></pre><p><strong>为什么要自定义序列化、反序列化机制呢？</strong></p><p>保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。</p><pre><code class="language-java">transient Object[] elementData; // non-private to simplify nested class access</code></pre><p>由于ArrayList实质上是一个动态数组，往往数组中会有空余的空间，如果采用默认的序列化机制，那些空余的空间会作为null写入本地文件或者在网络中传输，耗费了不必要的资源。所以，ArrayList使用自定义序列化机制，仅写入索引为【0，size）的有效元素以节省资源</p><p>序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。</p><pre><code class="language-java">ArrayList list = new ArrayList();ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(file));oos.writeObject(list);</code></pre><h2 id="迭代器"><a class="header-anchor" href="#迭代器">¶</a>迭代器</h2><pre><code class="language-java">//返回ListIterator，开始位置为指定参数public ListIterator&lt;E&gt; listIterator(int index) &amp;#123;    if (index &lt; 0 || index &gt; size)        throw new IndexOutOfBoundsException(&quot;Index: &quot;+index);    return new ListItr(index);&amp;#125;//返回ListIterator，开始位置为0public ListIterator&lt;E&gt; listIterator() &amp;#123;    return new ListItr(0);&amp;#125;//返回普通迭代器public Iterator&lt;E&gt; iterator() &amp;#123;    return new Itr();&amp;#125;//通用的迭代器实现private class Itr implements Iterator&lt;E&gt; &amp;#123;    int cursor;       //游标，下一个元素的索引，默认初始化为0    int lastRet = -1; //上次访问的元素的位置    int expectedModCount = modCount;//迭代过程不允许修改数组，否则就抛出异常    //是否还有下一个    public boolean hasNext() &amp;#123;        return cursor != size;    &amp;#125;    //下一个元素    @SuppressWarnings(&quot;unchecked&quot;)    public E next() &amp;#123;        checkForComodification();//检查数组是否被修改        int i = cursor;        if (i &gt;= size)            throw new NoSuchElementException();        Object[] elementData = ArrayList.this.elementData;        if (i &gt;= elementData.length)            throw new ConcurrentModificationException();        cursor = i + 1; //向后移动游标        return (E) elementData[lastRet = i];    //设置访问的位置并返回这个值    &amp;#125;    //删除元素    public void remove() &amp;#123;        if (lastRet &lt; 0)            throw new IllegalStateException();        checkForComodification();//检查数组是否被修改        try &amp;#123;            ArrayList.this.remove(lastRet);            cursor = lastRet;            lastRet = -1;            expectedModCount = modCount;        &amp;#125; catch (IndexOutOfBoundsException ex) &amp;#123;            throw new ConcurrentModificationException();        &amp;#125;    &amp;#125;    @Override    @SuppressWarnings(&quot;unchecked&quot;)    public void forEachRemaining(Consumer&lt;? super E&gt; consumer) &amp;#123;        Objects.requireNonNull(consumer);        final int size = ArrayList.this.size;        int i = cursor;        if (i &gt;= size) &amp;#123;            return;        &amp;#125;        final Object[] elementData = ArrayList.this.elementData;        if (i &gt;= elementData.length) &amp;#123;            throw new ConcurrentModificationException();        &amp;#125;        while (i != size &amp;&amp; modCount == expectedModCount) &amp;#123;            consumer.accept((E) elementData[i++]);        &amp;#125;        cursor = i;        lastRet = i - 1;        checkForComodification();    &amp;#125;    //检查数组是否被修改    final void checkForComodification() &amp;#123;        if (modCount != expectedModCount)            throw new ConcurrentModificationException();    &amp;#125;&amp;#125;//ListIterator迭代器实现private class ListItr extends Itr implements ListIterator&lt;E&gt; &amp;#123;    ListItr(int index) &amp;#123;        super();        cursor = index;    &amp;#125;    public boolean hasPrevious() &amp;#123;        return cursor != 0;    &amp;#125;    public int nextIndex() &amp;#123;        return cursor;    &amp;#125;    public int previousIndex() &amp;#123;        return cursor - 1;    &amp;#125;    @SuppressWarnings(&quot;unchecked&quot;)    public E previous() &amp;#123;        checkForComodification();        int i = cursor - 1;        if (i &lt; 0)            throw new NoSuchElementException();        Object[] elementData = ArrayList.this.elementData;        if (i &gt;= elementData.length)            throw new ConcurrentModificationException();        cursor = i;        return (E) elementData[lastRet = i];    &amp;#125;    public void set(E e) &amp;#123;        if (lastRet &lt; 0)            throw new IllegalStateException();        checkForComodification();        try &amp;#123;            ArrayList.this.set(lastRet, e);        &amp;#125; catch (IndexOutOfBoundsException ex) &amp;#123;            throw new ConcurrentModificationException();        &amp;#125;    &amp;#125;    public void add(E e) &amp;#123;        checkForComodification();        try &amp;#123;            int i = cursor;            ArrayList.this.add(i, e);            cursor = i + 1;            lastRet = -1;            expectedModCount = modCount;        &amp;#125; catch (IndexOutOfBoundsException ex) &amp;#123;            throw new ConcurrentModificationException();        &amp;#125;    &amp;#125;&amp;#125;</code></pre><p><strong>Iterator与ListIterator的区别：</strong></p><ol><li>Iterator可以应用于所有的集合，Set、List和Map和这些集合的子类型。而ListIterator只能用于List及其子类型；</li><li>Iterator只能实现顺序向后遍历，ListIterator可实现顺序向后遍历和逆向（顺序向前）遍历；</li><li>Iterator只能实现remove操作，ListIterator可以实现remove操作，add操作，set操作。</li></ol><h2 id="其他方法"><a class="header-anchor" href="#其他方法">¶</a>其他方法</h2><pre><code class="language-java">//返回ArrayList的大小（元素个数）public int size() &amp;#123;    return size;&amp;#125;//判断ArrayList是否为空public boolean isEmpty() &amp;#123;    return size == 0;&amp;#125;//返回此 ArrayList实例的浅拷贝（元素本身没有被复制，复制过程数组发生改变会抛出异常）public Object clone() &amp;#123;    try &amp;#123;        ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) super.clone();        v.elementData = Arrays.copyOf(elementData, size);        v.modCount = 0;        return v;    &amp;#125; catch (CloneNotSupportedException e) &amp;#123;        throw new InternalError(e);    &amp;#125;&amp;#125;/*浅克隆就是我们所看到的Arrays.copyOf， System.arraycopy，数组是新的，但是里面N个元素全是引用的旧的。浅拷贝(影子克隆):只复制基本类型。深拷贝(深度克隆):基本类+对象。*///返回一个包含ArrayList中所有元素的数组public Object[] toArray() &amp;#123;    return Arrays.copyOf(elementData, size);&amp;#125;// 返回一个数组，使用运行时确定类型，该数组包含在这个列表中的所有元素（从第一到最后一个元素）// 返回的数组容量由参数和本数组中较大值确定@SuppressWarnings(&quot;unchecked&quot;)public &lt;T&gt; T[] toArray(T[] a) &amp;#123;    if (a.length &lt; size)        // Make a new array of a's runtime type, but my contents:        return (T[]) Arrays.copyOf(elementData, size, a.getClass());    System.arraycopy(elementData, 0, a, 0, size);    if (a.length &gt; size)        a[size] = null;    return a;&amp;#125;</code></pre><h2 id="ArrayList相关问题"><a class="header-anchor" href="#ArrayList相关问题">¶</a>ArrayList相关问题</h2><h3 id="Integer-MAX-VALUE-8-这里为什么要减去8？"><a class="header-anchor" href="#Integer-MAX-VALUE-8-这里为什么要减去8？">¶</a>Integer.MAX_VALUE - 8  这里为什么要减去8？</h3><p>主要是考虑到不同的JVM,有的VM会在加入一些数据头,当扩容后的容量大于MAX_ARRAY_SIZE,我们会将最小需要容量和MAX_ARRAY_SIZE做比较,如果比它大, 只能取Integer.MAX_VALUE,否则是Integer.MAX_VALUE -8。<strong>这个是从jdk1.7开始才有的</strong></p><h3 id="jdk1-8的无参构造函数和之前版本的构造函数有什么区别"><a class="header-anchor" href="#jdk1-8的无参构造函数和之前版本的构造函数有什么区别">¶</a>jdk1.8的无参构造函数和之前版本的构造函数有什么区别?</h3><pre><code class="language-java">jdk1.6public ArrayList() &amp;#123;        this(10);    &amp;#125; jdk1.7public ArrayList() &amp;#123;        super();        this.elementData = EMPTY_ELEMENTDATA;    &amp;#125;jdk1.8public ArrayList() &amp;#123;        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;    &amp;#125;</code></pre><p>对比下可以看出：jdk1.6的无参构造方法（默认构造方法）构造的ArrayList的底层数组elementData大小（容量）默认为10；从1.7开始，无参构造方法构造的ArrayList的底层数组elementData大小默认为0。</p><p>java集合类在jdk1.7版本基本上都有一种改动：懒初始化。懒初始化指的是默认构造方法构造的集合类，占据尽可能少的内存空间（对于ArrayList来说，使用空数组来占据尽量少的空间，不使用null是为了避免null判断），在第一次进行包含有添加语义的操作时，才进行真正的<strong>初始化</strong>工作。</p><p>1.7开始的ArrayList，默认构造方法构造的实例，底层数组是空数组，容量为0，在进行第一次add/addAll等操作时才会真正给底层数组赋非empty的值。如果add/addAll添加的元素小于10，则把elementData数组扩容为10个元素大小，否则使用刚好合适的大小（例如，第一次addAll添加6个，那么扩容为10个，第一次添加大于10个的，比如24个，扩容为24个，刚好合适）</p><p>1.8版本，默认构造的实例这个行为没有改变，只是用的数组名字变了。</p><h3 id="jdk1-6中扩容算法的缺陷"><a class="header-anchor" href="#jdk1-6中扩容算法的缺陷">¶</a>jdk1.6中扩容算法的缺陷</h3><p>（由于jdk1.7和jdk1.8在扩容算法方面差别不大，所以下面没有严格区分）</p><pre><code class="language-java">jdk1.6public void ensureCapacity(int minCapacity) &amp;#123;      modCount++;      int oldCapacity = elementData.length;      if (minCapacity &gt; oldCapacity) &amp;#123;          Object oldData[] = elementData;          int newCapacity = (oldCapacity * 3)/2 + 1;          if (newCapacity &lt; minCapacity)              newCapacity = minCapacity;          // minCapacity is usually close to size, so this is a win:          elementData = Arrays.copyOf(elementData, newCapacity);      &amp;#125;  &amp;#125;</code></pre><p>从上面的代码可以看出jdk1.6的ensureCapacity方法只是简单进行了逻辑上的操作，没有过多考虑int型溢出的问题，从1.7开始对这个进行了完善。</p><p>而且没考虑入参minCapacity可能因为int溢出变为负数。这个方法可以外部手动调用，手动扩容传入负数这个肯定是应该拦截掉的。但是自动扩容会因为int溢出产生负数，碰到这种情况时应该特殊处理，而不是什么都不做，等着后面抛出一个ArrayIndexOutOfBoundsException。</p><p>还有就是下面这句代码会造成过早溢出</p><pre><code class="language-java">int newCapacity = (oldCapacity * 3)/2 + 1;</code></pre><p>虽然上面这行代码和1.7开始的oldCapacity + (oldCapacity &gt;&gt; 1) 差不多，都是相当于1.5倍，但实际上是有区别的。</p><p><strong>这里主要有两个区别</strong></p><p><strong>第一个区别</strong>是jdk1.6的乘除运算的数学结果比后面一个大1比如oldCapacity=10，1.6的算法得到16，1.7开始的算法得到15，这个影响不大；</p><p><strong>第二个区别</strong>就是两者在数字比较大时运算结果不一样，比如oldCapacity=10^9，这个数和Integer.MAX_VALUE位数一样，用1.6的算法得到的会是错误的-647483647，用1.7的则是正确的1500000000，这时候明明可以1.5倍扩容，但是jdk1.6却用的是按需扩容。</p><p>ensureCapacity（称之为手动，是因为此方法是public的，可以外部手动调用）。在1.6版本是只有这个手动的方法，内部自动操作也是调用这个方法，1.7开始进行了区分，并且进一步改进了扩容操作。</p><ul><li><p>从1.7开始将内部扩容和外部可以调用的扩容方法分开了，通过源码可以看出：外部调用的手动扩容方法ensureCapacity要多一个判断条件 minCapacity &gt;  minExpand，这个判断条件拦截掉负数的minCapacity，这样调用内部扩容ensureCapacityInternal方法时，minCapacity一定是正数；内部扩容方法直接就用minCapacity - elementData.length &gt; 0判断，此条件可以检测出int型溢出，碰到溢出最后会抛出一个OOM错误。jdk1.7用OOM，这比jdk1.6用ArrayIndexOutOfBoundsException更好，因为此时数组大小超出了虚拟机对数组的限制，虚拟机无法处理这种情况了，抛出一个ERROR是合理的。</p></li><li><p>使用这行代码</p></li></ul><pre><code class="language-java">newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);</code></pre><p>这行代码不仅仅是使用位运算加快执行速度，上面说了，这种做法才是对的，是真正的1.5倍。不仅仅因为那一个大小的差别，更重要的是避免过早出现int溢出的情况，保证了内部自动扩容会尽量按规定的策略执行。同时整个扩容处理流程中多增加了几处if判断，对各种情况处理更加完善。</p><h3 id="为什么ArrayList自动容量扩充选择扩充1-5倍？"><a class="header-anchor" href="#为什么ArrayList自动容量扩充选择扩充1-5倍？">¶</a>为什么ArrayList自动容量扩充选择扩充1.5倍？</h3><p>这种算法构造出来的新的数组长度的增量都会比上一次大( 而且是越来越大) ，避免频繁newInstance 的情况。</p><h3 id="为什么ArrayList-不适合频繁插入和删除操作？"><a class="header-anchor" href="#为什么ArrayList-不适合频繁插入和删除操作？">¶</a>为什么ArrayList 不适合频繁插入和删除操作？</h3><p>由上面分析的增加删除方法可以看出在ArrayList中经常会调用 System.arraycopy 这个效率很低的操作来复制数组，所以导致ArrayList在插入和删除操作中效率不高。</p><h3 id="RandomAccess接口"><a class="header-anchor" href="#RandomAccess接口">¶</a>RandomAccess接口</h3><pre><code class="language-java">public interface RandomAccess &amp;#123;&amp;#125;</code></pre><p>查看源码我们发现实际上 <code>RandomAccess</code> 接口中什么都没有定义。所以，在我看来 <code>RandomAccess</code> 接口不过是一个标识罢了。标识什么？ 标识实现这个接口的类具有随机访问功能。</p><p>在 <code>binarySearch（)</code> 方法中，它要判断传入的 list 是否 <code>RamdomAccess</code> 的实例，如果是，调用<code>indexedBinarySearch()</code>方法，如果不是，那么调用<code>iteratorBinarySearch()</code>方法</p><pre><code class="language-java">    public static &lt;T&gt;    int binarySearch(List&lt;? extends Comparable&lt;? super T&gt;&gt; list, T key) &amp;#123;        if (list instanceof RandomAccess || list.size()&lt;BINARYSEARCH_THRESHOLD)            return Collections.indexedBinarySearch(list, key);        else            return Collections.iteratorBinarySearch(list, key);    &amp;#125;</code></pre><p><code>ArrayList</code> 实现了 <code>RandomAccess</code> 接口， 而 <code>LinkedList</code> 没有实现。为什么呢？我觉得还是和底层数据结构有关！<code>ArrayList</code> 底层是数组，而 <code>LinkedList</code> 底层是链表。数组天然支持随机访问，时间复杂度为 O(1)，所以称为快速随机访问。链表需要遍历到特定位置才能访问特定位置的元素，时间复杂度为 O(n)，所以不支持快速随机访问。，<code>ArrayList</code> 实现了 <code>RandomAccess</code> 接口，就表明了他具有快速随机访问功能。 <code>RandomAccess</code> 接口只是标识，并不是说 <code>ArrayList</code> 实现 <code>RandomAccess</code> 接口才具有快速随机访问功能的！</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;ArrayList是List接口的 可变数组的实现。实现了所有可选列表操作，并允许包括 null 在内的所有元素。除了实现 List接口外，此类还提供一些方法来操作内部用来存储列表的数组的大小。ArrayList继承自 AbstractList，这是一个抽象类对一些基础的list操作做了一些封装.实现了RandomAccess 标记接口，表明可以实现快速随机访问.实现了Cloneable接口的实现表示该容器具有Clone函数操作，Serializable是序列化。&lt;/p&gt;
&lt;p&gt;每个ArrayList实例都有一个容量，该容量是指用来存储列表元素的数组的大小。它总是至少等于列表的大小。随着向ArrayList中不断添加元素，其容量也自动增长。自动增长会带来数据向新数组的重新拷贝，因此，如果可预知数据量的大小，就可在构造ArrayList实例时指定其容量。&lt;/p&gt;
&lt;p&gt;在添加大量元素前，应用程序也可以使用ensureCapacity操作来增加ArrayList实例的容量，这可以减少递增式再分配的数量。&lt;/p&gt;
&lt;p&gt;注意，此实现不是同步的。如果多个线程同时访问一个ArrayList实例，而其中至少一个线程从结构上修改了列表，那么它必须保持外部同步。&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;ArrayList这个数据结构比较简单，总体来说，ArrayList底层结构是数组，他的很多方法都是从数组上面演变而来的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面我们先来看一下ArrayList中的一些初始值&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="集合" scheme="https://gyl-coder.top/tags/%E9%9B%86%E5%90%88/"/>
    
    <category term="ArrayList" scheme="https://gyl-coder.top/tags/ArrayList/"/>
    
  </entry>
  
  <entry>
    <title>try catch finally执行顺序</title>
    <link href="https://gyl-coder.top/java/try_catch_finally/"/>
    <id>https://gyl-coder.top/java/try_catch_finally/</id>
    <published>2020-04-02T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<p>首先在finally和try中对数据的操作时数据分为 基本数据类型和引用数据类型，他们存放的地方也不一样，一个是栈区另一个是在堆区。</p><a id="more"></a><h3 id="finally中没有return"><a class="header-anchor" href="#finally中没有return">¶</a>finally中没有return</h3><pre><code class="language-java">public class Main &amp;#123;    private  static  int a=2;     public static void main(String[] args) &amp;#123;         System.out.println(&quot;test输出的结果 &quot;+test());        System.out.println(&quot;main 自加后 a=&quot;+(a++));    &amp;#125;        private  static  int test()&amp;#123;        try &amp;#123;            a+=3;            System.out.println(&quot;try  a=&quot;+a);            return a;        &amp;#125;catch (Exception e)&amp;#123;         &amp;#125;finally &amp;#123;            ++a;            System.out.println(&quot;finally a=&quot;+a);        &amp;#125;    &amp;#125;</code></pre><p>输出结果:</p><p>try  a=5<br>finally a=6<br>test输出的结果 5<br>main a=6</p><p>结论: 可见方法test的返回值不受finally中的影响，但是变量a还是受到了影响，值改变了，返回值是存放在栈中的，return是就           已经把返回值压入栈了，相当于一个临时变量。在finally中并不会影响返回值</p><h3 id="finally中加入return"><a class="header-anchor" href="#finally中加入return">¶</a>finally中加入return</h3><pre><code class="language-java">public class Main &amp;#123;    private  static  int a=2;     public static void main(String[] args) &amp;#123;         System.out.println(&quot;test输出的结果 &quot;+test());        System.out.println(&quot;main 自加后 a=&quot;+(a++));    &amp;#125;        private  static  int test()&amp;#123;        try &amp;#123;            a+=3;            System.out.println(&quot;try  a=&quot;+a);            return a;        &amp;#125;catch (Exception e)&amp;#123;         &amp;#125;finally &amp;#123;            ++a;            System.out.println(&quot;finally a=&quot;+a);            return a;        &amp;#125;    &amp;#125;</code></pre><p>输出结果:</p><p>try  a=5<br>finally a=6<br>test输出的结果 6<br>main a=6</p><p>结论: 此时test方法的返回值是6和a的值相等， 在try,catch中的返回值可以发现被finally的返回值给屏蔽了，所以如果finally中              有return则会屏蔽当前方法中的返回值</p><h3 id="现在对引用变量进行分析"><a class="header-anchor" href="#现在对引用变量进行分析">¶</a>现在对引用变量进行分析</h3><p>finally中没有return</p><pre><code class="language-java">public class Main &amp;#123;    private  static List&lt;String&gt; list=new ArrayList&lt;&gt;();     public static void main(String[] args) &amp;#123;        System.out.println(&quot;test输出的结果 &quot;+test());        System.out.println(&quot;main list=&quot;+list.toString());      &amp;#125;    private  static  List test()&amp;#123;        try &amp;#123;            list.add(&quot;33&quot;);            System.out.println(&quot;try  list=&quot;+list.toString());            return list;        &amp;#125;catch (Exception e)&amp;#123;         &amp;#125;finally &amp;#123;            list.add(&quot;66&quot;);            System.out.println(&quot;finally list=&quot;+list.toString());        &amp;#125;        return null;    &amp;#125;&amp;#125;</code></pre><p>输出结果:</p><p>try  list=[33]<br>finally list=[33, 66]<br>test输出的结果 [33, 66]<br>main list=[33, 66]</p><p>结论: 通过结果可以知道 test的返回值内容也是跟集合list一样的， 因为list是引用类型所以堆区中存放了内存地址，在finally对值          进行改变时还是只想同一个地址，只是地址的内容变化了</p><p>2 finally中有return 、</p><p>输出值:</p><p>try  list=[33]<br>finally list=[33, 66]<br>test输出的结果 [33, 66]<br>main list=[33, 66]</p><p>结论:可见引用类型时finally有没有return都会对当前方法的返回值产生影响</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;首先在finally和try中对数据的操作时数据分为 基本数据类型和引用数据类型，他们存放的地方也不一样，一个是栈区另一个是在堆区。&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="try-catch" scheme="https://gyl-coder.top/tags/try-catch/"/>
    
    <category term="异常捕获" scheme="https://gyl-coder.top/tags/%E5%BC%82%E5%B8%B8%E6%8D%95%E8%8E%B7/"/>
    
  </entry>
  
  <entry>
    <title>手写实现IOC 和 AOP</title>
    <link href="https://gyl-coder.top/spring/custom-ioc-aop/"/>
    <id>https://gyl-coder.top/spring/custom-ioc-aop/</id>
    <published>2020-04-02T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<p>通过上一篇 <a href="https://gyl-coder.top/spring/spring-ioc-aop">IOC &amp; AOP 详解</a> 我们了解了 IOC 和 AOP 这两个思想，下面我们先不去考虑Spring是如何实现这两个思想的，先通过一个 <red>银行转账</red> 的案例，分析一下该案例在代码层面存在什么问题？分析之后使用我们已有的知识来解决这些问题（痛点）。</p><p>其实这个过程就是在一步步分析并手动实现 IOC 和 AOP 。</p><a id="more"></a><h2 id="案例介绍"><a class="header-anchor" href="#案例介绍">¶</a>案例介绍</h2><p>银行转账：账户A向账户B转账（账户A减钱，账户B加钱）。为了简单起见，在前端页面中写死了两个账户。每次只需要输入转账金额，进行转账操作，验证功能即可。</p><h3 id="案例表结构"><a class="header-anchor" href="#案例表结构">¶</a>案例表结构</h3><pre><code class="language-sql">name    varcher  255 用户名money   int      255 账户金额cardNo  varcher  255 银行卡号</code></pre><h3 id="案例代码调用关系"><a class="header-anchor" href="#案例代码调用关系">¶</a>案例代码调用关系</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411155954500.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411155954500.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h3 id="核心代码"><a class="header-anchor" href="#核心代码">¶</a>核心代码</h3><pre><code class="language-java">@WebServlet(name=&quot;transferServlet&quot;,urlPatterns = &quot;/transferServlet&quot;)public class TransferServlet extends HttpServlet &amp;#123;    // 1. 实例化service层对象    private TransferService transferService = new TransferServiceImpl();    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &amp;#123;        doPost(req,resp);    &amp;#125;    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &amp;#123;        // 设置请求体的字符编码        req.setCharacterEncoding(&quot;UTF-8&quot;);        String fromCardNo = req.getParameter(&quot;fromCardNo&quot;);        String toCardNo = req.getParameter(&quot;toCardNo&quot;);        String moneyStr = req.getParameter(&quot;money&quot;);        int money = Integer.parseInt(moneyStr);        Result result = new Result();        try &amp;#123;            // 2. 调用service层方法            transferService.transfer(fromCardNo,toCardNo,money);            result.setStatus(&quot;200&quot;);        &amp;#125; catch (Exception e) &amp;#123;            e.printStackTrace();            result.setStatus(&quot;201&quot;);            result.setMessage(e.toString());        &amp;#125;        // 响应        resp.setContentType(&quot;application/json;charset=utf-8&quot;);        resp.getWriter().print(JsonUtils.object2Json(result));    &amp;#125;&amp;#125;</code></pre><pre><code class="language-java">public interface TransferService &amp;#123;    void transfer(String fromCardNo, String toCardNo, int money) throws Exception;&amp;#125;</code></pre><pre><code class="language-java">public class TransferServiceImpl implements TransferService &amp;#123;    private AccountDao accountDao = new JdbcAccountDaoImpl();    @Override    public void transfer(String fromCardNo, String toCardNo, int money) throws Exception &amp;#123;            Account from = accountDao.queryAccountByCardNo(fromCardNo);            Account to = accountDao.queryAccountByCardNo(toCardNo);            from.setMoney(from.getMoney()-money);            to.setMoney(to.getMoney()+money);            accountDao.updateAccountByCardNo(to);            accountDao.updateAccountByCardNo(from);    &amp;#125;&amp;#125;</code></pre><pre><code class="language-java">public interface AccountDao &amp;#123;    /**     * 通过卡号查询账户     * @param cardNo     * @return     * @throws Exception     */    Account queryAccountByCardNo(String cardNo) throws Exception;    /**     * 更新账户信息     * @param account     * @return     * @throws Exception     */    int updateAccountByCardNo(Account account) throws Exception;&amp;#125;</code></pre><pre><code class="language-java">public class JdbcAccountDaoImpl implements AccountDao &amp;#123;    @Override    public Account queryAccountByCardNo(String cardNo) throws Exception &amp;#123;        //从连接池获取连接        Connection con = DruidUtils.getInstance().getConnection();        String sql = &quot;select * from account where cardNo=?&quot;;        PreparedStatement preparedStatement = con.prepareStatement(sql);        preparedStatement.setString(1,cardNo);        ResultSet resultSet = preparedStatement.executeQuery();        Account account = new Account();        while(resultSet.next()) &amp;#123;            account.setCardNo(resultSet.getString(&quot;cardNo&quot;));            account.setName(resultSet.getString(&quot;name&quot;));            account.setMoney(resultSet.getInt(&quot;money&quot;));        &amp;#125;        resultSet.close();        preparedStatement.close();        con.close();        return account;    &amp;#125;    @Override    public int updateAccountByCardNo(Account account) throws Exception &amp;#123;        // 从连接池获取连接        Connection con = DruidUtils.getInstance().getConnection();        String sql = &quot;update account set money=? where cardNo=?&quot;;        PreparedStatement preparedStatement = con.prepareStatement(sql);        preparedStatement.setInt(1,account.getMoney());        preparedStatement.setString(2,account.getCardNo());        int i = preparedStatement.executeUpdate();        preparedStatement.close();        con.close();        return i;    &amp;#125;&amp;#125;</code></pre><h2 id="案例问题分析"><a class="header-anchor" href="#案例问题分析">¶</a>案例问题分析</h2><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411161239748.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411161239748.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>通过上面的流程分析以及简要代码，我们可以发现如下问题：</p><p><strong>问题一：</strong> new 关键字将 service 层的实现类 TransferServiceImpl 和 Dao 层的具体实现类 JdbcAccountDaoImpl 耦合在了一起，当需要切换Dao层实现类的时候必须要修改 service 的代码、重新编译，这样不符合面向接口开发的最优原则。</p><p><strong>问题二：</strong> service 层没有事务控制，如果转账过程中出现异常可能会导致数据错乱，后果很严重，尤其是在金融银行领域。</p><h2 id="问题解决思路"><a class="header-anchor" href="#问题解决思路">¶</a>问题解决思路</h2><h3 id="new关键字耦合问题解决方案"><a class="header-anchor" href="#new关键字耦合问题解决方案">¶</a>new关键字耦合问题解决方案</h3><p>实例化对象的方式处理 <red>new</red> 之外，还有什么技术？</p><p>答：反射（将类的权限定类名配置在xml文件中）</p><p>项目中往往有很多对象需要实例化，考虑使用<red>工程模式</red>通过反射来实例化对象。（工厂模式是解耦合非常好的一种方式）</p><p>代码中能否只声明所需实例的接口类型，不出现new关键字，也不出现工厂类的字眼？</p><p>答：可以，声明一个变量并提供一个set方法，在反射的时候将所需要的对象注入进去。</p><pre><code class="language-java">public class TransferServiceImpl implements TransferService &amp;#123;        private AccountDao accountDao;    public void setAccountDao(AccountDao accountDao) &amp;#123;        this.accountDao = accountDao;    &amp;#125;&amp;#125;</code></pre><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411170129158.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411170129158.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h3 id="new关键字耦合问题代码改造"><a class="header-anchor" href="#new关键字耦合问题代码改造">¶</a>new关键字耦合问题代码改造</h3><p><strong>首先定义 bean.xml 文件</strong></p><pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!--跟标签beans，里面配置一个又一个的bean子标签，每一个bean子标签都代表一个类的配置--&gt;&lt;beans&gt;    &lt;!--id标识对象，class是类的全限定类名--&gt;    &lt;bean id=&quot;accountDao&quot; class=&quot;com.yanliang.dao.impl.JdbcAccountDaoImpl&quot;&gt;        &lt;property name=&quot;ConnectionUtils&quot; ref=&quot;connectionUtils&quot;/&gt;    &lt;/bean&gt;    &lt;bean id=&quot;transferService&quot; class=&quot;com.yanliang.service.impl.TransferServiceImpl&quot;&gt;        &lt;!--set+ name 之后锁定到传值的set方法了，通过反射技术可以调用该方法传入对应的值--&gt;        &lt;property name=&quot;AccountDao&quot; ref=&quot;accountDao&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p><strong>定义BeanFactory</strong></p><pre><code class="language-java">/** * 工厂类，生产对象（使用反射技术） * 任务一：读取解析xml，通过反射技术实例化对象并且存储待用（map集合） * 任务二：对外提供获取实例对象的接口（根据id获取） */public class BeanFactory &amp;#123;    private static Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();  // 存储对象    /**     * 读取解析xml，通过反射技术实例化对象并且存储待用（map集合）     */    static &amp;#123;        // 加载xml        InputStream resourceAsStream = BeanFactory.class.getClassLoader().getResourceAsStream(&quot;beans.xml&quot;);        // 解析xml        SAXReader saxReader = new SAXReader();        try &amp;#123;            Document document = saxReader.read(resourceAsStream);            // 获取根元素            Element rootElement = document.getRootElement();            List&lt;Element&gt; beanList = rootElement.selectNodes(&quot;//bean&quot;);            for (int i = 0; i &lt; beanList.size(); i++) &amp;#123;                Element element =  beanList.get(i);                // 处理每个bean元素，获取到该元素的id 和 class 属性                String id = element.attributeValue(&quot;id&quot;);        // accountDao                String clazz = element.attributeValue(&quot;class&quot;);  // com.yanliang.dao.impl.JdbcAccountDaoImpl                // 通过反射技术实例化对象                Class&lt;?&gt; aClass = Class.forName(clazz);                Object o = aClass.newInstance();  // 实例化之后的对象                // 存储到map中待用                map.put(id,o);            &amp;#125;            // 实例化完成之后维护对象的依赖关系，检查哪些对象需要传值进入，根据它的配置，我们传入相应的值            // 有property子元素的bean就有传值需求            List&lt;Element&gt; propertyList = rootElement.selectNodes(&quot;//property&quot;);            // 解析property，获取父元素            for (int i = 0; i &lt; propertyList.size(); i++) &amp;#123;                Element element =  propertyList.get(i);   //&lt;property name=&quot;AccountDao&quot; ref=&quot;accountDao&quot;&gt;&lt;/property&gt;                String name = element.attributeValue(&quot;name&quot;);                String ref = element.attributeValue(&quot;ref&quot;);                // 找到当前需要被处理依赖关系的bean                Element parent = element.getParent();                // 调用父元素对象的反射功能                String parentId = parent.attributeValue(&quot;id&quot;);                Object parentObject = map.get(parentId);                // 遍历父对象中的所有方法，找到&quot;set&quot; + name                Method[] methods = parentObject.getClass().getMethods();                for (int j = 0; j &lt; methods.length; j++) &amp;#123;                    Method method = methods[j];                    if(method.getName().equalsIgnoreCase(&quot;set&quot; + name)) &amp;#123;  // 该方法就是 setAccountDao(AccountDao accountDao)                        method.invoke(parentObject,map.get(ref));                    &amp;#125;                &amp;#125;                // 把处理之后的parentObject重新放到map中                map.put(parentId,parentObject);            &amp;#125;        &amp;#125; catch (DocumentException e) &amp;#123;            e.printStackTrace();        &amp;#125; catch (ClassNotFoundException e) &amp;#123;            e.printStackTrace();        &amp;#125; catch (IllegalAccessException e) &amp;#123;            e.printStackTrace();        &amp;#125; catch (InstantiationException e) &amp;#123;            e.printStackTrace();        &amp;#125; catch (InvocationTargetException e) &amp;#123;            e.printStackTrace();        &amp;#125;    &amp;#125;    /**     * 对外提供获取实例对象的接口（根据id获取）     * @param id     * @return     */    public static  Object getBean(String id) &amp;#123;        return map.get(id);    &amp;#125;&amp;#125;</code></pre><p>对象的实例化工作交给BeanFactory来进行之后，我们再具体使用是就可以像如下这样了：</p><pre><code class="language-java">@WebServlet(name=&quot;transferServlet&quot;,urlPatterns = &quot;/transferServlet&quot;)public class TransferServlet extends HttpServlet &amp;#123;//    // 1. 实例化service层对象//    private TransferService transferService = new TransferServiceImpl();    // 改造为通过Bean工程获取service层对象    private TransferService transferService = (TransferService) BeanFactory.getBean(&quot;transferService&quot;);            public class TransferServiceImpl implements TransferService &amp;#123;//    private AccountDao accountDao = new JdbcAccountDaoImpl();//    // 改造为通过Bean工厂获取对象//    private AccountDao accountDao = (AccountDao) BeanFactory.getBean(&quot;accountDao&quot;);    // 最佳状态    private AccountDao accountDao;    public void setAccountDao(AccountDao accountDao) &amp;#123;        this.accountDao = accountDao;    &amp;#125;</code></pre><h3 id="事务控制问题分析"><a class="header-anchor" href="#事务控制问题分析">¶</a>事务控制问题分析</h3><p>在转账的业务代码中手动模拟转账异常，来验证一下。在两个账户的转入和转出之间模拟一个分母为0的异常。</p><pre><code class="language-java">accountDao.updateAccountByCardNo(to);int i = 1/0;accountDao.updateAccountByCardNo(from);</code></pre><p>然后启动程序，点击转账（李大雷 向 韩梅梅转 100 ￥）之后，会出现如下错误。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411175805231.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411175805231.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>这时我们再查看数据库</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411175900117.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411175900117.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>发现 韩梅梅 的账户增加了100￥，但是李大雷的账户并没有减少（两个账户原本都有10000￥）。</p><p>出现这个问题的原因就是因为Service层没有事务控制的功能，在转账过程中出现错误（转入和转出之间出现异常，转入已经完成，转出没有进行）这事就会造成上面的问题。</p><p>数据库的事务问题归根结底是 Connection 的事务</p><ul><li>connection.commit() 提交事务</li><li>connection.rollback() 回滚事务</li></ul><p>在上面银行转账的案例中，两次update操作使用的是两个数据库连接，这样的话，肯定就不属于同一个事务控制了。</p><p><strong>解决思路：</strong></p><p>通过上面的分析，我们得出问题的原因是两次update使用了两个不同的connection连接。那么要想解决这个问题，我们就需要让两次update使用同一个connection连接</p><p>两次update属于同一个线程内的执行调用，我们可以给当前线程绑定一个Connection，和当前线程有关系的数据库操作都去使用这个connection（从当前线程中获取，第一次使用连接，发现当前线程没有，就从连接池获取一个连接绑定到当前线程）</p><p>另一方面，目前事务控制是在Dao层进行的（connection），我们需要将事务控制提到service层（service层才是具体执行业务逻辑的地方，这里可能会调用多个dao层的方法，我们需要对service层的方法进行整体的事务控制）。</p><p>有了上面两个思路，下面我们进行代码修改。</p><h3 id="事务控制代码修改"><a class="header-anchor" href="#事务控制代码修改">¶</a>事务控制代码修改</h3><p>增加 ConnectionUtils 工具类</p><pre><code class="language-java">/** * 获取连接，并将连接与线程绑定 */public class ConnectionUtils &amp;#123;    private ThreadLocal&lt;Connection&gt; threadLocal = new ThreadLocal&lt;&gt;(); // 存储当前线程的连接    /**     * 从当前线程获取连接     */    public Connection getCurrentThreadConn() throws SQLException &amp;#123;        /**         * 判断当前线程中是否已经绑定连接，如果没有绑定，需要从连接池获取一个连接绑定到当前线程          */        Connection connection = threadLocal.get();        if(connection == null) &amp;#123;            // 从连接池拿连接并绑定到线程            connection = DruidUtils.getInstance().getConnection();            // 绑定到当前线程            threadLocal.set(connection);        &amp;#125;        return connection;    &amp;#125;&amp;#125;</code></pre><p>增加 TransactionManager 事务管理类</p><pre><code class="language-java">/** * 事务管理器类：负责手动事务的开启、提交、回滚 */public class TransactionManager &amp;#123;    private ConnectionUtils connectionUtils;    public void setConnectionUtils(ConnectionUtils connectionUtils) &amp;#123;        this.connectionUtils = connectionUtils;    &amp;#125;    // 开启手动事务控制    public void beginTransaction() throws SQLException &amp;#123;        connectionUtils.getCurrentThreadConn().setAutoCommit(false);    &amp;#125;        // 提交事务    public void commit() throws SQLException &amp;#123;        connectionUtils.getCurrentThreadConn().commit();    &amp;#125;        // 回滚事务    public void rollback() throws SQLException &amp;#123;        connectionUtils.getCurrentThreadConn().rollback();    &amp;#125;&amp;#125;</code></pre><p>增加代理工厂 ProxyFactory</p><pre><code class="language-java">/** * 代理对象工厂：生成代理对象的 */public class ProxyFactory &amp;#123;    private TransactionManager transactionManager;    public void setTransactionManager(TransactionManager transactionManager) &amp;#123;        this.transactionManager = transactionManager;    &amp;#125;    /**     * Jdk动态代理     * @param obj  委托对象     * @return   代理对象     */    public Object getJdkProxy(Object obj) &amp;#123;        // 获取代理对象        return  Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(),                new InvocationHandler() &amp;#123;                    @Override                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123;                        Object result = null;                        try&amp;#123;                            // 开启事务(关闭事务的自动提交)                            transactionManager.beginTransaction();                            result = method.invoke(obj,args);                            // 提交事务                            transactionManager.commit();                        &amp;#125;catch (Exception e) &amp;#123;                            e.printStackTrace();                            // 回滚事务                            transactionManager.rollback();                            // 抛出异常便于上层servlet捕获                            throw e;                        &amp;#125;                        return result;                    &amp;#125;                &amp;#125;);    &amp;#125;    /**     * 使用cglib动态代理生成代理对象     * @param obj 委托对象     * @return     */    public Object getCglibProxy(Object obj) &amp;#123;        return  Enhancer.create(obj.getClass(), new MethodInterceptor() &amp;#123;            @Override            public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &amp;#123;                Object result = null;                try&amp;#123;                    // 开启事务(关闭事务的自动提交)                    transactionManager.beginTransaction();                    result = method.invoke(obj,objects);                    // 提交事务                    transactionManager.commit();                &amp;#125;catch (Exception e) &amp;#123;                    e.printStackTrace();                    // 回滚事务                    transactionManager.rollback();                    // 抛出异常便于上层servlet捕获                    throw e;                &amp;#125;                return result;            &amp;#125;        &amp;#125;);    &amp;#125;&amp;#125;</code></pre><p>修改beans.xml文件</p><pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!--跟标签beans，里面配置一个又一个的bean子标签，每一个bean子标签都代表一个类的配置--&gt;&lt;beans&gt;    &lt;!--id标识对象，class是类的全限定类名--&gt;    &lt;bean id=&quot;accountDao&quot; class=&quot;com.yanliang.dao.impl.JdbcAccountDaoImpl&quot;&gt;        &lt;property name=&quot;ConnectionUtils&quot; ref=&quot;connectionUtils&quot;/&gt;    &lt;/bean&gt;    &lt;bean id=&quot;transferService&quot; class=&quot;com.yanliang.service.impl.TransferServiceImpl&quot;&gt;        &lt;!--set+ name 之后锁定到传值的set方法了，通过反射技术可以调用该方法传入对应的值--&gt;        &lt;property name=&quot;AccountDao&quot; ref=&quot;accountDao&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!--配置新增的三个Bean--&gt;    &lt;bean id=&quot;connectionUtils&quot; class=&quot;com.yanliang.utils.ConnectionUtils&quot;&gt;&lt;/bean&gt;    &lt;!--事务管理器--&gt;    &lt;bean id=&quot;transactionManager&quot; class=&quot;com.yanliang.utils.TransactionManager&quot;&gt;        &lt;property name=&quot;ConnectionUtils&quot; ref=&quot;connectionUtils&quot;/&gt;    &lt;/bean&gt;    &lt;!--代理对象工厂--&gt;    &lt;bean id=&quot;proxyFactory&quot; class=&quot;com.yanliang.factory.ProxyFactory&quot;&gt;        &lt;property name=&quot;TransactionManager&quot; ref=&quot;transactionManager&quot;/&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p>修改 JdbcAccountDaoImpl的实现</p><pre><code class="language-java">public class JdbcAccountDaoImpl implements AccountDao &amp;#123;        private ConnectionUtils connectionUtils;    public void setConnectionUtils(ConnectionUtils connectionUtils) &amp;#123;        this.connectionUtils = connectionUtils;    &amp;#125;    @Override    public Account queryAccountByCardNo(String cardNo) throws Exception &amp;#123;        //从连接池获取连接//        Connection con = DruidUtils.getInstance().getConnection();        // 改造为：从当前线程当中获取绑定的connection连接        Connection con = connectionUtils.getCurrentThreadConn();        String sql = &quot;select * from account where cardNo=?&quot;;        PreparedStatement preparedStatement = con.prepareStatement(sql);        preparedStatement.setString(1,cardNo);        ResultSet resultSet = preparedStatement.executeQuery();        Account account = new Account();        while(resultSet.next()) &amp;#123;            account.setCardNo(resultSet.getString(&quot;cardNo&quot;));            account.setName(resultSet.getString(&quot;name&quot;));            account.setMoney(resultSet.getInt(&quot;money&quot;));        &amp;#125;        resultSet.close();        preparedStatement.close();//        con.close();        return account;    &amp;#125;    @Override    public int updateAccountByCardNo(Account account) throws Exception &amp;#123;        // 从连接池获取连接//        Connection con = DruidUtils.getInstance().getConnection();        // 改造为：从当前线程当中获取绑定的connection连接        Connection con = connectionUtils.getCurrentThreadConn();        String sql = &quot;update account set money=? where cardNo=?&quot;;        PreparedStatement preparedStatement = con.prepareStatement(sql);        preparedStatement.setInt(1,account.getMoney());        preparedStatement.setString(2,account.getCardNo());        int i = preparedStatement.executeUpdate();        preparedStatement.close();//        con.close();        return i;    &amp;#125;&amp;#125;</code></pre><p>修改 TransferServlet</p><pre><code class="language-java">@WebServlet(name=&quot;transferServlet&quot;,urlPatterns = &quot;/transferServlet&quot;)public class TransferServlet extends HttpServlet &amp;#123;//    // 1. 实例化service层对象//    private TransferService transferService = new TransferServiceImpl();    // 改造为通过Bean工程获取service层对象//    private TransferService transferService = (TransferService) BeanFactory.getBean(&quot;transferService&quot;);    // 从工程获取委托对象（委托对象增强了事务控制的功能）    private ProxyFactory proxyFactory = (ProxyFactory) BeanFactory.getBean(&quot;proxyFactory&quot;);    private TransferService transferService = (TransferService) proxyFactory.getProxy(BeanFactory.getBean(&quot;transferService&quot;)) ;    @Override    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &amp;#123;        doPost(req,resp);    &amp;#125;    @Override    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &amp;#123;        // 设置请求体的字符编码        req.setCharacterEncoding(&quot;UTF-8&quot;);        String fromCardNo = req.getParameter(&quot;fromCardNo&quot;);        String toCardNo = req.getParameter(&quot;toCardNo&quot;);        String moneyStr = req.getParameter(&quot;money&quot;);        int money = Integer.parseInt(moneyStr);        Result result = new Result();        try &amp;#123;            // 2. 调用service层方法            transferService.transfer(fromCardNo,toCardNo,money);            result.setStatus(&quot;200&quot;);        &amp;#125; catch (Exception e) &amp;#123;            e.printStackTrace();            result.setStatus(&quot;201&quot;);            result.setMessage(e.toString());        &amp;#125;        // 响应        resp.setContentType(&quot;application/json;charset=utf-8&quot;);        resp.getWriter().print(JsonUtils.object2Json(result));    &amp;#125;&amp;#125;</code></pre><p>改造完之后，我们再次进行测试，这时会发现当转账过程中出现错误是，事务能够成功的被控制住（转出账户不会少钱，转入账户不会多钱）。</p><h3 id="为什么要使用代理的方式来实现事务控制？"><a class="header-anchor" href="#为什么要使用代理的方式来实现事务控制？">¶</a>为什么要使用代理的方式来实现事务控制？</h3><p>这里我们可以考虑一个问题，为什么要使用代理的方式来实现事务控制？</p><p>如果没有使用代理的方式，我们要向实现事务控制这需要将，事务控制的相关代码写在service层的TransferServiceImpl 具体实现中。</p><pre><code class="language-java">public class TransferServiceImpl implements TransferService &amp;#123;    // 最佳状态    private AccountDao accountDao;    // 构造函数传值/set方法传值    public void setAccountDao(AccountDao accountDao) &amp;#123;        this.accountDao = accountDao;    &amp;#125;    @Override    public void transfer(String fromCardNo, String toCardNo, int money) throws Exception &amp;#123;        try&amp;#123;            // 开启事务(关闭事务的自动提交)            TransactionManager.getInstance().beginTransaction();*/            Account from = accountDao.queryAccountByCardNo(fromCardNo);            Account to = accountDao.queryAccountByCardNo(toCardNo);            from.setMoney(from.getMoney()-money);            to.setMoney(to.getMoney()+money);            accountDao.updateAccountByCardNo(to);            // 模拟异常            int c = 1/0;            accountDao.updateAccountByCardNo(from);            // 提交事务            TransactionManager.getInstance().commit();        &amp;#125;catch (Exception e) &amp;#123;            e.printStackTrace();            // 回滚事务            TransactionManager.getInstance().rollback();            // 抛出异常便于上层servlet捕获            throw e;        &amp;#125;    &amp;#125;&amp;#125;</code></pre><p>这样的话，事务控制和具体的业务代码就耦合在了一起，如果有多个方法都需要实现事务控制的功能，我们需要在每个业务方法是都添加上这些代码。这样将会出现大量的重复代码。所以这里使用了 AOP 的思想通过动态代理的方式实现了事务控制。</p><div class="tag link"><a class="link-card" title="下载源码" href="https://github.com/gyl-coder/ISpring-IOC-AOP/tree/feat-init"><div class="left"><img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div><div class="right"><p class="text">下载源码</p><p class="url">https://github.com/gyl-coder/ISpring-IOC-AOP/tree/feat-init</p></div></a></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;通过上一篇 &lt;a href=&quot;https://gyl-coder.top/spring/spring-ioc-aop&quot;&gt;IOC &amp;amp; AOP 详解&lt;/a&gt; 我们了解了 IOC 和 AOP 这两个思想，下面我们先不去考虑Spring是如何实现这两个思想的，先通过一个 &lt;red&gt;银行转账&lt;/red&gt; 的案例，分析一下该案例在代码层面存在什么问题？分析之后使用我们已有的知识来解决这些问题（痛点）。&lt;/p&gt;
&lt;p&gt;其实这个过程就是在一步步分析并手动实现 IOC 和 AOP 。&lt;/p&gt;</summary>
    
    
    
    <category term="Spring" scheme="https://gyl-coder.top/categories/Spring/"/>
    
    
    <category term="动态代理" scheme="https://gyl-coder.top/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"/>
    
    <category term="Spring" scheme="https://gyl-coder.top/tags/Spring/"/>
    
    <category term="IOC" scheme="https://gyl-coder.top/tags/IOC/"/>
    
    <category term="AOP" scheme="https://gyl-coder.top/tags/AOP/"/>
    
  </entry>
  
  <entry>
    <title>动态代理原理剖析</title>
    <link href="https://gyl-coder.top/java/dynamic-proxy/"/>
    <id>https://gyl-coder.top/java/dynamic-proxy/</id>
    <published>2020-04-01T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<p>动态代理的常用实现方式是反射。反射机制是 Java 语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。</p><p>动态代理是一种方便运行时动态构建代理、动态处理代理方法调用的机制，很多场景都是利用类似机制做到的，比如用来包装 RPC 调用、面向切面的编程（AOP）。</p><p>JDK 自身提供的动态代理，就是主要利用了上面提到的反射机制。但动态代理不止有反射一种实现方式，还有其他的实现方式，比如利用传说中更高性能的字节码操作机制，类似 ASM、cglib（基于 ASM，一个 Java 字节码操作框架）、Javassist 等。简单来说，动态代理是一种行为方式，而反射或 ASM 只是它的一种实现手段而已。</p><p>JDK Proxy 和 CGLib 的区别主要体现在以下几个方面：</p><ul><li>JDK Proxy 是 Java 语言自带的功能，无需通过加载第三方类实现；</li><li>Java 对 JDK Proxy 提供了稳定的支持，并且会持续的升级和更新 JDK Proxy，例如 Java 8 版本中的 JDK Proxy 性能相比于之前版本提升了很多；</li><li>JDK Proxy 是通过拦截器加反射的方式实现的；</li><li>JDK Proxy 只能代理继承接口的类；</li><li>JDK Proxy 实现和调用起来比较简单；</li><li>CGLib 是第三方提供的工具，基于 ASM 实现的，性能比较高；</li><li>CGLib 无需通过接口来实现，它是通过实现子类的方式来完成调用的。</li></ul><a id="more"></a><h2 id="什么是静态代理"><a class="header-anchor" href="#什么是静态代理">¶</a>什么是静态代理</h2><p>静态代理是代理类在编译期间就创建好了，不是编译器生成的代理类，而是手动创建的类。在编译时就已经将接口，被代理类，代理类等确定下来。，软件设计中所指的代理一般是指静态代理，也就是在代码中显式指定的代理。</p><p>下面我们通过一个简单的案例，来了解下静态代理。</p><pre><code class="language-java">/** * 静态代理类接口, 委托类和代理类都需要实现的接口规范。 * 定义了一个猫科动物的两个行为接口，吃东西，奔跑。 * 作为代理类 和委托类之间的约束接口 */public interface Cat &amp;#123;         public String eatFood(String foodName);         public boolean running();&amp;#125;</code></pre><pre><code class="language-java">    /**     * 狮子 实现了猫科动物接口Cat， 并实现了具体的行为。作为委托类实现     */    public class Lion implements Cat &amp;#123;            private String name;            private int runningSpeed;            public String getName() &amp;#123;                    return name;        &amp;#125;            public void setName(String name) &amp;#123;                    this.name = name;         &amp;#125;            public int getRunningSpeed() &amp;#123;                    return runningSpeed;         &amp;#125;            public void setRunningSpeed(int runningSpeed) &amp;#123;                    this.runningSpeed = runningSpeed;         &amp;#125;            public Lion() &amp;#123; &amp;#125;                    @Override        public String eatFood(String foodName) &amp;#123;            String eat = this.name + &quot; Lion eat food. foodName = &quot; + foodName;            System.out.println(eat);        return eat;        &amp;#125;            @Override        public boolean running() &amp;#123;            System.out.println(this.name + &quot; Lion is running . Speed :&quot; + this.runningSpeed);        return false;        &amp;#125;    &amp;#125;</code></pre><p>代理类角色(FeederProxy)</p><pre><code class="language-java">/** * 饲养员 实现Cat接口，作为静态代理类实现。代理狮子的行为。 * 代理类中可以新增一些其他行为，在实践中主要做的是参数校验的功能。 */public class FeederProxy implements Cat &amp;#123;        private Cat cat;        public FeederProxy()&amp;#123;&amp;#125;        public FeederProxy(Cat cat) &amp;#123;                 if (cat instanceof Cat) &amp;#123;                         this.cat = cat;          &amp;#125;     &amp;#125;        public void setCat(Cat cat) &amp;#123;                 if (cat instanceof Cat) &amp;#123;                         this.cat = cat;          &amp;#125;     &amp;#125;        @Override    public String eatFood(String foodName) &amp;#123;        System.out.println(&quot;proxy Lion exec eatFood &quot;);                return cat.eatFood(foodName);    &amp;#125;        @Override    public boolean running() &amp;#123;        System.out.println(&quot;proxy Lion exec running.&quot;);                return cat.running();    &amp;#125;&amp;#125;</code></pre><p>静态代理类测试</p><pre><code class="language-java">    /**     * 静态代理类测试     */    public class staticProxyTest &amp;#123;            public static void main(String[] args) &amp;#123;            Lion lion = new Lion();            lion.setName(&quot;狮子 小王&quot;);            lion.setRunningSpeed(100);                    /**             * new 静态代理类，静态代理类在编译前已经创建好了，和动态代理的最大区别点             */            Cat proxy = new FeederProxy(lion);                   System.out.println(Thread.currentThread().getName()+&quot; -- &quot; + proxy.eatFood(&quot;水牛&quot;));            proxy.running();         &amp;#125;    &amp;#125;</code></pre><p>静态代理很好的诠释了代理设计模式，代理模式最主要的就是有一个公共接口（Cat），一个委托类（Lion），一个代理类（FeederProxy）,代理类持有委托类的实例，代为执行具体类实例方法。</p><p>代理模式就是在访问实际对象时引入一定程度的间接性，因为这种间接性，可以附加多种用途。这里的间接性就是指客户端不直接调用实际对象的方法，客户端依赖公共接口并使用代理类。 那么我们在代理过程中就可以加上一些其他用途。</p><p>就这个例子来说在 eatFood 方法调用中，代理类在调用具体实现类之前添加System.out.println(&quot;proxy Lion exec eatFood &quot;);语句 就是添加间接性带来的收益。代理类存在的意义是为了增加一些公共的逻辑代码。</p><h3 id="静态代理的缺陷"><a class="header-anchor" href="#静态代理的缺陷">¶</a>静态代理的缺陷</h3><ol><li><p>代理类和委托类实现了相同的接口，代理类通过委托类实现了相同的方法。这样就出现了大量的代码重复。如果接口增加一个方法，除了所有实现类需要实现这个方法外，所有代理类也需要实现此方法。增加了代码维护的复杂度。</p></li><li><p>代理对象只服务于一种类型的对象，如果要服务多类型的对象。势必要为每一种对象都进行代理，静态代理在程序规模稍大时就无法胜任了。</p></li><li><p>静态代理一个代理只能代理一种类型，而且是在编译器就已经确定被代理的对象。</p></li></ol><h2 id="JDK-Proxy-和-CGLib-的使用样例"><a class="header-anchor" href="#JDK-Proxy-和-CGLib-的使用样例">¶</a>JDK Proxy 和 CGLib 的使用样例</h2><h3 id="JDK-Proxy-动态代理实现"><a class="header-anchor" href="#JDK-Proxy-动态代理实现">¶</a>JDK Proxy 动态代理实现</h3>]]></content>
    
    
    <summary type="html">&lt;p&gt;动态代理的常用实现方式是反射。反射机制是 Java 语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。&lt;/p&gt;
&lt;p&gt;动态代理是一种方便运行时动态构建代理、动态处理代理方法调用的机制，很多场景都是利用类似机制做到的，比如用来包装 RPC 调用、面向切面的编程（AOP）。&lt;/p&gt;
&lt;p&gt;JDK 自身提供的动态代理，就是主要利用了上面提到的反射机制。但动态代理不止有反射一种实现方式，还有其他的实现方式，比如利用传说中更高性能的字节码操作机制，类似 ASM、cglib（基于 ASM，一个 Java 字节码操作框架）、Javassist 等。简单来说，动态代理是一种行为方式，而反射或 ASM 只是它的一种实现手段而已。&lt;/p&gt;
&lt;p&gt;JDK Proxy 和 CGLib 的区别主要体现在以下几个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JDK Proxy 是 Java 语言自带的功能，无需通过加载第三方类实现；&lt;/li&gt;
&lt;li&gt;Java 对 JDK Proxy 提供了稳定的支持，并且会持续的升级和更新 JDK Proxy，例如 Java 8 版本中的 JDK Proxy 性能相比于之前版本提升了很多；&lt;/li&gt;
&lt;li&gt;JDK Proxy 是通过拦截器加反射的方式实现的；&lt;/li&gt;
&lt;li&gt;JDK Proxy 只能代理继承接口的类；&lt;/li&gt;
&lt;li&gt;JDK Proxy 实现和调用起来比较简单；&lt;/li&gt;
&lt;li&gt;CGLib 是第三方提供的工具，基于 ASM 实现的，性能比较高；&lt;/li&gt;
&lt;li&gt;CGLib 无需通过接口来实现，它是通过实现子类的方式来完成调用的。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="动态代理" scheme="https://gyl-coder.top/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>IOC &amp; AOP 详解</title>
    <link href="https://gyl-coder.top/spring/spring-ioc-aop/"/>
    <id>https://gyl-coder.top/spring/spring-ioc-aop/</id>
    <published>2020-04-01T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<p>下面从以下几个问题展开对 <red>IOC &amp; AOP </red> 的解释</p><ul><li>什么是IOC？</li><li>IOC解决了什么问题？</li><li>IOC 和 DI 的区别？</li><li>什么是AOP？</li><li>AOP解决了什么问题？</li><li>AOP为什么叫做切面变成？</li></ul><p>首先声明： <red>IOC &amp; AOP </red>  不是Spring提出来的，它们在Spring之前其实已经存在了，只不过当时更加偏向于理论。 Spring 在技术层次将这两个思想进行了很好的实现。</p><a id="more"></a><h3 id="什么是-IOC"><a class="header-anchor" href="#什么是-IOC">¶</a>什么是 IOC</h3><p><green> IOC （Inversion of control ）</green> 控制反转/反转控制。它是一种 <green>思想</green> 不是一个技术实现。描述的是：Java 开发领域对象的创建以及管理的问题。</p><p>例如：现有 类A依赖于类B</p><p>**传统的开发方式：**往往是在类A中手动通过 <green>new</green> 关键字来 new 一个B的对象出来</p><p><strong>使用IOC思想的开发方式：</strong> 不通过<green>new</green> 关键字来创建对象，而是通过 <green>IOC容器</green> (Spring 框架) 来帮助我们实例化对象。我们需要哪个对象，直接从IOC容器里面过去即可。</p><p>从以上两种开发方式的对比来看：我们 “丧失了一个权力” (创建、管理对象的权力)，从而也得到了一个好处（不用再考虑对象的创建、管理等一系列的事情）</p><h4 id="为什么叫控制反转"><a class="header-anchor" href="#为什么叫控制反转">¶</a>为什么叫控制反转</h4><p><strong>控制：</strong> 指的是对象创建（实例化、管理）的权力</p><p><strong>反转：</strong> 控制权交给外部环境（Spring框架、IOC容器）</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411114146872.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411114146872.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h3 id="IOC-解决了什么问题"><a class="header-anchor" href="#IOC-解决了什么问题">¶</a>IOC 解决了什么问题</h3><p>IOC 主要解决的是对象之间的耦合问题。</p><p>例如：现有一个针对User的操作，利用 Service 和 Dao 两层结构进行开发</p><p>在没有使用IOC思想的情况下，Service 层想要使用 Dao层的具体实现的话，需要通过 <yellow>new</yellow> 关键字在UserServiceImpl 中手动 new出 IUserDao 的具体实现类 UserDaoImpl（不能直接new接口类）。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411115607696.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411115607696.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>很完美，这种方式也是可以实现的，但是我们想象一下如下场景：开发过程中突然接到一个新的需求，针对对IUserDao 接口开发出另一个具体实现类。因为Server层依赖了IUserDao的具体实现，所以我们需要修改UserServiceImpl中new的对象。如果只有一个类引用了IUserDao的具体实现，可能觉得还好，修改起来也不是很费力气，但是如果有许许多多的地方都引用了IUserDao的具体实现的话，一旦需要更换IUserDao的实现方式，那修改起来将会非常的头疼。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411120144353.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411120144353.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>使用IOC的思想，我们将对象的控制权（创建、管理）交有IOC容器去管理，我们在使用的时候直接向IOC容器 “要” 就可以了</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411120751016.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411120751016.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h3 id="IOC-和-DI-的区别"><a class="header-anchor" href="#IOC-和-DI-的区别">¶</a>IOC 和 DI 的区别</h3><p>IOC 和 DI 描述的是同一件事情（对象实例化以及依赖关系的维护），只不过角度不同。</p><p>IOC （Inversion of control ） 控制反转/反转控制。是站在对象的角度，对象实例化以及管理的权限（反转）交给了容器。</p><p>DI （Dependancy Injection）依赖注入。是站在容器的角度，容器会把对象依赖的其他对象注入（送进去）。例如：对象A 实例化过程中因为声明了一个B类型的属性，那么就需要容器把B对象注入到A中。</p><h3 id="什么是AOP"><a class="header-anchor" href="#什么是AOP">¶</a>什么是AOP</h3><p>AOP：Aspect oriented programming 面向切面编程，AOP是 OOP（面向对象编程）的一种延续，下面我们先看一个OOP的例子。</p><p>例如：现有三个类，Horse、Pig、Dog，这三个类中都有 eat 和 run 两个方法。</p><p>通过OOP思想中的继承，我们可以提取出一个 Animal 的父类，然后将 eat 和 run 方法放入父类中，Horse、Pig、Dog通过继承Animal类即可自动获得 eat 和 run 方法。这样将会少些很多重复的代码。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411132252046.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411132252046.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>OOP编程思想可以解决大部分的代码重复问题。但是有一些问题是处理不了的。比如在父类Animal 中的多个方法的相同位置出现了重复的代码，OOP就解决不了。</p><pre><code class="language-java">/** * 动物父类 */public class Animal &amp;#123;        /** 身高 */    private String height;        /** 体重 */    private double weight;        public void eat() &amp;#123;        // 性能监控代码        long start = System.currentTimeMillis();                // 业务逻辑代码        System.out.println(&quot;I can eat...&quot;);        // 性能监控代码        System.out.println(&quot;执行时长：&quot; + (System.currentTimeMillis() - start)/1000f + &quot;s&quot;);    &amp;#125;        public void run() &amp;#123;        // 性能监控代码        long start = System.currentTimeMillis();        // 业务逻辑代码        System.out.println(&quot;I can run...&quot;);        // 性能监控代码        System.out.println(&quot;执行时长：&quot; + (System.currentTimeMillis() - start)/1000f + &quot;s&quot;);    &amp;#125;&amp;#125;</code></pre><p>这部分重复的代码，一般统称为 <strong>横切逻辑代码</strong>。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411133826720.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411133826720.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>横切逻辑代码存在的问题：</p><ul><li>代码重复问题</li><li>横切逻辑代码和业务代码混杂在一起，代码臃肿，不变维护</li></ul><p><strong>AOP 就是用来解决这些问题的</strong></p><p>AOP 另辟蹊径，提出横向抽取机制，将横切逻辑代码和业务逻辑代码分离</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411134119203.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/spring/ioc-aop/image-20200411134119203.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>代码拆分比较容易，难的是如何在不改变原有业务逻辑的情况下，悄无声息的将横向逻辑代码应用到原有的业务逻辑中，达到和原来一样的效果。</p><h3 id="AOP解决了什么问题"><a class="header-anchor" href="#AOP解决了什么问题">¶</a>AOP解决了什么问题</h3><p>通过上面的分析可以发现，AOP主要用来解决：在不改变原有业务逻辑的情况下，增强横切逻辑代码，根本上解耦合，避免横切逻辑代码重复。</p><h3 id="AOP为什么叫面向切面编程"><a class="header-anchor" href="#AOP为什么叫面向切面编程">¶</a>AOP为什么叫面向切面编程</h3><p><red><strong>切：</strong></red> 指的是横切逻辑，原有业务逻辑代码不动，只能操作横切逻辑代码，所以面向横切逻辑</p><p><green><strong>面：</strong></green> 横切逻辑代码往往要影响的是很多个方法，每个方法如同一个点，多个点构成一个面。这里有一个面的概念</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;下面从以下几个问题展开对 &lt;red&gt;IOC &amp;amp; AOP &lt;/red&gt; 的解释&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么是IOC？&lt;/li&gt;
&lt;li&gt;IOC解决了什么问题？&lt;/li&gt;
&lt;li&gt;IOC 和 DI 的区别？&lt;/li&gt;
&lt;li&gt;什么是AOP？&lt;/li&gt;
&lt;li&gt;AOP解决了什么问题？&lt;/li&gt;
&lt;li&gt;AOP为什么叫做切面变成？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;首先声明： &lt;red&gt;IOC &amp;amp; AOP &lt;/red&gt;  不是Spring提出来的，它们在Spring之前其实已经存在了，只不过当时更加偏向于理论。 Spring 在技术层次将这两个思想进行了很好的实现。&lt;/p&gt;</summary>
    
    
    
    <category term="Spring" scheme="https://gyl-coder.top/categories/Spring/"/>
    
    
    <category term="Spring" scheme="https://gyl-coder.top/tags/Spring/"/>
    
    <category term="IOC" scheme="https://gyl-coder.top/tags/IOC/"/>
    
    <category term="AOP" scheme="https://gyl-coder.top/tags/AOP/"/>
    
  </entry>
  
  <entry>
    <title>Settings.xml 详解</title>
    <link href="https://gyl-coder.top/java/settings/"/>
    <id>https://gyl-coder.top/java/settings/</id>
    <published>2020-04-01T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<p>从 <code>settings.xml</code> 的文件名就可以看出，它是用来设置 maven 参数的配置文件。settings.xml 中包含类似本地仓储位置、修改远程仓储服务器、认证信息等配置。</p><ul><li>settings.xml 是maven的<strong>全局配置文件</strong>。</li><li>pom.xml 文件是本地<strong>项目配置文件</strong>。</li></ul><a id="more"></a><h2 id="settings-xml-文件位置"><a class="header-anchor" href="#settings-xml-文件位置">¶</a>settings.xml 文件位置</h2><p>settings.xml 文件一般位于两个位置：</p><ul><li><p>全局配置</p><p>${maven.home}/conf/settings.xml</p></li><li><p>用户配置</p><p>${user.home}/.m2/settings.xml</p></li></ul><blockquote><p>**注意：**用户配置优先于全局配置。<code>$&#123;user.home&#125;</code> 和和所有其他系统属性只能在 3.0+版本上使用。</p></blockquote><h2 id="配置优先级"><a class="header-anchor" href="#配置优先级">¶</a>配置优先级</h2><blockquote><p>**重要：**局部配置优先于全局配置</p></blockquote><p>配置优先级从高到低：<code>pom.xml &gt; user settings &gt; global settings</code></p><p>如果这些文件同时存在，在应用配置时，会合并它们的内容，如果有重复的配置，优先级高的配置会覆盖优先级低的。</p><h2 id="settings-xml-元素详解"><a class="header-anchor" href="#settings-xml-元素详解">¶</a>settings.xml 元素详解</h2><h3 id="顶级元素概览"><a class="header-anchor" href="#顶级元素概览">¶</a>顶级元素概览</h3><pre><code>&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;      xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;      xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0                          https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt;  &lt;localRepository/&gt;  &lt;interactiveMode/&gt;  &lt;usePluginRegistry/&gt;  &lt;offline/&gt;  &lt;pluginGroups/&gt;  &lt;servers/&gt;  &lt;mirrors/&gt;  &lt;proxies/&gt;  &lt;profiles/&gt;  &lt;activeProfiles/&gt;&lt;/settings&gt;</code></pre><h3 id="LocalRepository"><a class="header-anchor" href="#LocalRepository">¶</a>LocalRepository</h3><p>**作用：**该值表示构建系统本地仓库的路径。</p><p>默认值：<code>~/.m2/repository</code></p><pre><code>&lt;localRepository&gt;$&#123;user.home&#125;/.m2/repository&lt;/localRepository&gt;</code></pre><h3 id="InteractiveMode"><a class="header-anchor" href="#InteractiveMode">¶</a>InteractiveMode</h3><p><strong>作用</strong>：表示 maven 是否需要和用户交互以获得输入。</p><p>如果 maven 需要和用户交互以获得输入，则设置成 true，反之则应为 false。默认为 true。</p><pre><code>&lt;interactiveMode&gt;true&lt;/interactiveMode&gt;</code></pre><h3 id="UsePluginRegistry"><a class="header-anchor" href="#UsePluginRegistry">¶</a>UsePluginRegistry</h3><p><strong>作用</strong>：maven 是否需要使用 <code>plugin-registry.xml</code> 文件来管理插件版本。</p><p>如果需要让 maven 使用文件<code>~/.m2/plugin-registry.xml</code> 来管理插件版本，则设为 true。默认为 false。</p><pre><code>&lt;usePluginRegistry&gt;false&lt;/usePluginRegistry&gt;</code></pre><h3 id="Offline"><a class="header-anchor" href="#Offline">¶</a>Offline</h3><p><strong>作用</strong>：表示 maven 是否需要在离线模式下运行。</p><p>如果构建系统需要在离线模式下运行，则为 true，默认为 false。</p><p>当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，该配置就十分有用。</p><pre><code>&lt;offline&gt;false&lt;/offline&gt;</code></pre><h3 id="PluginGroups"><a class="header-anchor" href="#PluginGroups">¶</a>PluginGroups</h3><p><strong>作用</strong>：当插件的组织 id（groupId）没有显式提供时，供搜寻插件组织 Id（groupId）的列表。</p><p>该元素包含一个 pluginGroup 元素列表，每个子元素包含了一个组织 Id（groupId）。</p><p>当我们使用某个插件，并且没有在命令行为其提供组织 Id（groupId）的时候，Maven 就会使用该列表。默认情况下该列表包含了 <code>org.apache.maven.plugins</code> 和 <code>org.codehaus.mojo</code>。</p><pre><code>&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0                      https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt;  ...  &lt;pluginGroups&gt;    &lt;!--plugin的组织Id（groupId） --&gt;    &lt;pluginGroup&gt;org.codehaus.mojo&lt;/pluginGroup&gt;  &lt;/pluginGroups&gt;  ...&lt;/settings&gt;</code></pre><h3 id="Servers"><a class="header-anchor" href="#Servers">¶</a>Servers</h3><p><strong>作用</strong>：一般，仓库的下载和部署是在 pom.xml 文件中的 <code>repositories</code> 和 <code>distributionManagement</code> 元素中定义的。然而，一般类似用户名、密码（<strong>有些仓库访问是需要安全认证的</strong>）等信息不应该在 pom.xml 文件中配置，这些信息可以配置在 <code>settings.xml</code> 中。</p><pre><code>&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0                      https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt;  ...  &lt;!--配置服务端的一些设置。一些设置如安全证书不应该和pom.xml一起分发。这种类型的信息应该存在于构建服务器上的settings.xml文件中。 --&gt;  &lt;servers&gt;    &lt;!--服务器元素包含配置服务器时需要的信息 --&gt;    &lt;server&gt;      &lt;!--这是server的id（注意不是用户登陆的id），该id与distributionManagement中repository元素的id相匹配。 --&gt;      &lt;id&gt;server001&lt;/id&gt;      &lt;!--鉴权用户名。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --&gt;      &lt;username&gt;my_login&lt;/username&gt;      &lt;!--鉴权密码 。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。密码加密功能已被添加到2.1.0 +。详情请访问密码加密页面 --&gt;      &lt;password&gt;my_password&lt;/password&gt;      &lt;!--鉴权时使用的私钥位置。和前两个元素类似，私钥位置和私钥密码指定了一个私钥的路径（默认是$&#123;user.home&#125;/.ssh/id_dsa）以及如果需要的话，一个密语。将来passphrase和password元素可能会被提取到外部，但目前它们必须在settings.xml文件以纯文本的形式声明。 --&gt;      &lt;privateKey&gt;$&#123;usr.home&#125;/.ssh/id_dsa&lt;/privateKey&gt;      &lt;!--鉴权时使用的私钥密码。 --&gt;      &lt;passphrase&gt;some_passphrase&lt;/passphrase&gt;      &lt;!--文件被创建时的权限。如果在部署的时候会创建一个仓库文件或者目录，这时候就可以使用权限（permission）。这两个元素合法的值是一个三位数字，其对应了unix文件系统的权限，如664，或者775。 --&gt;      &lt;filePermissions&gt;664&lt;/filePermissions&gt;      &lt;!--目录被创建时的权限。 --&gt;      &lt;directoryPermissions&gt;775&lt;/directoryPermissions&gt;    &lt;/server&gt;  &lt;/servers&gt;  ...&lt;/settings&gt;</code></pre><h3 id="Mirrors"><a class="header-anchor" href="#Mirrors">¶</a>Mirrors</h3><p><strong>作用</strong>：为仓库列表配置的下载镜像列表。</p><pre><code>&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0                      https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt;  ...  &lt;mirrors&gt;    &lt;!-- 给定仓库的下载镜像。 --&gt;    &lt;mirror&gt;      &lt;!-- 该镜像的唯一标识符。id用来区分不同的mirror元素。 --&gt;      &lt;id&gt;planetmirror.com&lt;/id&gt;      &lt;!-- 镜像名称 --&gt;      &lt;name&gt;PlanetMirror Australia&lt;/name&gt;      &lt;!-- 该镜像的URL。构建系统会优先考虑使用该URL，而非使用默认的服务器URL。 --&gt;      &lt;url&gt;http://downloads.planetmirror.com/pub/maven2&lt;/url&gt;      &lt;!-- 被镜像的服务器的id。例如，如果我们要设置了一个Maven中央仓库（http://repo.maven.apache.org/maven2/）的镜像，就需要将该元素设置成central。这必须和中央仓库的id central完全一致。 --&gt;      &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;    &lt;/mirror&gt;  &lt;/mirrors&gt;  ...&lt;/settings&gt;</code></pre><h3 id="Proxies"><a class="header-anchor" href="#Proxies">¶</a>Proxies</h3><p><strong>作用</strong>：用来配置不同的代理。</p><pre><code>&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0                      https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt;  ...  &lt;proxies&gt;    &lt;!--代理元素包含配置代理时需要的信息 --&gt;    &lt;proxy&gt;      &lt;!--代理的唯一定义符，用来区分不同的代理元素。 --&gt;      &lt;id&gt;myproxy&lt;/id&gt;      &lt;!--该代理是否是激活的那个。true则激活代理。当我们声明了一组代理，而某个时候只需要激活一个代理的时候，该元素就可以派上用处。 --&gt;      &lt;active&gt;true&lt;/active&gt;      &lt;!--代理的协议。 协议://主机名:端口，分隔成离散的元素以方便配置。 --&gt;      &lt;protocol&gt;http&lt;/protocol&gt;      &lt;!--代理的主机名。协议://主机名:端口，分隔成离散的元素以方便配置。 --&gt;      &lt;host&gt;proxy.somewhere.com&lt;/host&gt;      &lt;!--代理的端口。协议://主机名:端口，分隔成离散的元素以方便配置。 --&gt;      &lt;port&gt;8080&lt;/port&gt;      &lt;!--代理的用户名，用户名和密码表示代理服务器认证的登录名和密码。 --&gt;      &lt;username&gt;proxyuser&lt;/username&gt;      &lt;!--代理的密码，用户名和密码表示代理服务器认证的登录名和密码。 --&gt;      &lt;password&gt;somepassword&lt;/password&gt;      &lt;!--不该被代理的主机名列表。该列表的分隔符由代理服务器指定；例子中使用了竖线分隔符，使用逗号分隔也很常见。 --&gt;      &lt;nonProxyHosts&gt;*.google.com|ibiblio.org&lt;/nonProxyHosts&gt;    &lt;/proxy&gt;  &lt;/proxies&gt;  ...&lt;/settings&gt;</code></pre><h3 id="Profiles"><a class="header-anchor" href="#Profiles">¶</a>Profiles</h3><p><strong>作用</strong>：根据环境参数来调整构建配置的列表。</p><p><code>settings.xml</code> 中的 <code>profile</code> 元素是 <code>pom.xml</code> 中 <code>profile</code> 元素的<strong>裁剪版本</strong>。</p><p>它包含了<code>id</code>、<code>activation</code>、<code>repositories</code>、<code>pluginRepositories</code> 和 <code>properties</code> 元素。这里的 profile 元素只包含这五个子元素是因为这里只关心构建系统这个整体（这正是 settings.xml 文件的角色定位），而非单独的项目对象模型设置。如果一个 <code>settings.xml</code> 中的 <code>profile</code> 被激活，它的值会覆盖任何其它定义在 <code>pom.xml</code> 中带有相同 id 的 <code>profile</code>。</p><pre><code>&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0                      https://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt;  ...  &lt;profiles&gt;    &lt;profile&gt;      &lt;!-- profile的唯一标识 --&gt;      &lt;id&gt;test&lt;/id&gt;      &lt;!-- 自动触发profile的条件逻辑 --&gt;      &lt;activation /&gt;      &lt;!-- 扩展属性列表 --&gt;      &lt;properties /&gt;      &lt;!-- 远程仓库列表 --&gt;      &lt;repositories /&gt;      &lt;!-- 插件仓库列表 --&gt;      &lt;pluginRepositories /&gt;    &lt;/profile&gt;  &lt;/profiles&gt;  ...&lt;/settings&gt;</code></pre><h3 id="Activation"><a class="header-anchor" href="#Activation">¶</a>Activation</h3><p><strong>作用</strong>：自动触发 <code>profile</code> 的条件逻辑。</p><p>如 <code>pom.xml</code> 中的 <code>profile</code> 一样，<code>profile</code> 的作用在于它能够在某些特定的环境中自动使用某些特定的值；这些环境通过 <code>activation</code> 元素指定。<code>activation</code> 元素并不是激活 <code>profile</code> 的唯一方式。<code>settings.xml</code> 文件中的 <code>activeProfile</code> 元素可以包含 <code>profile</code> 的 <code>id</code>。<code>profile</code> 也可以通过在命令行，使用 <code>-P</code> 标记和逗号分隔的列表来显式的激活（如，<code>-P test</code>）。</p><pre><code>&lt;activation&gt;  &lt;!--profile默认是否激活的标识 --&gt;  &lt;activeByDefault&gt;false&lt;/activeByDefault&gt;  &lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --&gt;  &lt;jdk&gt;1.5&lt;/jdk&gt;  &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --&gt;  &lt;os&gt;    &lt;!--激活profile的操作系统的名字 --&gt;    &lt;name&gt;Windows XP&lt;/name&gt;    &lt;!--激活profile的操作系统所属家族(如 'windows') --&gt;    &lt;family&gt;Windows&lt;/family&gt;    &lt;!--激活profile的操作系统体系结构 --&gt;    &lt;arch&gt;x86&lt;/arch&gt;    &lt;!--激活profile的操作系统版本 --&gt;    &lt;version&gt;5.1.2600&lt;/version&gt;  &lt;/os&gt;  &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;name&#125;引用），其拥有对应的name = 值，Profile就会被激活。如果值字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --&gt;  &lt;property&gt;    &lt;!--激活profile的属性的名称 --&gt;    &lt;name&gt;mavenVersion&lt;/name&gt;    &lt;!--激活profile的属性的值 --&gt;    &lt;value&gt;2.0.3&lt;/value&gt;  &lt;/property&gt;  &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --&gt;  &lt;file&gt;    &lt;!--如果指定的文件存在，则激活profile。 --&gt;    &lt;exists&gt;$&#123;basedir&#125;/file2.properties&lt;/exists&gt;    &lt;!--如果指定的文件不存在，则激活profile。 --&gt;    &lt;missing&gt;$&#123;basedir&#125;/file1.properties&lt;/missing&gt;  &lt;/file&gt;&lt;/activation&gt;</code></pre><blockquote><p>注：在 maven 工程的 pom.xml 所在目录下执行 mvn help:active-profiles 命令可以查看中央仓储的 profile 是否在工程中生效。</p></blockquote><h3 id="properties"><a class="header-anchor" href="#properties">¶</a>properties</h3><p><strong>作用</strong>：对应<code>profile</code>的扩展属性列表。</p><p>maven 属性和 ant 中的属性一样，可以用来存放一些值。这些值可以在 <code>pom.xml</code> 中的任何地方使用标记${X}来使用，这里 X 是指属性的名称。属性有五种不同的形式，并且都能在 settings.xml 文件中访问。</p><pre><code>&lt;!--  1. env.X: 在一个变量前加上&quot;env.&quot;的前缀，会返回一个shell环境变量。例如,&quot;env.PATH&quot;指代了$path环境变量（在Windows上是%PATH%）。  2. project.x：指代了POM中对应的元素值。例如: &lt;project&gt;&lt;version&gt;1.0&lt;/version&gt;&lt;/project&gt;通过$&#123;project.version&#125;获得version的值。  3. settings.x: 指代了settings.xml中对应元素的值。例如：&lt;settings&gt;&lt;offline&gt;false&lt;/offline&gt;&lt;/settings&gt;通过 $&#123;settings.offline&#125;获得offline的值。  4. Java System Properties: 所有可通过java.lang.System.getProperties()访问的属性都能在POM中使用该形式访问，例如 $&#123;java.home&#125;。  5. x: 在&lt;properties/&gt;元素中，或者外部文件中设置，以$&#123;someVar&#125;的形式使用。 --&gt;&lt;properties&gt;  &lt;user.install&gt;$&#123;user.home&#125;/our-project&lt;/user.install&gt;&lt;/properties&gt;</code></pre><div class="note "><p>注：如果该 profile 被激活，则可以在pom.xml中使用${user.install}。</p></div> <h3 id="Repositories"><a class="header-anchor" href="#Repositories">¶</a>Repositories</h3><p><strong>作用</strong>：远程仓库列表，它是 maven 用来填充构建系统本地仓库所使用的一组远程仓库。</p><pre><code>&lt;repositories&gt;  &lt;!--包含需要连接到远程仓库的信息 --&gt;  &lt;repository&gt;    &lt;!--远程仓库唯一标识 --&gt;    &lt;id&gt;codehausSnapshots&lt;/id&gt;    &lt;!--远程仓库名称 --&gt;    &lt;name&gt;Codehaus Snapshots&lt;/name&gt;    &lt;!--如何处理远程仓库里发布版本的下载 --&gt;    &lt;releases&gt;      &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt;      &lt;enabled&gt;false&lt;/enabled&gt;      &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --&gt;      &lt;updatePolicy&gt;always&lt;/updatePolicy&gt;      &lt;!--当Maven验证构件校验文件失败时该怎么做-ignore（忽略），fail（失败），或者warn（警告）。 --&gt;      &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt;    &lt;/releases&gt;    &lt;!--如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt;    &lt;snapshots&gt;      &lt;enabled /&gt;      &lt;updatePolicy /&gt;      &lt;checksumPolicy /&gt;    &lt;/snapshots&gt;    &lt;!--远程仓库URL，按protocol://hostname/path形式 --&gt;    &lt;url&gt;http://snapshots.maven.codehaus.org/maven2&lt;/url&gt;    &lt;!--用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --&gt;    &lt;layout&gt;default&lt;/layout&gt;  &lt;/repository&gt;&lt;/repositories&gt;</code></pre><h3 id="pluginRepositories"><a class="header-anchor" href="#pluginRepositories">¶</a>pluginRepositories</h3><p><strong>作用</strong>：发现插件的远程仓库列表。</p><p>和 <code>repository</code> 类似，只是 <code>repository</code> 是管理 jar 包依赖的仓库，<code>pluginRepositories</code> 则是管理插件的仓库。maven 插件是一种特殊类型的构件。由于这个原因，插件仓库独立于其它仓库。<code>pluginRepositories</code> 元素的结构和 <code>repositories</code> 元素的结构类似。每个 <code>pluginRepository</code> 元素指定一个 Maven 可以用来寻找新插件的远程地址。</p><pre><code>pluginRepositoriespluginRepositoryreleasesenabledupdatePolicychecksumPolicyreleasessnapshotsenabledupdatePolicychecksumPolicysnapshotsidnameurllayoutpluginRepositorypluginRepositories</code></pre><h3 id="ActiveProfiles"><a class="header-anchor" href="#ActiveProfiles">¶</a>ActiveProfiles</h3><p><strong>作用</strong>：手动激活 profiles 的列表，按照<code>profile</code>被应用的顺序定义<code>activeProfile</code>。</p><p>该元素包含了一组 <code>activeProfile</code> 元素，每个 <code>activeProfile</code> 都含有一个 profile id。任何在 <code>activeProfile</code> 中定义的 profile id，不论环境设置如何，其对应的 <code>profile</code> 都会被激活。如果没有匹配的 <code>profile</code>，则什么都不会发生。</p><p>例如，env-test 是一个 activeProfile，则在 pom.xml（或者 profile.xml）中对应 id 的 profile 会被激活。如果运行过程中找不到这样一个 profile，Maven 则会像往常一样运行。</p><pre><code>settingsactiveProfilesactiveProfileactiveProfileactiveProfilessettings</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;从 &lt;code&gt;settings.xml&lt;/code&gt; 的文件名就可以看出，它是用来设置 maven 参数的配置文件。settings.xml 中包含类似本地仓储位置、修改远程仓储服务器、认证信息等配置。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;settings.xml 是maven的&lt;strong&gt;全局配置文件&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;pom.xml 文件是本地&lt;strong&gt;项目配置文件&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="settings" scheme="https://gyl-coder.top/tags/settings/"/>
    
  </entry>
  
  <entry>
    <title>MyBatis 入门</title>
    <link href="https://gyl-coder.top/mybatis/mybatis-beginner/"/>
    <id>https://gyl-coder.top/mybatis/mybatis-beginner/</id>
    <published>2020-03-29T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<p>MyBatis 是一款优秀的基于 ORM 的半自动轻量级持久层框架。它支持定制化SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的POJO（Plain Old Java Objects，普通老式Java 对象）为数据库的记录。</p><p>MyBatis 原本是Apache 的一个开源项目IBatis，2010年6月这个项目由 Apache Software Foundation 迁移到了 Google Code，随后更名为 <red>MyBatis</red> 。</p><p>iBatis 一词来源于 “internet” 和 “abatis” 的组合，是一个基于Java的持久层框架。</p><div class="tag link"><a class="link-card" title="官网地址" href="https://mybatis.org/mybatis-3/"><div class="left"><img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div><div class="right"><p class="text">官网地址</p><p class="url">https://mybatis.org/mybatis-3/</p></div></a></div><a id="more"></a><p>上面简单介绍了一下 MyBatis ，下面我们来看下MyBatis 的优势</p><h2 id="MyBatis-的优势-劣势"><a class="header-anchor" href="#MyBatis-的优势-劣势">¶</a>MyBatis 的优势&amp;劣势</h2><h3 id="优势"><a class="header-anchor" href="#优势">¶</a>优势</h3><p>我认为 MyBatis 有以下几点优势</p><ul><li><strong>简单易学</strong> MyBatis 本身体积较小且没有第三方依赖，使用起来简单容易上手。源码也比较容易看懂</li><li><strong>边界清晰</strong> MyBatis 是一个半自动化的持久层框架，Sql 和 Java代码分开，功能边界较为清晰。一个专注业务，一个专注数据。</li><li><strong>代码量相对较少</strong> 因为MyBatis核心是对JDBC代码的封装，避免开发人员写大量重复的代码。</li></ul><h3 id="劣势"><a class="header-anchor" href="#劣势">¶</a>劣势</h3><ul><li>依赖SQL 要求开发人员有一定的SQL 功底</li><li>SQL 语句的编写工作量大（表多，表结构复杂时）</li><li>数据库移植性差（针对不同的数据库SQL 有差异）</li></ul><h2 id="MyBatis-基本应用"><a class="header-anchor" href="#MyBatis-基本应用">¶</a>MyBatis 基本应用</h2><h3 id="开发步骤"><a class="header-anchor" href="#开发步骤">¶</a>开发步骤</h3><p>如果要在工程中使用MyBatis 基本流程如下：</p><ol><li>在pom 文件中添加Mybatis 的依赖</li><li>创建表结构</li><li>编写表结构所对应的实体类 xxx.java</li><li>编写对应实体类的映射文件 xxxMapper.xml</li><li>编写MyBatis 的核心配置文件 SqlMapConfig.xml</li><li>编写测试类</li></ol><p>下面我们通过使用MyBatis 对一个User 实体进行CRUD 操作。</p><h4 id="引入相关依赖"><a class="header-anchor" href="#引入相关依赖">¶</a>引入相关依赖</h4><p>在工程所在的 pom 文件中加入以下依赖</p><pre><code>    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.encoding&gt;UTF-8&lt;/maven.compiler.encoding&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;!--mybatis 依赖--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;            &lt;version&gt;3.4.5&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--mysql 依赖--&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;5.1.6&lt;/version&gt;            &lt;scope&gt;runtime&lt;/scope&gt;        &lt;/dependency&gt;        &lt;!-- 单元测试依赖 --&gt;        &lt;dependency&gt;            &lt;groupId&gt;junit&lt;/groupId&gt;            &lt;artifactId&gt;junit&lt;/artifactId&gt;            &lt;version&gt;4.12&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;</code></pre><h4 id="创建User-表结构"><a class="header-anchor" href="#创建User-表结构">¶</a>创建User 表结构</h4><p>在数据库中建立一个简单的User 表结构</p><table><thead><tr><th style="text-align:center">字段名</th><th style="text-align:center">字段类型</th><th style="text-align:center">长度</th></tr></thead><tbody><tr><td style="text-align:center">id</td><td style="text-align:center">int</td><td style="text-align:center">11</td></tr><tr><td style="text-align:center">username</td><td style="text-align:center">varchar</td><td style="text-align:center">50</td></tr><tr><td style="text-align:center">password</td><td style="text-align:center">varchar</td><td style="text-align:center">50</td></tr></tbody></table><h4 id="编写User-实体"><a class="header-anchor" href="#编写User-实体">¶</a>编写User 实体</h4><p>这里为了减少代码量，引入了 lombok</p><pre><code>@Getter@Setter@ToStringpublic class User &amp;#123;    /** 用户Id */    private int id;    /** 用户名 */    private String username;    /** 用户密码 */    private String password;&amp;#125;</code></pre><h4 id="编写UserMapper-映射文件"><a class="header-anchor" href="#编写UserMapper-映射文件">¶</a>编写UserMapper 映射文件</h4><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper  PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot;  &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;mapper namespace=&quot;com.yanliang.mockTest.dao.IUserDao&quot;&gt;    &lt;!-- 查询所有 --&gt;    &lt;select id=&quot;selectList&quot; resultType=&quot;com.yanliang.mockTest.User&quot;&gt;        select * from user    &lt;/select&gt;    &lt;!-- 查询单个对象 --&gt;    &lt;select id=&quot;selectOne&quot; resultType=&quot;com.yanliang.mockTest.User&quot; paramterType=&quot;com.yanliang.mockTest.User&quot;&gt;        select * from user where id = #&amp;#123;id&amp;#125; and username = #&amp;#123;username&amp;#125;    &lt;/select&gt;    &lt;!--    插入--&gt;    &lt;insert id=&quot;insert&quot; parameterType=&quot;com.yanliang.mockTest.User&quot;&gt;        insert into user        values ( #&amp;#123;id&amp;#125;, #&amp;#123;username&amp;#125; )    &lt;/insert&gt;    &lt;!--    删除--&gt;    &lt;delete id=&quot;delete&quot; parameterType=&quot;java.lang.Integer&quot;&gt;        delete from user where id = #&amp;#123;id&amp;#125;    &lt;/delete&gt;    &lt;!--    更新--&gt;    &lt;update id=&quot;update&quot; parameterType=&quot;com.yanliang.mockTest.User&quot;&gt;        update user set username = #&amp;#123;username&amp;#125;        where id = #&amp;#123;id&amp;#125;    &lt;/update&gt;&lt;/mapper&gt;</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;MyBatis 是一款优秀的基于 ORM 的半自动轻量级持久层框架。它支持定制化SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的POJO（Plain Old Java Objects，普通老式Java 对象）为数据库的记录。&lt;/p&gt;
&lt;p&gt;MyBatis 原本是Apache 的一个开源项目IBatis，2010年6月这个项目由 Apache Software Foundation 迁移到了 Google Code，随后更名为 &lt;red&gt;MyBatis&lt;/red&gt; 。&lt;/p&gt;
&lt;p&gt;iBatis 一词来源于 “internet” 和 “abatis” 的组合，是一个基于Java的持久层框架。&lt;/p&gt;
&lt;div class=&quot;tag link&quot;&gt;&lt;a class=&quot;link-card&quot; title=&quot;官网地址&quot; href=&quot;https://mybatis.org/mybatis-3/&quot;&gt;&lt;div class=&quot;left&quot;&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png&quot;/&gt;&lt;/div&gt;&lt;div class=&quot;right&quot;&gt;&lt;p class=&quot;text&quot;&gt;官网地址&lt;/p&gt;&lt;p class=&quot;url&quot;&gt;https://mybatis.org/mybatis-3/&lt;/p&gt;&lt;/div&gt;&lt;/a&gt;&lt;/div&gt;</summary>
    
    
    
    <category term="Mybatis" scheme="https://gyl-coder.top/categories/Mybatis/"/>
    
    
    <category term="Mybatis" scheme="https://gyl-coder.top/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>HashMap 底层实现原理分析</title>
    <link href="https://gyl-coder.top/java/collection/HashMapAnalysis/"/>
    <id>https://gyl-coder.top/java/collection/HashMapAnalysis/</id>
    <published>2020-03-22T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<p><code>HashMap</code> 是 <code>Map</code> 的一个实现类，它代表的是一种键值对的数据存储形式。</p><p>大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。</p><p><code>HashMap</code>最多只允许一条记录的键为<code>null</code>，允许多条记录的值为<code>null</code>。不保证有序 (比如插入的顺序)、也不保证序不随时间变化。</p><p><code>jdk 8</code> 之前，其内部是由 <red>数组 + 链表</red> 来实现的，而 <code>jdk 8</code> 对于链表长度超过 <green>8</green> 的链表将转储为 <yellow>红黑树</yellow>。</p><p><code>HashMap</code>非线程安全，即任一时刻可以有多个线程同时写<code>HashMap</code>，可能会导致数据的不一致。如果需要满足线程安全，可以用 <code>Collections</code>的<code>synchronizedMap</code>方法使<code>HashMap</code>具有线程安全的能力，或者使用<code>ConcurrentHashMap</code>。</p><p><code>HashMap</code>是 <blue>数组 + 链表 + 红黑树</blue>（JDK1.8 增加了红黑树部分）实现的。JDK 1.8 之所以添加红黑树是因为一旦链表过长，会严重影响 HashMap 的性能，而红黑树具有快速增删改查的特点，这样就可以有效的解决链表过长时操作比较慢的问题。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323120021.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323120021.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><a id="more"></a><h2 id="存储结构"><a class="header-anchor" href="#存储结构">¶</a>存储结构</h2><blockquote><p>下面我们先来看一下 HashMap 内部所用到的存储结构</p></blockquote><pre><code class="language-java">static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &amp;#123;    final int hash;    final K key;    V value;    Node&lt;K,V&gt; next;    Node(int hash, K key, V value, Node&lt;K,V&gt; next) &amp;#123;        this.hash = hash;        this.key = key;        this.value = value;        this.next = next;    &amp;#125;    public final K getKey()        &amp;#123; return key; &amp;#125;    public final V getValue()      &amp;#123; return value; &amp;#125;    public final String toString() &amp;#123; return key + &quot;=&quot; + value; &amp;#125;    public final int hashCode() &amp;#123;        return Objects.hashCode(key) ^ Objects.hashCode(value);    &amp;#125;    public final V setValue(V newValue) &amp;#123;        V oldValue = value;        value = newValue;        return oldValue;    &amp;#125;    public final boolean equals(Object o) &amp;#123;        if (o == this)            return true;        if (o instanceof Map.Entry) &amp;#123;            Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;            if (Objects.equals(key, e.getKey()) &amp;&amp;                Objects.equals(value, e.getValue()))                return true;        &amp;#125;        return false;    &amp;#125;&amp;#125;</code></pre><p>可以看出每个哈希桶中包含了四个字段：hash、key、value、next，其中 next 表示链表的下一个节点。</p><p><code>Node</code>是<code>HashMap</code>的一个内部类，实现了 Map.Entry 接口，本质上就是一个映射 (键值对)。</p><p>有时两个<code>key</code>会定位到相同的位置，表示发生了 <cyan>Hash 碰撞</cyan>。当然<code>Hash</code>算法计算结果越分散均匀，<code>Hash</code>碰撞的概率就越小，<code>map</code>的存取效率就会越高。</p><p><code>HashMap</code>类中有一个非常重要的字段，就是 <code>Node[] table</code>，即哈希桶数组。如果哈希桶数组很大，即使较差的<code>Hash</code>算法也会比较分散，如果哈希桶数组数组很小，即使好的<code>Hash</code>算法也会出现较多碰撞。</p><p>所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的<code>hash</code>算法减少 <cyan>Hash 碰撞</cyan>。那么通过什么方式来控制 map 使得 Hash 碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是好的 Hash 算法和扩容机制。</p><p>上面大体介绍了 <code>HashMap</code> 的组成结构，下面我们来看一些关于 <code>HashMap</code> 的核心问题。</p><ul><li>HashMap 中的hash算法如何实现？</li><li>JDK1.8HashMap扩容时做了哪些优化？</li><li>加载因子为什么是0.75？</li><li>当有哈希冲突时，HashMap是如何查找并确认元素的？HashMap源码中有哪些重要的方法？</li><li>HashMap 源码中有哪些重要的方法？</li></ul><h2 id="成员变量"><a class="header-anchor" href="#成员变量">¶</a>成员变量</h2><p>不过在这之前我们先了解下 hashmap 中的变量</p><pre><code class="language-java">// HashMap 初始化长度static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // HashMap 最大长度static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 默认的加载因子 （扩容因子）static final float DEFAULT_LOAD_FACTOR = 0.75f;// 当链表长度大于此值且容量大于64时static final int TREEIFY_THRESHOLD = 8;// 转换链表的临界值，当元素小于此值时，将红黑树转换为链表结构static final int UNTREEIFY_THRESHOLD = 6;// 最小数容量static final int MIN_TREEIFY_CAPACITY = 64;transient Node&lt;K,V&gt;[] table;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;transient int size;    transient int modCount; int threshold;  final float loadFactor;</code></pre><div class="note "><p>在 HashMap 中有两个很重要的参数，容量 (Capacity) 和负载因子(Load factor)</p></div><p><code>Capacity</code>就是<code>buckets</code>的数目，<code>Load factor</code>就是<code>buckets</code>填满程度的最大比例。如果对迭代性能要求很高的话不要把<code>capacity</code>设置过大，也不要把<code>load factor</code>设置过小。当<code>bucket</code>填充的数目（即 hashmap 中元素的个数）大于<code>capacity*load factor</code>时就需要调整 buckets 的数目为当前的 <strong>2 倍</strong>。</p><h2 id="HashMap-中的hash算法如何实现？"><a class="header-anchor" href="#HashMap-中的hash算法如何实现？">¶</a>HashMap 中的hash算法如何实现？</h2><pre><code class="language-java">static final int hash(Object key) &amp;#123;    int h;    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&amp;#125;static int indexFor(int h, int length) &amp;#123;       return h &amp; (length-1);  &amp;#125;</code></pre><blockquote><p>indexFor 是 jdk1.7 的源码，jdk1.8 没有这个方法但是 jdk1.8 也是通过取模运算来计算的</p></blockquote><p>这里的 Hash 算法本质上就是三步：</p><ol><li>取 key 的 hashCode 值</li><li>高位运算</li><li>取模运算</li></ol><p>对于任意给定的对象，只要它的<code>hashCode()</code>返回值相同，那么程序调用方法一所计算得到的<code>Hash</code>码值总是相同的。我们首先想到的就是把<code>hash</code>值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，这里我们用 <code>&amp;</code> 位运算来优化效率。</p><p>这个方法非常巧妙，它通过<code>h &amp; (table.length -1)</code>来得到该对象的保存位，而<code>HashMap</code>底层数组的长度总是 <strong>2 的 n 次方</strong>，这是<code>HashMap</code>在速度上的优化。当 length 总是 2 的 n 次方时，<code>h&amp; (length-1)</code>运算等价于对 length 取模，也就是<code>h%length</code>，但是 <strong>&amp;</strong> 比 <strong>%</strong> 具有更高的效率。</p><p>在<code>JDK1.8</code>的实现中，优化了高位运算的算法，通过<code>hashCode()</code>的高 16 位异或低 16 位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以 Node 数组 table 的 length 比较小的时候，也能保证考虑到高低 Bit 都参与到 Hash 的计算中，同时不会有太大的开销。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323122051.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323122051.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h2 id="JDK1-8HashMap扩容时做了哪些优化？"><a class="header-anchor" href="#JDK1-8HashMap扩容时做了哪些优化？">¶</a>JDK1.8HashMap扩容时做了哪些优化？</h2><p>扩容 (resize) 就是重新计算容量，向<code>HashMap</code>对象里不停的添加元素，而<code>HashMap</code>对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。</p><p>当然<code>Java</code>里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。</p><p>当<code>put</code>时，如果发现目前的<code>bucket</code>占用程度已经超过了<code>Load Factor</code>所希望的比例，那么就会发生<code>resize</code>。在<code>resize</code>的过程，简单的说就是把<code>bucket</code>扩充为 <strong>2 倍</strong>，之后重新计算<code>index</code>，把节点再放到新的<code>bucket</code>中。<br>因为我们使用的是 2 次幂的扩展 (指长度扩为原来 2 倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动 2 次幂的位置。</p><p>例如我们从 16 扩展为 32 时，具体的变化如下所示：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323122216.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323122216.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>因此元素在重新计算<code>hash</code>之后，因为 n 变为 2 倍，那么 n-1 的 mask 范围在高位多 1bit(红色)，因此新的 index 就会发生这样的变化：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323122224.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323122224.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>因此，我们在扩充<code>HashMap</code>的时候，不需要重新计算<code>hash</code>，只需要看看原来的<code>hash</code>值新增的那个 bit 是 1 还是 0 就好了，是 0 的话索引没变，是 1 的话索引变成 “原索引 + oldCap”。</p><p>这个设计确实非常的巧妙，既省去了重新计算 hash 值的时间，而且同时，由于新增的 1bit 是 0 还是 1 可以认为是随机的，因此<code>resize</code>的过程，均匀的把之前的冲突的节点分散到新的<code>bucket</code>了。</p><pre><code class="language-java">final Node&lt;K,V&gt;[] resize() &amp;#123;    // 扩容前的数组    Node&lt;K,V&gt;[] oldTab = table;        // 扩容前的数组大小和阈值    int oldCap = (oldTab == null) ? 0 : oldTab.length;    int oldThr = threshold;    // 预定义新数组的大小和阈值    int newCap, newThr = 0;    if (oldCap &gt; 0) &amp;#123;            // 超过最大值就不再扩容了        if (oldCap &gt;= MAXIMUM_CAPACITY) &amp;#123;               threshold = Integer.MAX_VALUE;            return oldTab;        &amp;#125;            // 扩大容量为当前容量的两倍，但不能超过 MAXIMUM_CAPACITY        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)            newThr = oldThr &lt;&lt; 1;       &amp;#125;    // 当前数组没有数据，使用初始化的值    else if (oldThr &gt; 0)         newCap = oldThr;    else &amp;#123;            // 如果初始化的值为 0， 则使用默认的初始化容量        newCap = DEFAULT_INITIAL_CAPACITY;        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);    &amp;#125;            if (newThr == 0) &amp;#123;           float ft = (float)newCap * loadFactor;        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?                  (int)ft : Integer.MAX_VALUE);    &amp;#125;    threshold = newThr;    @SuppressWarnings(&amp;#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&amp;#125;)    Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];          // 开始扩容，将新的容量赋值给 table    table = newTab;    // 原数据不为空，将原始的容量复制到新 table 中    if (oldTab != null) &amp;#123;        // 根据容量循环数组，复制非空元素到新 table         for (int j = 0; j &lt; oldCap; ++j) &amp;#123;                 Node&lt;K,V&gt; e;            if ((e = oldTab[j]) != null) &amp;#123;                  oldTab[j] = null;                // 如果链表只有一个，则进行直接赋值                if (e.next == null)                       newTab[e.hash &amp; (newCap - 1)] = e;                else if (e instanceof TreeNode)                      // 红黑树相关的操作                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);                else &amp;#123;                       // 链表复制,JDK 1.8 扩容优化部分                    Node&lt;K,V&gt; loHead = null, loTail = null;                    Node&lt;K,V&gt; hiHead = null, hiTail = null;                    Node&lt;K,V&gt; next;                    do &amp;#123;                        next = e.next;                        // 原索引                        if ((e.hash &amp; oldCap) == 0) &amp;#123;                                if (loTail == null)                                loHead = e;                            else                                loTail.next = e;                            loTail = e;                        &amp;#125;                        // 原索引 + oldCap                        else &amp;#123;                                                      if (hiTail == null)                                hiHead = e;                            else                                hiTail.next = e;                            hiTail = e;                        &amp;#125;                    &amp;#125; while ((e = next) != null);                    // 将原索引放入到哈希桶中                    if (loTail != null) &amp;#123;                              loTail.next = null;                        newTab[j] = loHead;                    &amp;#125;                    // 将原索引 + oldCap 放到哈希桶中                    if (hiTail != null) &amp;#123;                             hiTail.next = null;                        newTab[j + oldCap] = hiHead;                    &amp;#125;                &amp;#125;            &amp;#125;        &amp;#125;    &amp;#125;    return newTab;&amp;#125;</code></pre><h2 id="加载因子为什么是0-75？"><a class="header-anchor" href="#加载因子为什么是0-75？">¶</a>加载因子为什么是0.75？</h2><p>加载因子也叫扩容因子或负载因子，用来判断什么时候进行扩容的，假如加载因子是 0.5，HashMap 的初始化容量是 16，那么当 HashMap 中有 16*0.5=8 个元素时，HashMap 就会进行扩容。</p><p>那加载因子为什么是 0.75 而不是 0.5 或者 1.0 呢？</p><p>这其实是出于容量和性能之间平衡的结果：</p><ul><li>当加载因子设置比较大的时候，扩容的门槛就被提高了，扩容发生的频率比较低，占用的空间会比较小，但此时发生 Hash 冲突的几率就会提升，因此需要更复杂的数据结构来存储元素，这样对元素的操作时间就会增加，运行效率也会因此降低；</li><li>而当加载因子值比较小的时候，扩容的门槛会比较低，因此会占用更多的空间，此时元素的存储就比较稀疏，发生哈希冲突的可能性就比较小，因此操作性能会比较高。</li></ul><p>所以综合了以上情况就取了一个 0.5 到 1.0 的平均数 0.75 作为加载因子。</p><ul><li>当有哈希冲突时，HashMap是如何查找并确认元素的？</li><li>HashMap 源码中有哪些重要的方法？</li></ul><h2 id="HashMap-中的核心方法"><a class="header-anchor" href="#HashMap-中的核心方法">¶</a>HashMap 中的核心方法</h2><p>HashMap 源码中三个重要方法：查询、新增和数据扩容。</p><h3 id="查询"><a class="header-anchor" href="#查询">¶</a>查询</h3><p>bucket 里的第一个节点，直接命中；<br>如果有冲突，则通过 key.equals(k) 去查找对应的 entry<br>若为树，则在树中通过 key.equals(k) 查找，O(logn)；<br>若为链表，则在链表中通过 key.equals(k) 查找，O(n)。</p><p>具体代码的实现如下：</p><pre><code class="language-java">public V get(Object key) &amp;#123;    Node&lt;K,V&gt; e;    // 对 key 进行哈希操作    return (e = getNode(hash(key), key)) == null ? null : e.value;&amp;#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &amp;#123;    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;    // 非空判断    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;        (first = tab[(n - 1) &amp; hash]) != null) &amp;#123;                // 判断第一个元素是否是要查询的元素        if (first.hash == hash &amp;&amp;             ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))            return first;        // 一下一个节点非空判断        if ((e = first.next) != null) &amp;#123;            // 如果第一节点是树结构，则使用 getTreeNode 直接获取相应的数据            if (first instanceof TreeNode)                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);            // 非树结构循环节点判断            do &amp;#123;                // hash 相等并且 key 相同，则返回此节点                if (e.hash == hash &amp;&amp;                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                    return e;            &amp;#125; while ((e = e.next) != null);        &amp;#125;    &amp;#125;    return null;&amp;#125;</code></pre><p>从以上源码可以看出，当哈希冲突时我们需要通过判断 key 值是否相等，才能确认此元素是不是我们想要的元素。</p><h3 id="新增"><a class="header-anchor" href="#新增">¶</a>新增</h3><p><code>put</code> 方法也是<code>HashMap</code>中比较重要的方法，因为通过该方法我们可以窥探到 <code>HashMap</code> 在内部是如何进行数据存储的，所谓的<red>数组 + 链表 + 红黑树</red>的存储结构是如何形成的，又是在何种情况下将链表转换成红黑树来优化性能的。</p><p>put 方法的大致实现过程如下：</p><ul><li>对 key 的 hashCode() 做 hash，然后再计算 index;</li><li>如果没碰撞直接放到 bucket 里；</li><li>如果碰撞了，以链表的形式存在 buckets 后；</li><li>如果碰撞导致链表过长 (大于等于 TREEIFY_THRESHOLD)，就把链表转换成红黑树；</li><li>如果节点已经存在就替换 old value(保证 key 的唯一性)</li><li>如果 bucket 满了 (超过 load factor*current capacity)，就要 resize。</li></ul><pre><code class="language-java">public V put(K key, V value) &amp;#123;        // 对 key 进行哈希操作    return putVal(hash(key), key, value, false, true);&amp;#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent,               boolean evict) &amp;#123;    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;        // 哈希表为空则创建    if ((tab = table) == null || (n = tab.length) == 0)           n = (tab = resize()).length;    // 根据 key 的哈希值计算出要插入的数组索引 i    if ((p = tab[i = (n - 1) &amp; hash]) == null)           // 如果 table[i] = null 则直接插入        tab[i] = newNode(hash, key, value, null);    else &amp;#123;           Node&lt;K,V&gt; e; K k;            // 如果 key 已经存在了，直接覆盖 value        if (p.hash == hash &amp;&amp;                   ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))            e = p;        // 如果 key 不存在，判断是否为红黑树        else if (p instanceof TreeNode)               // 红黑树直接插入键值对            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);        else &amp;#123;             // 链表结构，循环准备插入            for (int binCount = 0; ; ++binCount) &amp;#123;                // 下一个元素为空时                if ((e = p.next) == null) &amp;#123;                    p.next = newNode(hash, key, value, null);                    // 转换为红黑树进行处理                    if (binCount &gt;= TREEIFY_THRESHOLD - 1)                         treeifyBin(tab, hash);                    break;                &amp;#125;                // key 已经存在直接覆盖 value                if (e.hash == hash &amp;&amp;                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                    break;                p = e;            &amp;#125;        &amp;#125;          if (e != null) &amp;#123;             V oldValue = e.value;            if (!onlyIfAbsent || oldValue == null)                e.value = value;            afterNodeAccess(e);            return oldValue;        &amp;#125;    &amp;#125;    ++modCount;        // 超过最大容量，扩容    if (++size &gt; threshold)        resize();    afterNodeInsertion(evict);    return null;&amp;#125;</code></pre><p>新增方法的执行流程，如下图所示：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323143244.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323143244.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h2 id="HashMap-死循环分析"><a class="header-anchor" href="#HashMap-死循环分析">¶</a>HashMap 死循环分析</h2><p>以 JDK 1.7 为例，假设 HashMap 默认大小为 2，原本 HashMap 中有一个元素 key(5)，我们再使用两个线程：t1 添加元素 key(3)，t2 添加元素 key(7)，当元素 key(3) 和 key(7) 都添加到 HashMap 中之后，线程 t1 在执行到 Entry&lt;K,V&gt; next = e.next; 时，交出了 CPU 的使用权，源码如下：</p><pre><code class="language-java">void transfer(Entry[] newTable, boolean rehash) &amp;#123;    int newCapacity = newTable.length;    for (Entry&lt;K,V&gt; e: table) &amp;#123;        while (null != e) &amp;#123;            Entry&lt;K,V&gt; next = e.next; // 线程一执行到此处            if(rehash) &amp;#123;                e.hash = null == e.key ? 0 : hash(key);            &amp;#125;            int i = indexFor(e.hash, newCapacity);            e.next = newTable[i];            newTable[i] = e;            e = next;        &amp;#125;    &amp;#125;&amp;#125;</code></pre><p>那么此时线程 t1 中的 e 指向了 key(3)，而 next 指向了 key(7) ；之后线程 t2 重新 rehash 之后链表的顺序被反转，链表的位置变成了 key(5) → key(7) → key(3)，其中 “→” 用来表示下一个元素。</p><p>当 t1 重新获得执行权之后，先执行 newTalbe[i] = e 把 key(3) 的 next 设置为 key(7)，而下次循环时查询到 key(7) 的 next 元素为 key(3)，于是就形成了 key(3) 和 key(7) 的循环引用，因此就导致了死循环的发生，如下图所示：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323151453.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323151453.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>当然发生死循环的原因是 JDK 1.7 链表插入方式为首部倒序插入，这个问题在 JDK 1.8 得到了改善，变成了尾部正序插入。</p><div class="tag link"><a class="link-card" title="参考文章" href="https://coolshell.cn/articles/9606.html"><div class="left"><img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div><div class="right"><p class="text">参考文章</p><p class="url">https://coolshell.cn/articles/9606.html</p></div></a></div><h2 id="其他方法"><a class="header-anchor" href="#其他方法">¶</a>其他方法</h2><h3 id="构造方法"><a class="header-anchor" href="#构造方法">¶</a>构造方法</h3><pre><code class="language-java">public HashMap(int initialCapacity, float loadFactor) &amp;#123;    if (initialCapacity &lt; 0)        throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; +                                           initialCapacity);    if (initialCapacity &gt; MAXIMUM_CAPACITY)        initialCapacity = MAXIMUM_CAPACITY;    if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))        throw new IllegalArgumentException(&quot;Illegal load factor: &quot; +                                           loadFactor);    this.loadFactor = loadFactor;    this.threshold = tableSizeFor(initialCapacity);&amp;#125;</code></pre><p>这是一个最基本的构造函数，需要调用方传入两个参数，<strong>initialCapacity</strong> 和 <strong>loadFactor</strong>。</p><p>程序的大部分代码在判断传入参数的合法性，<strong>initialCapacity</strong> 小于零将抛出异常，大于 <strong>MAXIMUM_CAPACITY</strong> 将被限定为 <strong>MAXIMUM_CAPACITY</strong>。<strong>loadFactor</strong> 如果小于等于零或者非数字类型也会抛出异常。</p><p><strong>整个构造函数的核心在对 threshold 的初始化操作：</strong></p><pre><code>static final int tableSizeFor(int cap) &amp;#123;    int n = cap - 1;    n |= n &gt;&gt;&gt; 1;    n |= n &gt;&gt;&gt; 2;    n |= n &gt;&gt;&gt; 4;    n |= n &gt;&gt;&gt; 8;    n |= n &gt;&gt;&gt; 16;    return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&amp;#125;</code></pre><p>由以上代码可以看出，当在实例化<code>HashMap</code>实例时，如果给定了<code>initialCapacity</code>，由于<code>HashMap</code>的<code>capacity</code>都是 2 的幂次方，因此这个方法用于找到大于等于<code>initialCapacity</code>的最小的 2 的幂（initialCapacity 如果就是 2 的幂，则返回的还是这个数）。</p><p><strong>下面分析这个算法：</strong></p><p>首先，我们想一下为什么要对 cap 做减 1 操作？</p><pre><code>int n = cap - 1</code></pre><p>这是为了防止，cap 已经是 2 的幂。如果 cap 已经是 2 的幂，又没有执行这个减 1 操作，则执行完后面的几条无符号右移操作之后，返回的 capacity 将是这个 cap 的 2 倍。如果不懂，要看完后面的几个无符号右移之后再回来看看。</p><p>下面看看这几个无符号右移操作：</p><p>如果 n 这时为 0 了（经过了 cap-1 之后），则经过后面的几次无符号右移依然是 0，最后返回的 capacity 是 1（最后有个 n+1 的操作）。</p><p>这里我们只讨论 n 不等于 0 的情况。</p><pre><code>n |= n &gt;&gt;&gt; 1;</code></pre><p>由于 n 不等于 0，则 n 的二进制表示中总会有一 bit 为 1，这时考虑最高位的 1。通过无符号右移 1 位，则将最高位的 1 右移了 1 位，再做或操作，使得 n 的二进制表示中与最高位的 1 紧邻的右边一位也为 1，如 000011xxxxxx。</p><pre><code>n |= n &gt;&gt;&gt; 2;</code></pre><p>注意，这个 n 已经进行过 <strong>n |= n &gt;&gt;&gt; 1</strong>; 操作。假设此时 n 为 000011xxxxxx ，则 n 无符号右移两位，会将最高位两个连续的 1 右移两位，然后再与原来的 n 做或操作，这样 n 的二进制表示的高位中会有 4 个连续的 1。如 00001111xxxxxx 。</p><pre><code>n |= n &gt;&gt;&gt; 4;</code></pre><p>这次把已经有的高位中的连续的 4 个 1，右移 4 位，再做或操作，这样 n 的二进制表示的高位中会有 8 个连续的 1。如 00001111 1111xxxxxx 。</p><p>以此类推 。。。</p><p>注意，容量最大也就是 32bit 的正数，因此最后 <strong>n |= n &gt;&gt;&gt; 16;</strong> 最多也就 32 个 1，但是这时已经大于了 MAXIMUM_CAPACITY ，所以取值到 MAXIMUM_CAPACITY 。</p><p>下面我们通过一个图片来看一下整个过程：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323151758.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323151758.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>HashMap 中还有很多的重载构造函数，但几乎都是基于上述的构造函数的。</p><pre><code>public HashMap(int initialCapacity) &amp;#123;    this(initialCapacity, DEFAULT_LOAD_FACTOR);&amp;#125;public HashMap() &amp;#123;    this.loadFactor = DEFAULT_LOAD_FACTOR; &amp;#125;</code></pre><p>以上这些构造函数都没有直接的创建一个切实存在的数组，他们都是在为创建数组需要的一些参数做初始化，<br>所以有些在构造函数中并没有被初始化的属性都会在实际初始化数组的时候用默认值替换。</p><p>实际对数组进行初始化是在添加元素的时候进行的（即 put 方法）</p><pre><code>public HashMap(Map&lt;? extends K, ? extends V&gt; m) &amp;#123;    this.loadFactor = DEFAULT_LOAD_FACTOR;    putMapEntries(m, false);&amp;#125;</code></pre><h3 id="remove-方法"><a class="header-anchor" href="#remove-方法">¶</a>remove 方法</h3><p>删除操作就是一个查找 + 删除的过程，相对于添加操作其实容易一些</p><pre><code>public V remove(Object key) &amp;#123;    Node&lt;K,V&gt; e;    return (e = removeNode(hash(key), key, null, false, true)) == null ?        null : e.value;&amp;#125;</code></pre><p>根据键值删除指定节点，这是一个最常见的操作了。显然，removeNode 方法是核心。</p><pre><code>final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,boolean matchValue, boolean movable) &amp;#123;    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index;    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;        (p = tab[index = (n - 1) &amp; hash]) != null) &amp;#123;        Node&lt;K,V&gt; node = null, e; K k; V v;        if (p.hash == hash &amp;&amp;            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))            node = p;        else if ((e = p.next) != null) &amp;#123;            if (p instanceof TreeNode)                node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);            else &amp;#123;                do &amp;#123;                    if (e.hash == hash &amp;&amp;                        ((k = e.key) == key ||                         (key != null &amp;&amp; key.equals(k)))) &amp;#123;                        node = e;                        break;                    &amp;#125;                    p = e;                &amp;#125; while ((e = e.next) != null);            &amp;#125;        &amp;#125;        if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||(value != null &amp;&amp; value.equals(v)))) &amp;#123;            if (node instanceof TreeNode)                                                                     ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable);            else if (node == p)                tab[index] = node.next;            else                p.next = node.next;            ++modCount;            --size;            afterNodeRemoval(node);            return node;        &amp;#125;    &amp;#125;    return null;&amp;#125;</code></pre><p>删除操作需要保证在表不为空的情况下进行，并且 p 节点根据键的 hash 值对应到数组的索引，在该索引处必定有节点，如果为 null ，那么间接说明此键所对应的结点并不存在于整个 HashMap 中，这是不合法的，所以首先要在这两个大前提下才能进行删除结点的操作。</p><p>第一步</p><pre><code>if (p.hash == hash &amp;&amp;((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))     node = p</code></pre><p>需要删除的结点就是这个头节点，让 node 引用指向它。否则说明待删除的结点在当前 p 所指向的头节点的链表或红黑树中，于是需要我们遍历查找。</p><p>第二步</p><pre><code>else if ((e = p.next) != null) &amp;#123;     if (p instanceof TreeNode)          node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);     else &amp;#123;         do &amp;#123;              if (e.hash == hash &amp;&amp;((k = e.key) == key ||(key != null &amp;&amp; key.equals(k)))) &amp;#123;                     node = e;              break;         &amp;#125;         p = e;         &amp;#125; while ((e = e.next) != null);     &amp;#125;&amp;#125;</code></pre><p>如果头节点是红黑树结点，那么调用红黑树自己的遍历方法去得到这个待删结点。否则就是普通链表，我们使用 do while 循环去遍历找到待删结点。找到节点之后，接下来就是删除操作了。</p><p>第三步</p><pre><code>if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||(value != null &amp;&amp; value.equals(v)))) &amp;#123;       if (node instanceof TreeNode)                    ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable);       else if (node == p)            tab[index] = node.next;       else            p.next = node.next;       ++modCount;       --size;       afterNodeRemoval(node);       return node; &amp;#125;</code></pre><p>删除操作也很简单，如果是红黑树结点的删除，直接调用红黑树的删除方法进行删除即可，如果是待删结点就是一个头节点，那么用它的 next 结点顶替它作为头节点存放在 table[index] 中，如果删除的是普通链表中的一个节点，用该结点的前一个节点直接跳过该待删结点指向它的 next 结点即可。</p><p>最后，如果 removeNode 方法删除成功将返回被删结点，否则返回 null。</p><h3 id="keySet"><a class="header-anchor" href="#keySet">¶</a>keySet</h3><pre><code>transient volatile Set&lt;K&gt;        keySet;public Set&lt;K&gt; keySet() &amp;#123;    Set&lt;K&gt; ks;    return (ks = keySet) == null ? (keySet = new KeySet()) : ks;&amp;#125;final class KeySet extends AbstractSet&lt;K&gt; &amp;#123;    public final int size()                 &amp;#123; return size; &amp;#125;    public final void clear()               &amp;#123; HashMap.this.clear(); &amp;#125;    public final Iterator&lt;K&gt; iterator()     &amp;#123; return new KeyIterator(); &amp;#125;    public final boolean contains(Object o) &amp;#123; return containsKey(o); &amp;#125;    public final boolean remove(Object key) &amp;#123;        return removeNode(hash(key), key, null, false, true) != null;    &amp;#125;    public final Spliterator&lt;K&gt; spliterator() &amp;#123;        return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0);    &amp;#125;&amp;#125;</code></pre><p>HashMap 中定义了一个 keySet 的实例属性，它保存的是整个 HashMap 中所有键的集合。上述所列出的 KeySet 类是 Set 的一个实现类，它负责为我们提供有关 HashMap 中所有对键的操作。</p><p>可以看到，KeySet 中的所有的实例方法都依赖当前的 HashMap 实例，也就是说，我们对返回的 keySet 集中的任意一个操作都会直接映射到当前 HashMap 实例中，例如你执行删除一个键的操作，那么 HashMap 中将会少一个节点。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;HashMap&lt;/code&gt; 是 &lt;code&gt;Map&lt;/code&gt; 的一个实现类，它代表的是一种键值对的数据存储形式。&lt;/p&gt;
&lt;p&gt;大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;HashMap&lt;/code&gt;最多只允许一条记录的键为&lt;code&gt;null&lt;/code&gt;，允许多条记录的值为&lt;code&gt;null&lt;/code&gt;。不保证有序 (比如插入的顺序)、也不保证序不随时间变化。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;jdk 8&lt;/code&gt; 之前，其内部是由 &lt;red&gt;数组 + 链表&lt;/red&gt; 来实现的，而 &lt;code&gt;jdk 8&lt;/code&gt; 对于链表长度超过 &lt;green&gt;8&lt;/green&gt; 的链表将转储为 &lt;yellow&gt;红黑树&lt;/yellow&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;HashMap&lt;/code&gt;非线程安全，即任一时刻可以有多个线程同时写&lt;code&gt;HashMap&lt;/code&gt;，可能会导致数据的不一致。如果需要满足线程安全，可以用 &lt;code&gt;Collections&lt;/code&gt;的&lt;code&gt;synchronizedMap&lt;/code&gt;方法使&lt;code&gt;HashMap&lt;/code&gt;具有线程安全的能力，或者使用&lt;code&gt;ConcurrentHashMap&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;HashMap&lt;/code&gt;是 &lt;blue&gt;数组 + 链表 + 红黑树&lt;/blue&gt;（JDK1.8 增加了红黑树部分）实现的。JDK 1.8 之所以添加红黑树是因为一旦链表过长，会严重影响 HashMap 的性能，而红黑树具有快速增删改查的特点，这样就可以有效的解决链表过长时操作比较慢的问题。&lt;/p&gt;
&lt;div class=&quot;img-wrap&quot;&gt;&lt;div class=&quot;img-bg&quot;&gt;&lt;img class=&quot;img&quot; src=&quot;https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/java/collection/20200323120021.png&quot;/&gt;&lt;/div&gt;&lt;/div&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="集合" scheme="https://gyl-coder.top/tags/%E9%9B%86%E5%90%88/"/>
    
    <category term="HashMap" scheme="https://gyl-coder.top/tags/HashMap/"/>
    
  </entry>
  
  <entry>
    <title>int 和 Integer 有什么区别？谈谈Integer的值缓存范围</title>
    <link href="https://gyl-coder.top/java/difference_between_int_and_integer/"/>
    <id>https://gyl-coder.top/java/difference_between_int_and_integer/</id>
    <published>2020-03-09T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<p>Java 虽然是面向对象的编程语言，但是依旧保留了一些原始数据类型，同时为了兼容java面向对象的特性，每种原始数据类型，都有对应的包装类型。</p><p>原始数据类型：boolean、char、byte、short、int、long、float、double<br>包装类型：Boolean、Character、Byte、Short、Integer、Long、Float、Double</p><p>包装类型是对原始数据类型的一种封装，包含对原始类型数据的存储、基本操作以及两种类型直接的转换。Java5中，引入了 <red>自动装箱和自动拆箱</red> 功能（boxing/unboxing），Java可以根据上下文，自动进行转换，极大的简化了相关的编程。</p><p>Integer就是int对应的包装类，它有一个int类型的字段存储数据，并且提供了基本操作，比如数学运算、类型转换等。</p><p>关于Integer的值缓存，是Java5中的一个改进。构造一个Integer对象的正常操作应该是直接使用Integer的构造器，new一个对象出来。但是根据具体实践，大部分的操作都较为集中在有限且较小的数值范围。因此，Java5中新增了静态工厂方法 <green>valueOf</green>，在调用它的时候会利用一个缓存机制。缓存的数值范围为<yellow>[-128, 127]</yellow>。</p><a id="more"></a><h2 id="知识点解读"><a class="header-anchor" href="#知识点解读">¶</a>知识点解读</h2><h3 id="如何理解自动装箱、拆箱"><a class="header-anchor" href="#如何理解自动装箱、拆箱">¶</a>如何理解自动装箱、拆箱</h3><p>自动装箱实际上算是一种语法糖。Java会自动进行转换，保证不同的写法在运行时是等价的，他们<cyan>发生在编译阶段</cyan>，也就是生成的字节码是一致的。</p><p><strong>语法糖虽好，用时小心</strong> 建议避免无意的装箱、拆线行为（创建100万个java对象和100万个整数的消耗不是一个数量级的，不管是内存使用还是处理速度，光是对象头的空间占用就已经是数量级的差距了。）</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Java 虽然是面向对象的编程语言，但是依旧保留了一些原始数据类型，同时为了兼容java面向对象的特性，每种原始数据类型，都有对应的包装类型。&lt;/p&gt;
&lt;p&gt;原始数据类型：boolean、char、byte、short、int、long、float、double&lt;br&gt;
包装类型：Boolean、Character、Byte、Short、Integer、Long、Float、Double&lt;/p&gt;
&lt;p&gt;包装类型是对原始数据类型的一种封装，包含对原始类型数据的存储、基本操作以及两种类型直接的转换。Java5中，引入了 &lt;red&gt;自动装箱和自动拆箱&lt;/red&gt; 功能（boxing/unboxing），Java可以根据上下文，自动进行转换，极大的简化了相关的编程。&lt;/p&gt;
&lt;p&gt;Integer就是int对应的包装类，它有一个int类型的字段存储数据，并且提供了基本操作，比如数学运算、类型转换等。&lt;/p&gt;
&lt;p&gt;关于Integer的值缓存，是Java5中的一个改进。构造一个Integer对象的正常操作应该是直接使用Integer的构造器，new一个对象出来。但是根据具体实践，大部分的操作都较为集中在有限且较小的数值范围。因此，Java5中新增了静态工厂方法 &lt;green&gt;valueOf&lt;/green&gt;，在调用它的时候会利用一个缓存机制。缓存的数值范围为&lt;yellow&gt;[-128, 127]&lt;/yellow&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="Int" scheme="https://gyl-coder.top/tags/Int/"/>
    
    <category term="Integer" scheme="https://gyl-coder.top/tags/Integer/"/>
    
  </entry>
  
  <entry>
    <title>如何设计一个可扩展的限流算法 [转]</title>
    <link href="https://gyl-coder.top/good/how-to-design-extensible-limiting-algorithm/"/>
    <id>https://gyl-coder.top/good/how-to-design-extensible-limiting-algorithm/</id>
    <published>2020-03-04T16:00:00.000Z</published>
    <updated>2020-09-28T14:54:21.932Z</updated>
    
    <content type="html"><![CDATA[<p>限流（Rate Limiting，即速率限制）通过限制每个用户调用API的频率来防止API被过度使用，这可以防止他们因疏忽或恶意导致的API滥用。在没有速率限制的情况下，每个用户可以随心所欲地请求，这可能会导致“峰值”请求，从而导致其他用户得不到响应。在启用速率限制之后，它们的请求将被限制为每秒固定的数量。</p><a id="more"></a><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305174712.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305174712.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>在示例图表中，你可以看到速率限制如何在一段时间内阻塞请求。API最初每分钟接收4个请求，用绿色表示。当12:02启用速率限制时，以红色显示的其他请求将被拒绝。</p><p>速率限制对于公共API是非常重要的，因为你想要为每个消费者（API调用者）维护良好的服务质量，即使有些用户获取了超出其公平配额的服务。计算密集型的端点特别需要速率限制——特别是通过自动伸缩或AWS Lambda和OpenWhisk等按计算付费服务来提供服务时。你还可能希望对提供敏感数据的API进行评级，因为如果攻击者在某些不可预见的事件中获得访问权限，这可能会限制暴露的数据。</p><p>实际上有许多不同的方法来实现速率限制，我们将探讨不同速率限制算法的优缺点。我们还将探讨跨集群扩展时出现的问题。最后，我们将向你展示一个如何使用Kong快速设置速率限制的示例，Kong是最流行的开源API网关。</p><h2 id="速度限制算法"><a class="header-anchor" href="#速度限制算法">¶</a>速度限制算法</h2><p>有各种各样的速率限制算法，每一种都有自己的优点和缺点。让我们回顾一下，这样你就可以根据自己的需要选择最好的限流算法。</p><h3 id="漏桶算法"><a class="header-anchor" href="#漏桶算法">¶</a>漏桶算法</h3><p>漏桶算法（Leaky Bucket，与令牌桶密切相关）是这样一种算法，它提供了一种简单、直观的方法来通过队列限制速率，你可以将队列看作一个存储请求的桶。当一个请求被注册时，它被附加到队列的末尾。每隔一段时间处理队列上的第一项。这也称为先进先出（FIFO）队列。如果队列已满，则丢弃（或泄漏）其他请求。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181120.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181120.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>这种算法的优点是它可以平滑请求的爆发，并以近似平均的速度处理它们。它也很容易在单个服务器或负载均衡器上实现，并且在有限的队列大小下对于每个用户都是内存有效的。</p><p>然而，突发的访问量会用旧的请求填满队列，并使最近的请求无法被处理。它也不能保证在固定的时间内处理请求。此外，如果为了容错或增加吞吐量而负载平衡服务器，则必须使用策略来协调和强制它们之间的限制。稍后我们将讨论分布式环境的挑战。</p><h3 id="固定窗口算法"><a class="header-anchor" href="#固定窗口算法">¶</a>固定窗口算法</h3><p>在固定窗口（Fixed Window）算法中，使用n秒的窗口大小（通常使用对人类友好的值，如60秒或3600秒）来跟踪速率。每个传入的请求都会增加窗口的计数器。如果计数器超过阈值，则丢弃请求。窗口通常由当前时间戳的层定义，因此12:00:03的窗口长度为60秒，应该在12:00:00的窗口中。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181216.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181216.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>这种算法的优点是，它可以确保处理更多最近的请求，而不会被旧的请求饿死。然而，发生在窗口边界附近的单个流量突发会导致处理请求的速度增加一倍，因为它允许在短时间内同时处理当前窗口和下一个窗口的请求。另外，如果许多消费者等待一个重置窗口，例如在一个小时的顶部，那么他们可能同时扰乱你的API。</p><h3 id="滑动日志算法"><a class="header-anchor" href="#滑动日志算法">¶</a>滑动日志算法</h3><p>滑动日志（Sliding Log）速率限制涉及到跟踪每个使用者请求的时间戳日志。这些日志通常存储在按时间排序的散列集或表中。时间戳超过阈值的日志将被丢弃。当新请求出现时，我们计算日志的总和来确定请求率。如果请求将超过阈值速率，则保留该请求。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181258.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181258.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>该算法的优点是不受固定窗口边界条件的限制，速率限制将严格执行。此外，因为滑动日志是针对每个消费者进行跟踪的，所以不会出现对固定窗口造成挑战的踩踏效应。但是，为每个请求存储无限数量的日志可能非常昂贵。它的计算成本也很高，因为每个请求都需要计算使用者先前请求的总和，这些请求可能跨越一个服务器集群。因此，它不能很好地处理大规模的流量突发或拒绝服务攻击。</p><h3 id="滑动窗口"><a class="header-anchor" href="#滑动窗口">¶</a>滑动窗口</h3><p>这是一种将固定窗口算法的低处理成本与改进的滑动日志边界条件相结合的混合方法。与固定窗口算法一样，我们跟踪每个固定窗口的计数器。接下来，我们根据当前的时间戳计算前一个窗口请求率的加权值，以平滑突发的流量。例如，如果当前窗口通过了25%，那么我们将前一个窗口的计数加权为75%。跟踪每个键所需的相对较少的数据点允许我们在大型集群中扩展和分布。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181343.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181343.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>我们推荐使用滑动窗口方法，因为它可以灵活地调整速率限制，并且具有良好的性能。速率窗口是它向API消费者提供速率限制数据的一种直观方式。它还避免了漏桶的饥饿问题和固定窗口实现的突发问题。</p><h2 id="分布式系统中的速率限制"><a class="header-anchor" href="#分布式系统中的速率限制">¶</a>分布式系统中的速率限制</h2><h3 id="同步策略"><a class="header-anchor" href="#同步策略">¶</a>同步策略</h3><p>如果希望在使用多个节点的集群时实施全局速率限制，则必须设置策略来实施该限制。如果每个节点都要跟踪自己的速率限制，那么当请求被发送到不同节点时，使用者可能会超过全局速率限制。实际上，节点的数量越大，用户越有可能超过全局限制。</p><p>执行此限制的最简单方法是在负载均衡器中设置粘性会话，以便每个使用者都被精确地发送到一个节点。缺点包括缺乏容错性和节点过载时的缩放问题。</p><p>允许更灵活的负载平衡规则的更好解决方案是使用集中的数据存储，如Redis或Cassandra。这将存储每个窗口和消费者的计数。这种方法的两个主要问题是增加了向数据存储发出请求的延迟，以及竞争条件（我们将在下面讨论）。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181452.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181452.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h3 id="竞态条件"><a class="header-anchor" href="#竞态条件">¶</a>竞态条件</h3><p>集中式数据存储的最大问题之一是高并发请求模式中的竞争条件。当你使用一种简单的“get-then-set”方法时，就会发生这种情况，在这种方法中，你检索当前速率限制计数器，增加它的值，然后将其推回到数据存储中。这个模型的问题是，在执行一个完整的读递增存储周期时，可能会出现额外的请求，每个请求都试图用无效的（较低的）计数器值存储递增计数器。这允许使用者发送非常高的请求率来绕过速率限制控制。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181532.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181532.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>避免这个问题的一种方法是在有问题的密钥周围放置一个“锁”，防止任何其他进程访问或写入计数器。这将很快成为一个主要的性能瓶颈，而且伸缩性不好，特别是在使用诸如Redis之类的远程服务器作为备份数据存储时。</p><p>更好的方法是使用“先设置后获取”的心态，依赖于原子操作符，它们以一种非常高性能的方式实现锁，允许你快速增加和检查计数器值，而不让原子操作成为障碍。</p><h3 id="性能优化"><a class="header-anchor" href="#性能优化">¶</a>性能优化</h3><p>使用集中式数据存储的另一个缺点是，在检查速率限制计数器时增加了延迟。不幸的是，即使是检查像Redis这样的快速数据存储，也会导致每个请求增加毫秒的延迟。</p><p>为了以最小的延迟确定这些速率限制，有必要在内存中进行本地检查。这可以通过放松速率检查条件和使用最终一致的模型来实现。例如，每个节点可以创建一个数据同步周期，该周期将与中央数据存储同步。每个节点定期将每个使用者的计数器增量和它看到的窗口推送到数据存储，数据存储将自动更新这些值。然后，节点可以检索更新后的值来更新其内存版本。集群内节点之间的这种收敛→发散→再收敛的循环最终是一致的。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181532.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181532.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>节点聚合的周期速率应该是可配置的。当流量分布在群集中的多个节点上时（例如，当坐在一个轮询调度平衡器后面时），较短的同步间隔将导致较少的数据点分散，而较长的同步间隔将对数据存储施加较小的读/写压力，更少的开销在每个节点上获取新的同步值。</p><h2 id="使用Kong快速设置速率限制"><a class="header-anchor" href="#使用Kong快速设置速率限制">¶</a>使用Kong快速设置速率限制</h2><p>Kong是一个开源的API网关，它使构建具有速率限制的可伸缩服务变得非常容易。它被全球超过300,000个活动实例使用。它可以完美地从单个的Kong节点扩展到大规模的、跨越全球的Kong集群。</p><p>Kong位于API前面，是上游API的主要入口。在处理请求和响应时，Kong将执行你决定添加到API中的任何插件。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181731.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/good/sheji/20200305181731.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>Kong的速率限制插件是高度可配置的。它提供了为每个API和消费者定义多个速率限制窗口和速率的灵活性。它支持本地内存、Redis、Postgres和Cassandra备份数据存储。它还提供了各种数据同步选项，包括同步和最终一致的模型。</p><p>你可以在其中一台开发机器上快速安装Kong来测试它。我最喜欢的入门方式是使用AWS云形成模板，因为只需几次单击就可以获得预先配置好的开发机器。只需选择一个HVM选项，并将实例大小设置为使用t2.micro，这些对于测试都是负担得起的。然后ssh到新实例上的命令行进行下一步。</p><h3 id="在Kong上添加API"><a class="header-anchor" href="#在Kong上添加API">¶</a>在Kong上添加API</h3><p>下一步是使用Kong的admin API在Kong上添加一个API。我们将使用httpbin作为示例，它是一个针对API的免费测试服务。get URL将把我的请求数据镜像成JSON。我们还假设Kong在本地系统上的默认端口上运行。</p><pre><code>curl -i -X POST \--url http://localhost:8001/apis/ \--data 'name=test' \--data 'uris=/test' \--data 'upstream_url=http://httpbin.org/get'</code></pre><p>现在 Kong 意识到每个发送到 “/test” 的请求都应该代理到 httpbin。我们可以向它的代理端口上的 Kong 发出以下请求来测试它：</p><pre><code>curl http://localhost:8000/test&amp;#123;    &quot;args&quot;: &amp;#123;&amp;#125;,    &quot;headers&quot;: &amp;#123;    &quot;Accept&quot;: &quot;*/*&quot;,    &quot;Connection&quot;: &quot;close&quot;,    &quot;Host&quot;: &quot;httpbin.org&quot;,    &quot;User-Agent&quot;: &quot;curl/7.51.0&quot;,    &quot;X-Forwarded-Host&quot;: &quot;localhost&quot;    &amp;#125;,    &quot;origin&quot;: &quot;localhost, 52.89.171.202&quot;,    &quot;url&quot;: &quot;http://localhost/get&quot;&amp;#125;</code></pre><p>它还是好的！Kong 已经接收了请求并将其代理到 httpbin，httpbin 已将我的请求头和我的原始 IP 地址进行了镜像。</p><h3 id="添加基本的速率限制"><a class="header-anchor" href="#添加基本的速率限制">¶</a>添加基本的速率限制</h3><p>让我们继续，通过使用社区版的限速插件 [1] 添加限速功能来保护它不受过多请求的影响，每个消费者每分钟只能发出 5 个请求：</p><pre><code>curl -i -X POST http://localhost:8001/apis/test/plugins/ \-d &quot;name=rate-limiting&quot; \-d &quot;config.minute=5&quot;</code></pre><p>如果我们现在发出超过 5 个请求，Kong 会回复以下错误信息：</p><pre><code>curl http://localhost:8000/test&amp;#123;    &quot;message&quot;:&quot;API rate limit exceeded&quot;&amp;#125;</code></pre><p>看上去不错！我们在 Kong 上添加了一个 API，并且仅在两个 HTTP 请求中向 Kong 的 admin API 添加了速率限制。</p><p>它默认使用固定的窗口来限制 IP 地址的速率，并使用默认的数据存储在集群中的所有节点之间进行同步。有关其他选项，包括每个用户的速率限制或使用其他数据存储（如 Redis），请参阅文档 [1]。</p><h3 id="企业版-Kong，更好的性能"><a class="header-anchor" href="#企业版-Kong，更好的性能">¶</a>企业版 Kong，更好的性能</h3><p>企业版 [2] 的速率限制增加了对滑动窗口算法的支持，以更好地控制和性能。滑动窗口可以防止你的 API 在窗口边界附近重载，如上面的部分所述。对于低延迟，它使用计数器的内存表，可以使用异步或同步更新跨集群进行同步。这提供了本地阈值的延迟，并且可以跨整个集群扩展。</p><p>第一步是安装企业版的 Kong。然后，可以配置速率限制、以秒为单位的窗口大小和同步计数器值的频率。它真的很容易使用，你可以得到这个强大的控制与一个简单的 API 调用：</p><pre><code>curl -i -X POST http://localhost:8001/apis/test/plugins \-d &quot;name=rate-limiting&quot; \-d &quot;config.limit=5&quot; \-d &quot;config.window_size=60&quot; \-d &quot;config.sync_rate=10&quot;</code></pre><p>企业还增加了对 Redis Sentinel 的支持，这使得 Redis 高可用性和更强的容错能力。你可以阅读更多的企业速率限制插件文档。</p><div class="tag link"><a class="link-card" title="阅读原文" href="https://mp.weixin.qq.com/s?__biz=MzA5OTAyNzQ2OA==&mid=2649704593&idx=1&sn=bccc83c5fc87bf4f032f91405be15cd4&scene=21#wechat_redirect'><i"><div class="left"><img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/256/safari.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/256/safari.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div><div class="right"><p class="text">阅读原文</p><p class="url">https://mp.weixin.qq.com/s?__biz=MzA5OTAyNzQ2OA==&mid=2649704593&idx=1&sn=bccc83c5fc87bf4f032f91405be15cd4&scene=21#wechat_redirect'><i</p></div></a></div>]]></content>
    
    
    <summary type="html">&lt;p&gt;限流（Rate Limiting，即速率限制）通过限制每个用户调用API的频率来防止API被过度使用，这可以防止他们因疏忽或恶意导致的API滥用。在没有速率限制的情况下，每个用户可以随心所欲地请求，这可能会导致“峰值”请求，从而导致其他用户得不到响应。在启用速率限制之后，它们的请求将被限制为每秒固定的数量。&lt;/p&gt;</summary>
    
    
    
    <category term="设计" scheme="https://gyl-coder.top/categories/%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="限流算法" scheme="https://gyl-coder.top/tags/%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/"/>
    
    <category term="设计" scheme="https://gyl-coder.top/tags/%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>kafka 主题管理</title>
    <link href="https://gyl-coder.top/kafka/kafka-topic-manage/"/>
    <id>https://gyl-coder.top/kafka/kafka-topic-manage/</id>
    <published>2019-12-07T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<p>对于 kafka 主题（topic）的管理（增删改查），使用最多的便是kafka自带的脚本。</p><a id="more"></a><h2 id="创建主题"><a class="header-anchor" href="#创建主题">¶</a>创建主题</h2><p>kafka提供了自带的 <code>kafka-topics</code> 脚本，用来帮助用户创建主题（topic）。</p><pre><code class="language-shell">bin/kafka-topics.sh --bootstrap-server broker_host:port --create --topic my_topic_name  --partitions 1 --replication-factor 1</code></pre><p>create 表明我们要创建主题，而 partitions 和 replication factor 分别设置了主题的分区数以及每个分区下的副本数。</p><h3 id="这里为什么用的-bootstrap-server-参数，而不是-zookeeper"><a class="header-anchor" href="#这里为什么用的-bootstrap-server-参数，而不是-zookeeper">¶</a>这里为什么用的 <code>--bootstrap-server</code> 参数，而不是 <code>--zookeeper</code> ?</h3><p><code>--zookeeper</code> 参数是之前版本的用法，从kafka 2.2 版本开始，社区推荐使用 <code>--bootstrap-server</code> 参数替换 <code>--zoookeeper</code> ，并且显式地将后者标记为 “已过期”，因此，如果你已经在使用 2.2 版本了，那么创建主题请指定 <code>--bootstrap-server</code> 参数。</p><p>推荐使用 <code>--bootstrap-server</code> 而非 <code>--zookeeper</code> 的原因主要有两个。</p><ol><li>使用 --zookeeper 会绕过 Kafka 的安全体系。这就是说，即使你为 Kafka 集群设置了安全认证，限制了主题的创建，如果你使用 --zookeeper 的命令，依然能成功创建任意主题，不受认证体系的约束。这显然是 Kafka 集群的运维人员不希望看到的。</li><li>使用 --bootstrap-server 与集群进行交互，越来越成为使用 Kafka 的标准姿势。换句话说，以后会有越来越少的命令和 API 需要与 ZooKeeper 进行连接。这样，我们只需要一套连接信息，就能与 Kafka 进行全方位的交互，不用像以前一样，必须同时维护 ZooKeeper 和 Broker 的连接信息。</li></ol><h2 id="查询主题"><a class="header-anchor" href="#查询主题">¶</a>查询主题</h2><p>创建好主题之后，Kafka 允许我们使用相同的脚本查询主题。你可以使用下面的命令，查询所有主题的列表。</p><pre><code class="language-shell">bin/kafka-topics.sh --bootstrap-server broker_host:port --list</code></pre><p>如果要查询单个主题的详细数据，你可以使用下面的命令。</p><pre><code class="language-shell">bin/kafka-topics.sh --bootstrap-server broker_host:port --describe --topic &lt;topic_name&gt;</code></pre><p>如果 describe 命令不指定具体的主题名称，那么 Kafka 默认会返回所有 “可见” 主题的详细数据给你。</p><p><strong>这里的 “可见”，是指发起这个命令的用户能够看到的 Kafka 主题</strong>。这和前面说到主题创建时，使用 --zookeeper 和 --bootstrap-server 的区别是一样的。如果指定了 --bootstrap-server，那么这条命令就会受到安全认证体系的约束，即对命令发起者进行权限验证，然后返回它能看到的主题。否则，如果指定 --zookeeper 参数，那么默认会返回集群中所有的主题详细数据。基于这些原因，我建议你最好统一使用 --bootstrap-server 连接参数。</p><h2 id="修改主题"><a class="header-anchor" href="#修改主题">¶</a>修改主题</h2><h3 id="修改主题分区"><a class="header-anchor" href="#修改主题分区">¶</a>修改主题分区</h3><p>其实就是增加分区，目前 Kafka 不允许减少某个主题的分区数。你可以使用 kafka-topics 脚本，结合 --alter 参数来增加某个主题的分区数，命令如下：</p><pre><code class="language-shell">bin/kafka-topics.sh --bootstrap-server broker_host:port --alter --topic &lt;topic_name&gt; --partitions &lt; 新分区数 &gt;</code></pre><p>这里要注意的是，你指定的分区数一定要比原有分区数大，否则 Kafka 会抛出 InvalidPartitionsException 异常。</p><h3 id="修改主题级别参数"><a class="header-anchor" href="#修改主题级别参数">¶</a>修改主题级别参数</h3><p>在主题创建之后，我们可以使用 kafka-configs 脚本修改对应的参数。</p><p>假设我们要设置主题级别参数 max.message.bytes，那么命令如下：</p><pre><code>bin/kafka-configs.sh --zookeeper zookeeper_host:port --entity-type topics --entity-name &lt;topic_name&gt; --alter --add-config max.message.bytes=10485760</code></pre><p>也许你会觉得奇怪，为什么这个脚本就要指定 --zookeeper，而不是 --bootstrap-server 呢？其实，这个脚本也能指定 --bootstrap-server 参数，只是它是用来设置动态参数的。在专栏后面，我会详细介绍什么是动态参数，以及动态参数都有哪些。现在，你只需要了解设置常规的主题级别参数，还是使用 --zookeeper。</p><h3 id="变更副本数"><a class="header-anchor" href="#变更副本数">¶</a>变更副本数</h3><p>使用自带的 kafka-reassign-partitions 脚本，帮助我们增加主题的副本数。</p><p>假设kafka的内部主题 <code>__consumer_offsets</code> 只有 1 个副本，现在我们想要增加至 3 个副本。下面是操作：</p><ol><li>创建一个 json 文件，显式提供 50 个分区对应的副本数。注意，replicas 中的 3 台 Broker 排列顺序不同，目的是将 Leader 副本均匀地分散在 Broker 上。该文件具体格式如下</li></ol><pre><code class="language-json">&amp;#123;&quot;version&quot;:1, &quot;partitions&quot;:[ &amp;#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[0,1,2]&amp;#125;,   &amp;#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[0,2,1]&amp;#125;,  &amp;#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,0,2]&amp;#125;,  &amp;#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:3,&quot;replicas&quot;:[1,2,0]&amp;#125;,  ...  &amp;#123;&quot;topic&quot;:&quot;__consumer_offsets&quot;,&quot;partition&quot;:49,&quot;replicas&quot;:[0,1,2]&amp;#125;]&amp;#125;</code></pre><ol start="2"><li>执行 <code>kafka-reassign-patitions</code> 脚本，命令如下：</li></ol><pre><code class="language-shell">bin/kafka-reassign-partitions.sh --zookeeper zookeeper_host:port --reassignment-json-file reassign.json --execute</code></pre><p>除了修改内部主题，我们可能还想查看这些内部主题的消息内容。特别是对于 __consumer_offsets 而言，由于它保存了消费者组的位移数据，有时候直接查看该主题消息是很方便的事情。下面的命令可以帮助我们直接查看消费者组提交的位移数据。</p><pre><code>bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --from-beginning</code></pre><p>除了查看位移提交数据，我们还可以直接读取该主题消息，查看消费者组的状态信息。</p><pre><code>bin/kafka-console-consumer.sh --bootstrap-server kafka_host:port --topic __consumer_offsets --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$GroupMetadataMessageFormatter&quot; --from-beginning</code></pre><p>对于内部主题 __transaction_state 而言，方法是相同的。你只需要指定 kafka.coordinator.transaction.TransactionLog$TransactionLogMessageFormatter 即可。</p><h3 id="修改主题限速"><a class="header-anchor" href="#修改主题限速">¶</a>修改主题限速</h3><p>这里主要是指设置 Leader 副本和 Follower 副本使用的带宽。有时候，我们想要让某个主题的副本在执行副本同步机制时，不要消耗过多的带宽。Kafka 提供了这样的功能。我来举个例子。假设我有个主题，名为 test，我想让该主题各个分区的 Leader 副本和 Follower 副本在处理副本同步时，不得占用超过 100MBps 的带宽。注意是大写 B，即每秒不超过 100MB。那么，我们应该怎么设置呢？</p><p>要达到这个目的，我们必须先设置 Broker 端参数 leader.replication.throttled.rate 和 follower.replication.throttled.rate，命令如下：</p><pre><code>bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.rate=104857600,follower.replication.throttled.rate=104857600' --entity-type brokers --entity-name 0</code></pre><p>这条命令结尾处的 --entity-name 就是 Broker ID。倘若该主题的副本分别在 0、1、2、3 多个 Broker 上，那么你还要依次为 Broker 1、2、3 执行这条命令。</p><p>设置好这个参数之后，我们还需要为该主题设置要限速的副本。在这个例子中，我们想要为所有副本都设置限速，因此统一使用通配符 * 来表示，命令如下：</p><pre><code>bin/kafka-configs.sh --zookeeper zookeeper_host:port --alter --add-config 'leader.replication.throttled.replicas=*,follower.replication.throttled.replicas=*' --entity-type topics --entity-name test</code></pre><h3 id="主题分区迁移"><a class="header-anchor" href="#主题分区迁移">¶</a>主题分区迁移</h3><p>同样是使用 kafka-reassign-partitions 脚本，对主题各个分区的副本进行 “手术” 般的调整，比如把某些分区批量迁移到其他 Broker 上。</p><h2 id="删除主题"><a class="header-anchor" href="#删除主题">¶</a>删除主题</h2><pre><code>bin/kafka-topics.sh --bootstrap-server broker_host:port --delete  --topic &lt;topic_name&gt;</code></pre><p>删除主题的命令并不复杂，关键是删除操作是异步的，执行完这条命令不代表主题立即就被删除了。它仅仅是被标记成 “已删除” 状态而已。Kafka 会在后台默默地开启主题删除操作。因此，通常情况下，你都需要耐心地等待一段时间。</p><h3 id="主题删除失败"><a class="header-anchor" href="#主题删除失败">¶</a>主题删除失败</h3><p>当运行完上面的删除命令后，很多人发现已删除主题的分区数据依然 “躺在” 硬盘上，没有被清除。这时该怎么办呢？</p><p>实际上，造成主题删除失败的原因有很多，最常见的原因有两个：</p><ul><li>副本所在的 Broker 宕机了</li><li>待删除主题的部分分区依然在执行迁移过程。</li></ul><p>如果是因为前者，通常你重启对应的 Broker 之后，删除操作就能自动恢复；如果是因为后者，那就麻烦了，很可能两个操作会相互干扰。</p><p>不管什么原因，一旦你碰到主题无法删除的问题，可以采用这样的方法：</p><ol><li>手动删除 ZooKeeper 节点 /admin/delete_topics 下以待删除主题为名的 znode。</li><li>手动删除该主题在磁盘上的分区目录。</li><li>在 ZooKeeper 中执行 rmr /controller，触发 Controller 重选举，刷新 Controller 缓存。</li></ol><p>在执行最后一步时，你一定要谨慎，因为它可能造成大面积的分区 Leader 重选举。事实上，仅仅执行前两步也是可以的，只是 Controller 缓存中没有清空待删除主题罢了，也不影响使用。</p><h2 id="常见问题"><a class="header-anchor" href="#常见问题">¶</a>常见问题</h2><h3 id="consumer-offsets-占用太多的磁盘"><a class="header-anchor" href="#consumer-offsets-占用太多的磁盘">¶</a>__consumer_offsets 占用太多的磁盘</h3><p>一旦你发现这个主题消耗了过多的磁盘空间，那么，你一定要显式地用 <strong>jstack 命令</strong>查看一下 kafka-log-cleaner-thread 前缀的线程状态。通常情况下，这都是因为该线程挂掉了，无法及时清理此内部主题。倘若真是这个原因导致的，那我们就只能重启相应的 Broker 了。另外，请你注意保留出错日志，因为这通常都是 Bug 导致的，最好提交到社区看一下。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;对于 kafka 主题（topic）的管理（增删改查），使用最多的便是kafka自带的脚本。&lt;/p&gt;</summary>
    
    
    
    <category term="kafka" scheme="https://gyl-coder.top/categories/kafka/"/>
    
    
    <category term="kafka" scheme="https://gyl-coder.top/tags/kafka/"/>
    
    <category term="topic" scheme="https://gyl-coder.top/tags/topic/"/>
    
  </entry>
  
  <entry>
    <title>kafka 问题总结</title>
    <link href="https://gyl-coder.top/kafka/kafka-todo-list/"/>
    <id>https://gyl-coder.top/kafka/kafka-todo-list/</id>
    <published>2019-12-06T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<ol><li><a href="https://gyl-coder.top/2019/10/09/kafka-reliability/">kafka如何保证数据可靠性和数据一致性</a></li><li><a href="https://gyl-coder.top/2019/10/10/kafka-rebalance/">Kafka Rebalance机制分析</a></li><li>Kafka的用途有哪些？使用场景如何？</li><li><a href="https://gyl-coder.top/2019/10/04/kafka-isr-ar/">Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么？</a></li><li><a href="https://gyl-coder.top/2019/10/04/Kafka%E4%B8%AD%E7%9A%84HW%E3%80%81LEO%E3%80%81LSO%E7%AD%89%E5%88%86%E5%88%AB%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%EF%BC%9F/">Kafka中的HW、LEO、LSO等分别代表什么？</a></li><li>Kafka中是怎么体现消息顺序性的？</li></ol><a id="more"></a><ol start="7"><li>Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</li><li><a href="https://gyl-coder.top/2019/10/03/kafka%20%E4%B8%BB%E9%A2%98%E7%AE%A1%E7%90%86/">kafka 主题管理</a></li><li>Kafka生产者客户端的整体结构是什么样子的？</li><li>Kafka生产者客户端中使用了几个线程来处理？分别是什么？</li><li>Kafka的旧版Scala的消费者客户端的设计有什么缺陷？</li><li>“消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果正确，那</li><li>有没有什么hack的手段？</li><li>消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?</li><li>有哪些情形会造成重复消费？</li><li>那些情景下会造成消息漏消费？</li><li>KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？</li><li>简述消费者与消费组之间的关系</li><li>当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？</li><li>topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</li><li>topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</li><li>创建topic时如何选择合适的分区数？</li><li>Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？</li><li>优先副本是什么？它有什么特殊的作用？</li><li><a href="https://gyl-coder.top/2019/10/09/kafka-partition-alocation/">Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理</a></li><li>简述Kafka的日志目录结构</li><li>Kafka中有那些索引文件？</li><li>如果我指定了一个offset，Kafka怎么查找到对应的消息？</li><li>如果我指定了一个timestamp，Kafka怎么查找到对应的消息？</li><li>聊一聊你对Kafka的Log Retention的理解</li><li>聊一聊你对Kafka的Log Compaction的理解</li><li>聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）</li><li>聊一聊Kafka的延时操作的原理</li><li>聊一聊Kafka控制器的作用</li><li>消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）</li><li>Kafka中的幂等是怎么实现的</li><li>Kafka中的事务是怎么实现的（这题我去面试6加被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸</li><li>Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？</li><li>失效副本是指什么？有那些应对措施？</li><li>多副本下，各个副本中的HW和LEO的演变过程</li><li>为什么Kafka不支持读写分离？</li><li>Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）</li><li>Kafka中怎么实现死信队列和重试队列？</li><li>Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）</li><li>Kafka中怎么做消息审计？</li><li>Kafka中怎么做消息轨迹？</li><li>Kafka中有那些配置参数比较有意思？聊一聊你的看法</li><li>Kafka中有那些命名比较有意思？聊一聊你的看法</li><li>Kafka有哪些指标需要着重关注？</li><li>怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)</li><li>Kafka的那些设计让它有如此高的性能？</li><li>Kafka有什么优缺点？</li><li>还用过什么同质类的其它产品，与Kafka相比有什么优缺点？</li><li>为什么选择Kafka?</li><li>在使用Kafka的过程中遇到过什么困难？怎么解决的？</li><li>怎么样才能确保Kafka极大程度上的可靠性？</li><li>聊一聊你对Kafka生态的理解</li></ol>]]></content>
    
    
    <summary type="html">&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://gyl-coder.top/2019/10/09/kafka-reliability/&quot;&gt;kafka如何保证数据可靠性和数据一致性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://gyl-coder.top/2019/10/10/kafka-rebalance/&quot;&gt;Kafka Rebalance机制分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kafka的用途有哪些？使用场景如何？&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://gyl-coder.top/2019/10/04/kafka-isr-ar/&quot;&gt;Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://gyl-coder.top/2019/10/04/Kafka%E4%B8%AD%E7%9A%84HW%E3%80%81LEO%E3%80%81LSO%E7%AD%89%E5%88%86%E5%88%AB%E4%BB%A3%E8%A1%A8%E4%BB%80%E4%B9%88%EF%BC%9F/&quot;&gt;Kafka中的HW、LEO、LSO等分别代表什么？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kafka中是怎么体现消息顺序性的？&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="kafka" scheme="https://gyl-coder.top/categories/kafka/"/>
    
    
    <category term="kafka" scheme="https://gyl-coder.top/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka 如何保证数据的可靠性和一致性</title>
    <link href="https://gyl-coder.top/kafka/kafka-reliability/"/>
    <id>https://gyl-coder.top/kafka/kafka-reliability/</id>
    <published>2019-12-05T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据可靠性"><a class="header-anchor" href="#数据可靠性">¶</a>数据可靠性</h2><p>Kafka 作为一个商业级消息中间件，消息可靠性的重要性可想而知。本文从 Producter 往 Broker 发送消息、Topic 分区副本以及 Leader 选举几个角度介绍数据的可靠性。</p><a id="more"></a><h3 id="Producer-往-Broker-发送消息"><a class="header-anchor" href="#Producer-往-Broker-发送消息">¶</a>Producer 往 Broker 发送消息</h3><p>如果我们要往 Kafka 对应的主题发送消息，我们需要通过 Producer 完成。前面我们讲过 Kafka 主题对应了多个分区，每个分区下面又对应了多个副本；为了让用户设置数据可靠性， Kafka 在 Producer 里面提供了消息确认机制。也就是说我们可以通过配置来决定有几个副本收到这条消息才算消息发送成功。可以在定义 Producer 时通过 <code>acks</code> 参数指定（在 0.8.2.X 版本之前是通过 <code>request.required.acks</code> 参数设置的，详见 <a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9LQUZLQS0zMDQz&amp;article=true">KAFKA-3043</a>）。这个参数支持以下三种值：</p><ul><li><p>acks=0：生产者不会等待任何来自服务器的响应。</p><p>如果当中出现问题，导致服务器没有收到消息，那么生产者无从得知，会造成消息丢失</p><p>由于生产者不需要等待服务器的响应所以可以以网络能够支持的最大速度发送消息，从而达到很高的吞吐量</p></li><li><p>acks=1（默认值）：只要集群的Leader节点收到消息，生产者就会收到一个来自服务器的成功响应</p><p>如果消息无法到达Leader节点（例如Leader节点崩溃，新的Leader节点还没有被选举出来）生产者就会收到一个错误响应，为了避免数据丢失，生产者会重发消息</p><p>如果一个没有收到消息的节点成为新Leader，消息还是会丢失</p><p>此时的吞吐量主要取决于使用的是同步发送还是异步发送，吞吐量还受到发送中消息数量的限制，例如生产者在收到服务器响应之前可以发送多少个消息</p></li><li><p>acks=-1：只有当所有参与复制的节点全部都收到消息时，生产者才会收到一个来自服务器的成功响应</p><p>这种模式是最安全的，可以保证不止一个服务器收到消息，就算有服务器发生崩溃，整个集群依然可以运行</p><p>延时比acks=1更高，因为要等待不止一个服务器节点接收消息</p></li></ul><p>根据实际的应用场景，我们设置不同的 <code>acks</code>，以此保证数据的可靠性。</p><p>另外，Producer 发送消息还可以选择同步（默认，通过 <code>producer.type=sync</code> 配置） 或者异步（<code>producer.type=async</code>）模式。如果设置成异步，虽然会极大的提高消息发送的性能，但是这样会增加丢失数据的风险。如果需要确保消息的可靠性，必须将 <code>producer.type</code> 设置为 sync。</p><h3 id="Topic-分区副本"><a class="header-anchor" href="#Topic-分区副本">¶</a>Topic 分区副本</h3><p>在 Kafka 0.8.0 之前，Kafka 是没有副本的概念的，那时候人们只会用 Kafka 存储一些不重要的数据，因为没有副本，数据很可能会丢失。但是随着业务的发展，支持副本的功能越来越强烈，所以为了保证数据的可靠性，Kafka 从 0.8.0 版本开始引入了分区副本（详情请参见 <a href="https://www.iteblog.com/redirect.php?url=aHR0cHM6Ly9pc3N1ZXMuYXBhY2hlLm9yZy9qaXJhL2Jyb3dzZS9LQUZLQS01MA==&amp;article=true">KAFKA-50</a>）。也就是说每个分区可以人为的配置几个副本（比如创建主题的时候指定 <code>replication-factor</code>，也可以在 Broker 级别进行配置 <code>default.replication.factor</code>），一般会设置为3。</p><p>Kafka 可以保证单个分区里的事件是有序的，分区可以在线（可用），也可以离线（不可用）。在众多的分区副本里面有一个副本是 Leader，其余的副本是 follower，所有的读写操作都是经过 Leader 进行的，同时 follower 会定期地去 leader 上复制数据。当 Leader 挂掉之后，其中一个 follower 会重新成为新的 Leader。通过分区副本，引入了数据冗余，同时也提供了 Kafka 的数据可靠性。</p><p><strong>Kafka 的分区多副本架构是 Kafka 可靠性保证的核心，把消息写入多个副本可以使 Kafka 在发生崩溃时仍能保证消息的持久性。</strong></p><h3 id="Leader-选举"><a class="header-anchor" href="#Leader-选举">¶</a>Leader 选举</h3><p>在介绍 Leader 选举之前，让我们先来了解一下 ISR（in-sync replicas）列表。每个分区的 leader 会维护一个 ISR 列表，ISR 列表里面就是 follower 副本的 Borker 编号，只有“跟得上” Leader 的 follower 副本才能加入到 ISR 里面，这个是通过 <code>replica.lag.time.max.ms</code> 参数配置的。只有 ISR 里的成员才有被选为 leader 的可能。</p><p>所以当 Leader 挂掉了，而且 <code>unclean.leader.election.enable=false</code> 的情况下，Kafka 会从 ISR 列表中选择第一个 follower 作为新的 Leader，因为这个分区拥有最新的已经 committed 的消息。通过这个可以保证已经 committed 的消息的数据可靠性。</p><p>综上所述，为了保证数据的可靠性，我们最少需要配置一下几个参数：</p><ul><li>producer 级别：acks=all（或者 request.required.acks=-1），同时发生模式为同步 producer.type=sync</li><li>topic 级别：设置 replication.factor&gt;=3，并且 min.insync.replicas&gt;=2；</li><li>broker 级别：关闭不完全的 Leader 选举，即 unclean.leader.election.enable=false；</li></ul><h2 id="数据一致性"><a class="header-anchor" href="#数据一致性">¶</a>数据一致性</h2><p>这里介绍的数据一致性主要是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。那么 Kafka 是如何实现的呢？</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.2/img/kafka/1567762579648.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.2/img/kafka/1567762579648.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message3，但是 Consumer 只能读取到 Message1。因为所有的 ISR 都同步了 Message1，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，对应于上图的副本2，这个很类似于木桶原理。</p><p>这样做的原因是还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。</p><p>当然，引入了 High Water Mark 机制，会导致 Broker 间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长（因为我们会先等待消息复制完毕）。延迟时间可以通过参数 <code>replica.lag.time.max.ms</code> 参数配置，它指定了副本在复制消息时可被允许的最大延迟时间。</p><p>输入中。。。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;数据可靠性&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#数据可靠性&quot;&gt;¶&lt;/a&gt;数据可靠性&lt;/h2&gt;
&lt;p&gt;Kafka 作为一个商业级消息中间件，消息可靠性的重要性可想而知。本文从 Producter 往 Broker 发送消息、Topic 分区副本以及 Leader 选举几个角度介绍数据的可靠性。&lt;/p&gt;</summary>
    
    
    
    <category term="kafka" scheme="https://gyl-coder.top/categories/kafka/"/>
    
    
    <category term="kafka" scheme="https://gyl-coder.top/tags/kafka/"/>
    
    <category term="数据可靠性" scheme="https://gyl-coder.top/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7/"/>
    
    <category term="数据一致性" scheme="https://gyl-coder.top/tags/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>Kafka Rebalance机制分析</title>
    <link href="https://gyl-coder.top/kafka/kafka-rebalance/"/>
    <id>https://gyl-coder.top/kafka/kafka-rebalance/</id>
    <published>2019-12-04T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.800Z</updated>
    
    <content type="html"><![CDATA[<p>Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 consumer 如何达成一致，来分配订阅 Topic 的每个分区。</p><p>例如：某 Group 下有 20 个 consumer 实例，它订阅了一个具有 100 个 partition 的 Topic 。正常情况下，kafka 会为每个 Consumer 平均的分配 5 个分区。这个分配的过程就是 Rebalance。</p><a id="more"></a><h2 id="触发-Rebalance-的时机"><a class="header-anchor" href="#触发-Rebalance-的时机">¶</a>触发 Rebalance 的时机</h2><p>Rebalance 的触发条件有3个。</p><ul><li>组成员个数发生变化。例如有新的 consumer 实例加入该消费组或者离开组。</li><li>订阅的 Topic 个数发生变化。</li><li>订阅 Topic 的分区数发生变化。</li></ul><p>Rebalance 发生时，Group 下所有 consumer 实例都会协调在一起共同参与，kafka 能够保证尽量达到最公平的分配。但是 Rebalance 过程对 consumer group 会造成比较严重的影响。在 Rebalance 的过程中 consumer group 下的所有消费者实例都会停止工作，等待 Rebalance 过程完成。</p><h2 id="Rebalance-过程分析"><a class="header-anchor" href="#Rebalance-过程分析">¶</a>Rebalance 过程分析</h2><p>Rebalance 过程分为两步：Join 和 Sync。</p><ol><li>Join 顾名思义就是加入组。这一步中，所有成员都向coordinator发送JoinGroup请求，请求加入消费组。一旦所有成员都发送了JoinGroup请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader——注意leader和coordinator不是一个概念。leader负责消费分配方案的制定。</li></ol><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951011.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951011.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><ol start="2"><li>Sync，这一步leader开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进SyncGroup请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了。</li></ol><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951012.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951012.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h2 id="Rebalance-场景分析"><a class="header-anchor" href="#Rebalance-场景分析">¶</a>Rebalance 场景分析</h2><h3 id="新成员加入组"><a class="header-anchor" href="#新成员加入组">¶</a>新成员加入组</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951013.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951013.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h3 id="组成员“崩溃”"><a class="header-anchor" href="#组成员“崩溃”">¶</a>组成员“崩溃”</h3><p>**组成员崩溃和组成员主动离开是两个不同的场景。**因为在崩溃时成员并不会主动地告知coordinator此事，coordinator有可能需要一个完整的session.timeout周期(心跳周期)才能检测到这种崩溃，这必然会造成consumer的滞后。可以说离开组是主动地发起rebalance；而崩溃则是被动地发起rebalance。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951014.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951014.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h3 id="组成员主动离开组"><a class="header-anchor" href="#组成员主动离开组">¶</a>组成员主动离开组</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951015.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951015.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h3 id="提交位移"><a class="header-anchor" href="#提交位移">¶</a>提交位移</h3><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951016.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/gyl-coder.github.com@v1.0.3/img/kafka/3951016.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h2 id="如何避免不必要的rebalance"><a class="header-anchor" href="#如何避免不必要的rebalance">¶</a>如何避免不必要的rebalance</h2><p>要避免 Rebalance，还是要从 Rebalance 发生的时机入手。我们在前面说过，Rebalance 发生的时机有三个：</p><ul><li>组成员数量发生变化</li><li>订阅主题数量发生变化</li><li>订阅主题的分区数发生变化</li></ul><p>后两个我们大可以人为的避免，发生rebalance最常见的原因是消费组成员的变化。</p><p>消费者成员正常的添加和停掉导致rebalance，这种情况无法避免，但是时在某些情况下，Consumer 实例会被 Coordinator 错误地认为 “已停止” 从而被“踢出”Group。从而导致rebalance。</p><p>当 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。如果某个 Consumer 实例不能及时地发送这些心跳请求，Coordinator 就会认为该 Consumer 已经 “死” 了，从而将其从 Group 中移除，然后开启新一轮 Rebalance。这个时间可以通过Consumer 端的参数 session.timeout.ms进行配置。默认值是 10 秒。</p><p>除了这个参数，Consumer 还提供了一个控制发送心跳请求频率的参数，就是 <a href="http://heartbeat.interval.ms">heartbeat.interval.ms</a>。这个值设置得越小，Consumer 实例发送心跳请求的频率就越高。频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更加快速地知晓当前是否开启 Rebalance，因为，目前 Coordinator 通知各个 Consumer 实例开启 Rebalance 的方法，就是将 REBALANCE_NEEDED 标志封装进心跳请求的响应体中。</p><p>除了以上两个参数，Consumer 端还有一个参数，用于控制 Consumer 实际消费能力对 Rebalance 的影响，即 <a href="http://max.poll.interval.ms">max.poll.interval.ms</a> 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起 “离开组” 的请求，Coordinator 也会开启新一轮 Rebalance。</p><p>通过上面的分析，我们可以看一下那些rebalance是可以避免的：</p><p><strong>第一类非必要 Rebalance 是因为未能及时发送心跳，导致 Consumer 被 “踢出”Group 而引发的</strong>。这种情况下我们可以设置 <strong><a href="http://session.timeout.ms">session.timeout.ms</a> 和 <a href="http://heartbeat.interval.ms">heartbeat.interval.ms</a></strong> 的值，来尽量避免rebalance的出现。（<strong>以下的配置是在网上找到的最佳实践，暂时还没测试过</strong>）</p><ul><li>设置 <a href="http://session.timeout.ms">session.timeout.ms</a> = 6s。</li><li>设置 <a href="http://heartbeat.interval.ms">heartbeat.interval.ms</a> = 2s。</li><li>要保证 Consumer 实例在被判定为 “dead” 之前，能够发送至少 3 轮的心跳请求，即 <a href="http://session.timeout.ms">session.timeout.ms</a> &gt;= 3 * <a href="http://heartbeat.interval.ms">heartbeat.interval.ms</a>。</li></ul><p>将 <a href="http://session.timeout.ms">session.timeout.ms</a> 设置成 6s 主要是为了让 Coordinator 能够更快地定位已经挂掉的 Consumer，早日把它们踢出 Group。</p><p><strong>第二类非必要 Rebalance 是 Consumer 消费时间过长导致的</strong>。此时，<strong><a href="http://max.poll.interval.ms">max.poll.interval.ms</a></strong> 参数值的设置显得尤为关键。如果要避免非预期的 Rebalance，你最好将该参数值设置得大一点，比你的下游最大处理时间稍长一点。</p><p>总之，要为业务处理逻辑留下充足的时间。这样，Consumer 就不会因为处理这些消息的时间太长而引发 Rebalance 。</p><h2 id="相关概念"><a class="header-anchor" href="#相关概念">¶</a>相关概念</h2><h3 id="coordinator"><a class="header-anchor" href="#coordinator">¶</a>coordinator</h3><p>Group Coordinator是一个服务，每个Broker在启动的时候都会启动一个该服务。Group Coordinator的作用是用来存储Group的相关Meta信息，并将对应Partition的Offset信息记录到Kafka内置Topic(__consumer_offsets)中。Kafka在0.9之前是基于Zookeeper来存储Partition的Offset信息(consumers/{group}/offsets/{topic}/{partition})，因为ZK并不适用于频繁的写操作，所以在0.9之后通过内置Topic的方式来记录对应Partition的Offset。</p><p>每个Group都会选择一个Coordinator来完成自己组内各Partition的Offset信息，选择的规则如下：</p><ul><li>1，计算Group对应在__consumer_offsets上的Partition</li><li>2，根据对应的Partition寻找该Partition的leader所对应的Broker，该Broker上的Group Coordinator即就是该Group的Coordinator</li></ul><p>Partition计算规则：</p><pre><code>partition-Id(__consumer_offsets) = Math.abs(groupId.hashCode() % groupMetadataTopicPartitionCount)</code></pre><p>其中groupMetadataTopicPartitionCount对应offsets.topic.num.partitions参数值，默认值是50个分区。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Rebalance 本质上是一种协议，规定了一个 Consumer Group 下的所有 consumer 如何达成一致，来分配订阅 Topic 的每个分区。&lt;/p&gt;
&lt;p&gt;例如：某 Group 下有 20 个 consumer 实例，它订阅了一个具有 100 个 partition 的 Topic 。正常情况下，kafka 会为每个 Consumer 平均的分配 5 个分区。这个分配的过程就是 Rebalance。&lt;/p&gt;</summary>
    
    
    
    <category term="kafka" scheme="https://gyl-coder.top/categories/kafka/"/>
    
    
    <category term="kafka" scheme="https://gyl-coder.top/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理</title>
    <link href="https://gyl-coder.top/kafka/kafka-partition-alocation/"/>
    <id>https://gyl-coder.top/kafka/kafka-partition-alocation/</id>
    <published>2019-12-03T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<p>在 kafka 中，分区分配是一个很重要的概念，它会影响Kafka整体的性能均衡。kafka 中一共有三处地方涉及此概念，分别是：生产者发送消息、消费者消费消息和创建主题。虽然这三处的对应操作都可以被称之为“分区分配”，但是其实质上所包含的内容却并不相同。</p><a id="more"></a><h2 id="生产者的分区分配"><a class="header-anchor" href="#生产者的分区分配">¶</a>生产者的分区分配</h2><p>用户在使用 kafka 客户端发送消息时，调用 <code>send</code> 方法发送消息之后，消息就自然而然的发送到了 broker 中。</p><p>其实这一过程需要经过拦截器、序列化器、分区器等一系列作用之后才能被真正发往 broker。消息在发往 broker 之前需要确认它需要发送到的分区，如果 ProducerRecord 中指定了 partition 字段，那就不需要分区器的作用，因为 partition 就代表的是所要发往的分区号。如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。</p><p>Kafka中提供的默认分区器是DefaultPartitioner，它实现了Partitioner接口（用户可以实现这个接口来自定义分区器），其中的partition方法就是用来实现具体的分区分配逻辑：</p><pre><code class="language-java">public int partition(String topic, Object key, byte[] keyBytes,                     Object value, byte[] valueBytes, Cluster cluster);</code></pre><p>默认情况下，如果消息的key不为null，那么默认的分区器会对key进行哈希（采用MurmurHash2算法，具备高运算性能及低碰撞率），最终根据得到的哈希值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息将会以轮询的方式发往 topic 的各个可用分区。</p><blockquote><p>注意：如果key不为null，那么计算得到的分区号会是所有分区中的任意一个；如果key为null并且有可用分区，那么计算得到的分区号仅为可用分区中的任意一个，注意两者之间的差别。</p></blockquote><h2 id="消费者的分区分配"><a class="header-anchor" href="#消费者的分区分配">¶</a>消费者的分区分配</h2><p>在Kafka的默认规则中，每一个分区只能被同一个消费组中的一个消费者消费。消费者的分区分配是指为消费组中的消费者分配所订阅主题中的分区。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka8.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka8.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>如图所示，某个主题中共有4个分区（Partition）：P0、P1、P2、P3。有两个消费组A和B都订阅了这个主题，消费组A中有4个消费者（C0、C1、C2和C3），消费组B中有2个消费者（C4和C5）。按照Kafka默认的规则，最后的分配结果是消费组A中的每一个消费者分配到1个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。每个消费者只能消费所分配到的分区中的消息。</p><p>对于消费者的分区分配而言，Kafka自身提供了三种策略，分别为 <code>RangeAssignor</code>、<code> RoundRobinAssignor</code> 以及 <code>StickyAssignor</code> ，其中 <code>RangeAssignor</code> 为默认的分区分配策略。</p><h3 id="RangeAssignor"><a class="header-anchor" href="#RangeAssignor">¶</a>RangeAssignor</h3><p>RangeAssignor策略的原理是按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者。对于每一个topic，RangeAssignor策略会将消费组内所有订阅这个topic的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围，如果不够平均分配，那么字典序靠前的消费者会被多分配一个分区。</p><p>假设n=分区数/消费者数量，m=分区数%消费者数量，那么前m个消费者每个分配n+1个分区，后面的（消费者数量-m）个消费者每个分配n个分区。</p><p>为了更加通俗的讲解RangeAssignor策略，我们不妨再举一些示例。假设消费组内有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有4个分区，那么所订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t0p3、t1p0、t1p1、t1p2、t1p3。最终的分配结果为：</p><pre><code>消费者C0：t0p0、t0p1、t1p0、t1p1消费者C1：t0p2、t0p3、t1p2、t1p3</code></pre><p>这样分配的很均匀，那么此种分配策略能够一直保持这种良好的特性呢？我们再来看下另外一种情况。假设上面例子中2个主题都只有3个分区，那么所订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为：</p><pre><code>消费者C0：t0p0、t0p1、t1p0、t1p1消费者C1：t0p2、t1p2</code></pre><p>可以明显的看到这样的分配并不均匀，如果将类似的情形扩大，有可能会出现部分消费者过载的情况。对此我们再来看下另一种RoundRobinAssignor策略的分配效果如何。</p><h3 id="RoundRobinAssignor"><a class="header-anchor" href="#RoundRobinAssignor">¶</a>RoundRobinAssignor</h3><p>RoundRobinAssignor策略的原理是将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，然后通过轮询方式逐个将分区以此分配给每个消费者。RoundRobinAssignor策略对应的partition.assignment.strategy参数值为：org.apache.kafka.clients.consumer.RoundRobinAssignor。</p><p>如果同一个消费组内所有的消费者的订阅信息都是相同的，那么RoundRobinAssignor策略的分区分配会是均匀的。举例，假设消费组中有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，那么所订阅的所有分区可以标识为：t0p0、t0p1、t0p2、t1p0、t1p1、t1p2。最终的分配结果为：</p><pre><code>消费者C0：t0p0、t0p2、t1p1消费者C1：t0p1、t1p0、t1p2</code></pre><p>如果同一个消费组内的消费者所订阅的信息是不相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个topic，那么在分配分区的时候此消费者将分配不到这个topic的任何分区。</p><p>举例，假设消费组内有3个消费者C0、C1和C2，它们共订阅了3个主题：t0、t1、t2，这3个主题分别有1、2、3个分区，即整个消费组订阅了t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。具体而言，消费者C0订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2，那么最终的分配结果为：</p><pre><code>消费者C0：t0p0消费者C1：t1p0消费者C2：t1p1、t2p0、t2p1、t2p2</code></pre><p>可以看到RoundRobinAssignor策略也不是十分完美，这样分配其实并不是最优解，因为完全可以将分区t1p1分配给消费者C1。</p><h3 id="StickyAssignor"><a class="header-anchor" href="#StickyAssignor">¶</a>StickyAssignor</h3><p>我们再来看一下StickyAssignor策略，“sticky”这个单词可以翻译为“粘性的”，Kafka从0.11.x版本开始引入这种分配策略，它主要有两个目的：</p><ol><li>分区的分配要尽可能的均匀；</li><li>分区的分配尽可能的与上次分配的保持相同。当两者发生冲突时，第一个目标优先于第二个目标。鉴于这两个目标，StickyAssignor策略的具体实现要比RangeAssignor和RoundRobinAssignor这两种分配策略要复杂很多。我们举例来看一下StickyAssignor策略的实际效果。</li></ol><p>假设消费组内有3个消费者：C0、C1和C2，它们都订阅了4个主题：t0、t1、t2、t3，并且每个主题有2个分区，也就是说整个消费组订阅了t0p0、t0p1、t1p0、t1p1、t2p0、t2p1、t3p0、t3p1这8个分区。最终的分配结果如下：</p><pre><code>消费者C0：t0p0、t1p1、t3p0消费者C1：t0p1、t2p0、t3p1消费者C2：t1p0、t2p1</code></pre><p>这样初看上去似乎与采用RoundRobinAssignor策略所分配的结果相同，但事实是否真的如此呢？再假设此时消费者C1脱离了消费组，那么消费组就会执行再平衡操作，进而消费分区会重新分配。如果采用RoundRobinAssignor策略，那么此时的分配结果如下：</p><pre><code>消费者C0：t0p0、t1p0、t2p0、t3p0消费者C2：t0p1、t1p1、t2p1、t3p1</code></pre><p>如分配结果所示，RoundRobinAssignor策略会按照消费者C0和C2进行重新轮询分配。而如果此时使用的是StickyAssignor策略，那么分配结果为：</p><pre><code>消费者C0：t0p0、t1p1、t3p0、t2p0消费者C2：t1p0、t2p1、t0p1、t3p1</code></pre><p>可以看到分配结果中保留了上一次分配中对于消费者C0和C2的所有分配结果，并将原来消费者C1的“负担”分配给了剩余的两个消费者C0和C2，最终C0和C2的分配还保持了均衡。</p><p>如果发生分区重分配，那么对于同一个分区而言有可能之前的消费者和新指派的消费者不是同一个，对于之前消费者进行到一半的处理还要在新指派的消费者中再次复现一遍，这显然很浪费系统资源。StickyAssignor策略如同其名称中的“sticky”一样，让分配策略具备一定的“粘性”，尽可能地让前后两次分配相同，进而减少系统资源的损耗以及其它异常情况的发生。</p><p>到目前为止所分析的都是消费者的订阅信息都是相同的情况，我们来看一下订阅信息不同的情况下的处理。</p><p>举例，同样消费组内有3个消费者：C0、C1和C2，集群中有3个主题：t0、t1和t2，这3个主题分别有1、2、3个分区，也就是说集群中有t0p0、t1p0、t1p1、t2p0、t2p1、t2p2这6个分区。消费者C0订阅了主题t0，消费者C1订阅了主题t0和t1，消费者C2订阅了主题t0、t1和t2。</p><p>如果此时采用RoundRobinAssignor策略，那么最终的分配结果如下所示（和讲述RoundRobinAssignor策略时的一样，这样不妨赘述一下）：</p><pre><code>【分配结果集1】消费者C0：t0p0消费者C1：t1p0消费者C2：t1p1、t2p0、t2p1、t2p2</code></pre><p>如果此时采用的是StickyAssignor策略，那么最终的分配结果为：</p><pre><code>【分配结果集2】消费者C0：t0p0消费者C1：t1p0、t1p1消费者C2：t2p0、t2p1、t2p2</code></pre><p>可以看到这是一个最优解（消费者C0没有订阅主题t1和t2，所以不能分配主题t1和t2中的任何分区给它，对于消费者C1也可同理推断）。<br>假如此时消费者C0脱离了消费组，那么RoundRobinAssignor策略的分配结果为：</p><pre><code>消费者C1：t0p0、t1p1消费者C2：t1p0、t2p0、t2p1、t2p2</code></pre><p>可以看到RoundRobinAssignor策略保留了消费者C1和C2中原有的3个分区的分配：t2p0、t2p1和t2p2（针对结果集1）。而如果采用的是StickyAssignor策略，那么分配结果为：</p><pre><code>消费者C1：t1p0、t1p1、t0p0消费者C2：t2p0、t2p1、t2p2</code></pre><p>可以看到StickyAssignor策略保留了消费者C1和C2中原有的5个分区的分配：t1p0、t1p1、t2p0、t2p1、t2p2。</p><p>从结果上看StickyAssignor策略比另外两者分配策略而言显得更加的优异，这个策略的代码实现也是异常复杂。</p><h3 id="自定义分区分配策略"><a class="header-anchor" href="#自定义分区分配策略">¶</a>自定义分区分配策略</h3><p>kafka 处理支持默认提供的三种分区分配算法，还支持用户自定义分区分配算法，自定义的分配策略必须要实现org.apache.kafka.clients.consumer.internals.PartitionAssignor接口。PartitionAssignor接口的定义如下：</p><pre><code class="language-java">Subscription subscription(Set&lt;String&gt; topics);String name();Map&lt;String, Assignment&gt; assign(Cluster metadata,                                Map&lt;String, Subscription&gt; subscriptions);void onAssignment(Assignment assignment);class Subscription &amp;#123;    private final List&lt;String&gt; topics;    private final ByteBuffer userData;（省略若干方法……）&amp;#125;class Assignment &amp;#123;    private final List&lt;TopicPartition&gt; partitions;    private final ByteBuffer userData;（省略若干方法……）&amp;#125;</code></pre><p>PartitionAssignor接口中定义了两个内部类：Subscription和Assignment。</p><p>Subscription类用来表示消费者的订阅信息，类中有两个属性：topics和userData，分别表示消费者所订阅topic列表和用户自定义信息。PartitionAssignor接口通过subscription()方法来设置消费者自身相关的Subscription信息，注意到此方法中只有一个参数topics，与Subscription类中的topics的相互呼应，但是并没有有关userData的参数体现。为了增强用户对分配结果的控制，可以在subscription()方法内部添加一些影响分配的用户自定义信息赋予userData，比如：权重、ip地址、host或者机架（rack）等等。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka9.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka9.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>举例，在subscription()这个方法中提供机架信息，标识此消费者所部署的机架位置，在分区分配时可以根据分区的leader副本所在的机架位置来实施具体的分配，这样可以让消费者与所需拉取消息的broker节点处于同一机架。参考下图，消费者consumer1和broker1都部署在机架rack1上，消费者consumer2和broker2都部署在机架rack2上。如果分区的分配不是机架感知的，那么有可能与图（上部分）中的分配结果一样，consumer1消费broker2中的分区，而consumer2消费broker1中的分区；如果分区的分配是机架感知的，那么就会出现图（下部分）的分配结果，consumer1消费broker1中的分区，而consumer2消费broker2中的分区，这样相比于前一种情形而言，既可以减少消费延迟又可以减少跨机架带宽的占用。</p><p>再来说一下Assignment类，它是用来表示分配结果信息的，类中也有两个属性：partitions和userData，分别表示所分配到的分区集合和用户自定义的数据。可以通过PartitionAssignor接口中的onAssignment()方法是在每个消费者收到消费组leader分配结果时的回调函数，例如在StickyAssignor策略中就是通过这个方法保存当前的分配方案，以备在下次消费组再平衡（rebalance）时可以提供分配参考依据。</p><p>接口中的name()方法用来提供分配策略的名称，对于Kafka提供的3种分配策略而言，RangeAssignor对应的protocol_name为“range”，RoundRobinAssignor对应的protocol_name为“roundrobin”，StickyAssignor对应的protocol_name为“sticky”，所以自定义的分配策略中要注意命名的时候不要与已存在的分配策略发生冲突。这个命名用来标识分配策略的名称，在后面所描述的加入消费组以及选举消费组leader的时候会有涉及。</p><p>真正的分区分配方案的实现是在assign()方法中，方法中的参数metadata表示集群的元数据信息，而subscriptions表示消费组内各个消费者成员的订阅信息，最终方法返回各个消费者的分配信息。</p><p>Kafka中还提供了一个抽象类org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor，它可以简化PartitionAssignor接口的实现，对assign()方法进行了实现，其中会将Subscription中的userData信息去掉后，在进行分配。Kafka提供的3种分配策略都是继承自这个抽象类。如果开发人员在自定义分区分配策略时需要使用userData信息来控制分区分配的结果，那么就不能直接继承AbstractPartitionAssignor这个抽象类，而需要直接实现PartitionAssignor接口。</p><p>下面代码参考Kafka中的RangeAssignor策略来自定义一个随机的分配策略，这里笔者称之为RandomAssignor，具体代码实现如下：</p><pre><code class="language-java">package org.apache.kafka.clients.consumer;import org.apache.kafka.clients.consumer.internals.AbstractPartitionAssignor;import org.apache.kafka.common.TopicPartition;import java.util.*;public class RandomAssignor extends AbstractPartitionAssignor &amp;#123;    @Override    public String name() &amp;#123;        return &quot;random&quot;;    &amp;#125;    @Override    public Map&lt;String, List&lt;TopicPartition&gt;&gt; assign(            Map&lt;String, Integer&gt; partitionsPerTopic,            Map&lt;String, Subscription&gt; subscriptions) &amp;#123;        Map&lt;String, List&lt;String&gt;&gt; consumersPerTopic = consumersPerTopic(subscriptions);        Map&lt;String, List&lt;TopicPartition&gt;&gt; assignment = new HashMap&lt;&gt;();        for (String memberId : subscriptions.keySet()) &amp;#123;            assignment.put(memberId, new ArrayList&lt;&gt;());        &amp;#125;        // 针对每一个topic进行分区分配        for (Map.Entry&lt;String, List&lt;String&gt;&gt; topicEntry : consumersPerTopic.entrySet()) &amp;#123;            String topic = topicEntry.getKey();            List&lt;String&gt; consumersForTopic = topicEntry.getValue();            int consumerSize = consumersForTopic.size();            Integer numPartitionsForTopic = partitionsPerTopic.get(topic);            if (numPartitionsForTopic == null) &amp;#123;                continue;            &amp;#125;            // 当前topic下的所有分区            List&lt;TopicPartition&gt; partitions = AbstractPartitionAssignor.partitions(topic, numPartitionsForTopic);            // 将每个分区随机分配给一个消费者            for (TopicPartition partition : partitions) &amp;#123;                int rand = new Random().nextInt(consumerSize);                String randomConsumer = consumersForTopic.get(rand);                assignment.get(randomConsumer).add(partition);            &amp;#125;        &amp;#125;        return assignment;    &amp;#125;    // 获取每个topic所对应的消费者列表，即：[topic, List[consumer]]    private Map&lt;String, List&lt;String&gt;&gt; consumersPerTopic(Map&lt;String, Subscription&gt; consumerMetadata) &amp;#123;        Map&lt;String, List&lt;String&gt;&gt; res = new HashMap&lt;&gt;();        for (Map.Entry&lt;String, Subscription&gt; subscriptionEntry : consumerMetadata.entrySet()) &amp;#123;            String consumerId = subscriptionEntry.getKey();            for (String topic : subscriptionEntry.getValue().topics())                put(res, topic, consumerId);        &amp;#125;        return res;    &amp;#125;&amp;#125;</code></pre><p>在使用时，消费者客户端需要添加相应的Properties参数，示例如下：</p><pre><code class="language-java">properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, RandomAssignor.class.getName());</code></pre><h3 id="分配的实施"><a class="header-anchor" href="#分配的实施">¶</a>分配的实施</h3><p>我们了解了Kafka中消费者的分区分配策略之后是否会有这样的疑问：如果消费者客户端中配置了两个分配策略，那么以哪个为准？如果有多个消费者，彼此所配置的分配策略并不完全相同，那么以哪个为准？多个消费者之间的分区分配是需要协同的，那么这个协同的过程又是怎样？</p><p>在kafka中有一个组协调器（GroupCoordinator）负责来协调消费组内各个消费者的分区分配，对于每一个消费组而言，在kafka服务端都会有其对应的一个组协调器。具体的协调分区分配的过程如下：<br>1.首先各个消费者向GroupCoordinator提案各自的分配策略。如下图所示，各个消费者提案的分配策略和订阅信息都包含在JoinGroupRequest请求中。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka10.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka10.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>2.GroupCoordinator收集各个消费者的提案，然后执行以下两个步骤：一、选举消费组的leader；二、选举消费组的分区分配策略。</p><p>选举消费组的分区分配策略比较好理解，为什么这里还要选举消费组的leader，因为最终的分区分配策略的实施需要有一个成员来执行，而这个leader消费者正好扮演了这一个角色。在Kafka中把具体的分区分配策略的具体执行权交给了消费者客户端，这样可以提供更高的灵活性。比如需要变更分配策略，那么只需修改消费者客户端就醒来，而不必要修改并重启Kafka服务端。</p><p>怎么选举消费组的leader? 这个分两种情况分析：如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader；如果某一时刻leader消费者由于某些原因退出了消费组，那么就会重新选举一个新的leader，这个重新选举leader的过程又更为“随意”了，相关代码如下：</p><pre><code class="language-scala">//scala code.private val members = new mutable.HashMap[String, MemberMetadata]var leaderId = members.keys.head</code></pre><p>解释一下这2行代码：在GroupCoordinator中消费者的信息是以HashMap的形式存储的，其中key为消费者的名称，而value是消费者相关的元数据信息。leaderId表示leader消费者的名称，它的取值为HashMap中的第一个键值对的key，这种选举的方式基本上和随机挑选无异。<br>总体上来说，消费组的leader选举过程是很随意的。</p><p>怎么选举消费组的分配策略？投票决定。每个消费者都可以设置自己的分区分配策略，对于消费组而言需要从各个消费者所呈报上来的各个分配策略中选举一个彼此都“信服”的策略来进行整体上的分区分配。这个分区分配的选举并非由leader消费者来决定，而是根据消费组内的各个消费者投票来决定。这里所说的“根据组内的各个消费者投票来决定”不是指GroupCoordinator还要与各个消费者进行进一步交互来实施，而是根据各个消费者所呈报的分配策略来实施。最终所选举的分配策略基本上可以看做是被各个消费者所支持的最多的策略，具体的选举过程如下：</p><p>收集各个消费者所支持的所有分配策略，组成候选集candidates。<br>每个消费者从候选集candidates中找出第一个自身所支持的策略，为这个策略投上一票。<br>计算候选集中各个策略的选票数，选票数最多的策略即为当前消费组的分配策略。<br>如果某个消费者并不支持所选举出的分配策略，那么就会报错。<br>3.GroupCoordinator发送回执给各个消费者，并交由leader消费者执行具体的分区分配。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka11.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka11.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>如上图所示，JoinGroupResponse回执中包含有GroupCoordinator中投票选举出的分配策略的信息。并且，只有leader消费者的回执中包含各个消费者的订阅信息，因为只需要leader消费者根据订阅信息来执行具体的分配，其余的消费并不需要。</p><p>4.leader消费者在整理出具体的分区分配方案后通过SyncGroupRequest请求提交给GroupCoordinator，然后GroupCoordinator为每个消费者挑选出各自的分配结果并通过SyncGroupResponse回执以告知它们。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka12.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka12.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h2 id="broker端的分区分配"><a class="header-anchor" href="#broker端的分区分配">¶</a>broker端的分区分配</h2><p>生产者的分区分配是指为每条消息指定其所要发往的分区，消费者中的分区分配是指为消费者指定其可以消费消息的分区，而这里的分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个broker中创建哪些分区的副本。分区分配是否均衡会影响到Kafka整体的负载均衡，具体还会牵涉到优先副本等概念。</p><p>在创建主题时，如果使用了replica-assignment参数，那么就按照指定的方案来进行分区副本的创建；如果没有使用replica-assignment参数，那么就需要按照内部的逻辑来计算分配方案了。使用kafka-topics.sh脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略：未指定机架信息和指定机架信息。如果集群中所有的broker节点都没有配置broker.rack参数，或者使用disable-rack-aware参数来创建主题，那么采用的就是未指定机架信息的分配策略，否则采用的就是指定机架信息的分配策略。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在 kafka 中，分区分配是一个很重要的概念，它会影响Kafka整体的性能均衡。kafka 中一共有三处地方涉及此概念，分别是：生产者发送消息、消费者消费消息和创建主题。虽然这三处的对应操作都可以被称之为“分区分配”，但是其实质上所包含的内容却并不相同。&lt;/p&gt;</summary>
    
    
    
    <category term="kafka" scheme="https://gyl-coder.top/categories/kafka/"/>
    
    
    <category term="kafka" scheme="https://gyl-coder.top/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>kafka的listeners配置错误导致主线程阻塞</title>
    <link href="https://gyl-coder.top/kafka/kafka-listeners-config/"/>
    <id>https://gyl-coder.top/kafka/kafka-listeners-config/</id>
    <published>2019-12-02T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<h2 id="问题背景"><a class="header-anchor" href="#问题背景">¶</a>问题背景</h2><p>我们在用kafka的时候，偶尔会遇到这样这样一个问题。</p><p>我们写的kafka的客户端程序，在启动的时候，会无缘无故的 <code>卡住（阻塞）</code> 如下图所示：</p><a id="more"></a><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka6.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka6.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>这时程序会长时间阻塞在这里，无法继续进行后续操作。</p><h2 id="问题排查"><a class="header-anchor" href="#问题排查">¶</a>问题排查</h2><p>因为日志没有任何报错信息，但是又可以肯定当前项目并没有完全启动成功。感觉像是程序当中有个地方卡到了。通过 <code>VisualVM</code> 工具dump 线程相关的信息，很快发现了问题所在。原来卡在了consumer初始化的地方。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka7.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka7.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>一下是我这边的处理方式，大家可以参考下。如果有更好的方式欢迎大家相互交流。</p><p>以下方法是在初始化Consumer的时候进行处理的：</p><pre><code class="language-java">public KafkaConsumerImpl init() &amp;#123;if (group == null || group.isEmpty()) &amp;#123;throw new RuntimeException(&quot;phoenix.mq.group is empty&quot;);&amp;#125;Properties props = new Properties();props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, namesrvAddr);props.put(ConsumerConfig.GROUP_ID_CONFIG, group);// 是否允许自动提交offset，这里设为false，下面手动提交props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, &quot;false&quot;);// ...consumer = new KafkaConsumer&lt;&gt;(props);// consumer 订阅的topic及partitiontopicPartition = new TopicPartition(this.topic, this.partitionId);this.partitions = Collections.singletonList(topicPartition);// 元数据初始化和连接测试，3次失败后抛出异常Callable&lt;Boolean&gt; call = new Callable&lt;Boolean&gt;() &amp;#123;boolean res = false;int tryTimes = 3;        @Overridepublic Boolean call() throws Exception &amp;#123;while (tryTimes-- &gt; 0) &amp;#123;try &amp;#123;consumer.assign(partitions);// 默认初始化offset当前最大值nextBeginOffset = consumer.position(topicPartition);res = true;break;&amp;#125; catch (Exception e) &amp;#123;if (e instanceof InterruptedException) &amp;#123;break; // 如果position在阻塞状态时，调用了 task.cancel 会抛出此异常。直接退出即可&amp;#125;LOG.error(e.getMessage(), e);LOG.error(&quot; ==&gt; error when trying to fetch metadata for kafka. topic&lt;&amp;#123;&amp;#125;&gt;, partition&lt;&amp;#123;&amp;#125;&gt;&quot;, topic,partitionId);&amp;#125;// sleeptry &amp;#123;Thread.sleep(2000);&amp;#125;catch (InterruptedException e) &amp;#123;e.printStackTrace();&amp;#125;&amp;#125;return res;&amp;#125;&amp;#125;;FutureTask&lt;Boolean&gt; task = new FutureTask&lt;&gt;(call);new Thread(task).start();boolean isOk = false;try &amp;#123;isOk = task.get(10000, TimeUnit.MILLISECONDS);&amp;#125;catch (Exception e) &amp;#123;LOG.error(&quot;Get task result timeout&quot;, e);&amp;#125;task.cancel(true);if (isOk) &amp;#123;LOG.info(&quot; ==&gt; init kafka consumer succeed: servers&lt;&amp;#123;&amp;#125;&gt;, topic&lt;&amp;#123;&amp;#125;&gt;, partition&lt;&amp;#123;&amp;#125;&gt;, nextBeginOffset&lt;&amp;#123;&amp;#125;&gt;&quot;,namesrvAddr, topic, partitionId, nextBeginOffset);&amp;#125;else &amp;#123;throw new RuntimeException(String.format(&quot; ==&gt; init kafka consumer failed. please check the conf (listeners or advertised.listeners or ...) and try to ping the host name in the conf value&quot;));&amp;#125;return this;&amp;#125;</code></pre><p>利用 FutureTask 的特性，定义一个定时任务， 在初始化Consumer的时候，尝试去连接kafka，如果配置的kafka的地址有误，或者配置出错在这里可以通过抛出错误体现出来。</p><p>最后通过<code>task.get()</code> 方法返回的结果来判断 Consumer 是否成功初始化。</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;问题背景&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#问题背景&quot;&gt;¶&lt;/a&gt;问题背景&lt;/h2&gt;
&lt;p&gt;我们在用kafka的时候，偶尔会遇到这样这样一个问题。&lt;/p&gt;
&lt;p&gt;我们写的kafka的客户端程序，在启动的时候，会无缘无故的 &lt;code&gt;卡住（阻塞）&lt;/code&gt; 如下图所示：&lt;/p&gt;</summary>
    
    
    
    <category term="kafka" scheme="https://gyl-coder.top/categories/kafka/"/>
    
    
    <category term="kafka" scheme="https://gyl-coder.top/tags/kafka/"/>
    
    <category term="线程阻塞" scheme="https://gyl-coder.top/tags/%E7%BA%BF%E7%A8%8B%E9%98%BB%E5%A1%9E/"/>
    
  </entry>
  
  <entry>
    <title>kafka中的ISR、AR代表什么？ISR的伸缩性又指什么？</title>
    <link href="https://gyl-coder.top/kafka/kafka-isr-ar/"/>
    <id>https://gyl-coder.top/kafka/kafka-isr-ar/</id>
    <published>2019-12-01T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<p>相信大家已经对 <code>kafka</code> 的基本概念已经有一定的了解了，下面直接来分析一下 ISR 和 AR 的概念。</p><a id="more"></a><h2 id="ISR-and-AR"><a class="header-anchor" href="#ISR-and-AR">¶</a>ISR and AR</h2><p>简单来说，分区中的所有副本统称为 <code>AR</code> (Assigned Replicas)。所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成 <code>ISR</code> (In Sync Replicas)。 ISR 集合是 AR 集合的一个子集。消息会先发送到leader副本，然后follower副本才能从leader中拉取消息进行同步。同步期间，follow副本相对于leader副本而言会有一定程度的滞后。前面所说的 ”一定程度同步“ 是指可忍受的滞后范围，这个范围可以通过参数进行配置。于leader副本同步滞后过多的副本（不包括leader副本）将组成 <code>OSR</code> （Out-of-Sync Replied）由此可见，AR = ISR + OSR。正常情况下，所有的follower副本都应该与leader 副本保持  一定程度的同步，即AR=ISR，OSR集合为空。</p><h2 id="ISR-的伸缩性"><a class="header-anchor" href="#ISR-的伸缩性">¶</a>ISR 的伸缩性</h2><p><strong>leader副本负责维护和跟踪</strong> <code>ISR</code> 集合中所有follower副本的滞后状态，当follower副本落后太多或失效时，leader副本会把它从 ISR 集合中剔除。如果 <code>OSR</code> 集合中所有follower副本“追上”了leader副本，那么leader副本会把它从 OSR 集合转移至 ISR 集合。默认情况下，当leader副本发生故障时，只有在 ISR 集合中的follower副本才有资格被选举为新的leader，而在 OSR 集合中的副本则没有任何机会（不过这个可以通过配置来改变）。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;相信大家已经对 &lt;code&gt;kafka&lt;/code&gt; 的基本概念已经有一定的了解了，下面直接来分析一下 ISR 和 AR 的概念。&lt;/p&gt;</summary>
    
    
    
    <category term="kafka" scheme="https://gyl-coder.top/categories/kafka/"/>
    
    
    <category term="kafka" scheme="https://gyl-coder.top/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka中的HW、LEO、LSO等分别代表什么？</title>
    <link href="https://gyl-coder.top/kafka/kafka-hw-leo-lso/"/>
    <id>https://gyl-coder.top/kafka/kafka-hw-leo-lso/</id>
    <published>2019-11-30T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<p><code>HW</code> 、 <code>LEO</code> 等概念和上一篇文章所说的 <code>ISR</code>有着紧密的关系，如果不了解 ISR 可以先看下ISR相关的介绍。</p><p><code>HW</code> （High Watermark）俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。</p><p>下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。</p><a id="more"></a><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka1.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka1.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p><code>LEO</code> （Log End Offset），标识当前日志文件中下一条待写入的消息的offset。上图中offset为9的位置即为当前日志文件的 LEO，LEO 的大小相当于当前日志分区中最后一条消息的offset值加1.分区 ISR 集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息。</p><hr><p>下面具体分析一下 ISR 集合和 HW、LEO的关系。</p><p>假设某分区的 ISR 集合中有 3 个副本，即一个 leader 副本和 2 个 follower 副本，此时分区的 LEO 和 HW 都分别为 3 。消息3和消息4从生产者出发之后先被存入leader副本。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka2.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka2.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka3.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka3.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>在消息被写入leader副本之后，follower副本会发送拉取请求来拉取消息3和消息4进行消息同步。</p><p>在同步过程中不同的副本同步的效率不尽相同，在某一时刻follower1完全跟上了leader副本而follower2只同步了消息3，如此leader副本的LEO为5，follower1的LEO为5，follower2的LEO 为4，那么当前分区的HW取最小值4，此时消费者可以消费到offset0至3之间的消息。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka4.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka4.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>当所有副本都成功写入消息3和消息4之后，整个分区的HW和LEO都变为5，因此消费者可以消费到offset为4的消息了。</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka5.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/kafka/kafka5.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><p>由此可见kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的follower副本都复制完，这条消息才会被确认已成功提交，这种复制方式极大的影响了性能。而在异步复制的方式下，follower副本异步的从leader副本中复制数据，数据只要被leader副本写入就会被认为已经成功提交。在这种情况下，如果follower副本都还没有复制完而落后于leader副本，然后leader副本宕机，则会造成数据丢失。kafka使用这种ISR的方式有效的权衡了数据可靠性和性能之间的关系。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;HW&lt;/code&gt; 、 &lt;code&gt;LEO&lt;/code&gt; 等概念和上一篇文章所说的 &lt;code&gt;ISR&lt;/code&gt;有着紧密的关系，如果不了解 ISR 可以先看下ISR相关的介绍。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;HW&lt;/code&gt; （High Watermark）俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。&lt;/p&gt;
&lt;p&gt;下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。&lt;/p&gt;</summary>
    
    
    
    <category term="kafka" scheme="https://gyl-coder.top/categories/kafka/"/>
    
    
    <category term="kafka" scheme="https://gyl-coder.top/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>智力题</title>
    <link href="https://gyl-coder.top/iq/"/>
    <id>https://gyl-coder.top/iq/</id>
    <published>2019-11-13T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<h4 id="No-1"><a class="header-anchor" href="#No-1">¶</a>No.1</h4><p>给一个瞎子52张扑克牌，并告诉他里面恰好有10张牌是正面朝上的。要求这个瞎子把牌分成两堆，使得每堆牌里正面朝上的牌的张数一样多。瞎子应该怎么做？</p><p>**答案：**把扑克牌分成两堆，一堆10张，一堆42张。然后，把小的那一堆里的所有牌全部翻过来。</p><h4 id="No-2"><a class="header-anchor" href="#No-2">¶</a>No.2</h4><p>如何用一枚硬币等概率地产生一个1到3之间的随机整数？如果这枚硬币是不公正的呢？</p><p>**答案：**如果是公正的硬币，则投掷两次，“正反”为1，“反正”为2，“正正”为3，“反反”重来。</p><p>如果是不公正的硬币，注意到出现“正反”和“反正”的概率一样，因此令“正反反正”、“反正正反”、“正反正反”分别为1、2、3，其余情况重来。另一种更妙的办法是，投掷三次硬币，“正反反”为1，“反正反”为2，“反反正”为3，其余情况重来。</p><h4 id="No-3"><a class="header-anchor" href="#No-3">¶</a>No.3</h4><p>30枚面值不全相同的硬币摆成一排，甲、乙两个人轮流选择这排硬币的其中一端，并取走最外边的那枚硬币。如果你先取硬币，能保证得到的钱不会比对手少吗？</p><p>**答案：**先取者可以让自己总是取奇数位置上的硬币或者总是取偶数位置上的硬币。数一数是奇数位置上的面值总和多还是偶数位置上的面值总和多，然后总是取这些位置上的硬币就可以了。</p><h4 id="No-4"><a class="header-anchor" href="#No-4">¶</a>No.4</h4><p>一个环形轨道上有n个加油站，所有加油站的油量总和正好够车跑一圈。证明，总能找到其中一个加油站，使得初始时油箱为空的汽车从这里出发，能够顺利环行一圈回到起点。</p><p>**答案：**总存在一个加油站，仅用它的油就足够跑到下一个加油站（否则所有加油站的油量加起来将不够全程）。把下一个加油站的所有油都提前搬到这个加 油站来，并把油已被搬走的加油站无视掉。在剩下的加油站中继续寻找油量足以到达下个加油站的地方，不断合并加油站，直到只剩一个加油站为止。显然从这里出发就能顺利跑完全程。</p><p>另一种证明方法：先让汽车油箱里装好足够多的油，随便从哪个加油站出发试跑一圈。车每到一个加油站时，记录此时油箱里剩下的油量，然后把那个加油站的油全部装上。试跑完一圈后，检查刚才路上到哪个加油站时剩的油量最少，那么空着油箱从那里出发显然一定能跑完全程。</p><h4 id="No-5"><a class="header-anchor" href="#No-5">¶</a>No.5</h4><p>初始时，两个口袋里各有一个球。把后面的n-2个球依次放入口袋，放进哪个口袋其概率与各口袋已有的球数成正比。这样下来，球数较少的那个口袋平均期望有多少个球？</p><p>**答案：**先考虑一个看似无关的问题——怎样产生一个1到n的随机排列。首先，在纸上写下数字1；然后，把2写在1的左边或者右边；然后，把3写在最 左边，最右边，或者插进1和2之间……总之，把数字i等概率地放进由前面i-1个数产生的（包括最左端和最右端在内的）共i个空位中的一个。这样生成的显 然是一个完全随机的排列。</p><p>我们换一个角度来看题目描述的过程：假想用一根绳子把两个球拴在一起，把这根绳子标号为1。接下来，把其中一个小球分裂成两个小球，这两个小球用 标号为2的绳子相连。总之，把“放进第i个球”的操作想象成把其中一个球分裂成两个用标有i-1的绳子相连的小球。联想我们前面的讨论，这些绳子的标号事 实上是一个随机的全排列，也就是说最开始绳子1的位置最后等可能地出现在每个地方。也就是说，它两边的小球个数(1,n-1)、(2,n-2)、 (3,n-3)、……、(n-1,1)这n-1种情况等可能地发生。因此，小袋子里的球数大约为n/4个。准确地说，当n为奇数时，小袋子里的球数为 (n+1)/4；当n为偶数时，小袋子里的球数为n^2/(4n-4)。</p><h4 id="No-6"><a class="header-anchor" href="#No-6">¶</a>No.6</h4><p>考虑一个n*n的棋盘，把有公共边的两个格子叫做相邻的格子。初始时，有些格子里有病毒。每一秒钟后，只要一个格子至少有两个相邻格子染上了病毒，那么他自己也会被感染。为了让所有的格子都被感染，初始时最少需要有几个带病毒的格子？给出一种方案并证明最优性。</p><p>**答案：**至少要n个，比如一条对角线上的n个格子。n个格子也是必需的。当一个新的格子被感染后，全体被感染的格子所组成的图形的周长将减少0个、 2个或4个单位（具体减少了多少要看它周围被感染的格子有多少个）。又因为当所有格子都被感染后，图形的周长为4n，因此初始时至少要有n个被感染的格 子。</p><h4 id="No-7"><a class="header-anchor" href="#No-7">¶</a>No.7</h4><p>在一个m*n的棋盘上，有k个格子里放有棋子。是否总能对所有棋子进行红蓝二染色，使得每行每列的红色棋子和蓝色棋子最多差一个？</p><p>**答案：**可以。建一个二分图G(X,Y)，其中X有m个顶点代表了棋盘的m个行，Y有n个顶点代表了棋盘的n个列。第i行第j列有棋子就在X(i) 和Y(j)之间连一条边。先找出图G里的所有环（由于是二分图，环的长度一定是偶数），把环里的边红蓝交替染色。剩下的没染色的图一定是一些树。对每棵树 递归地进行操作：去掉一个叶子节点和对应边，把剩下的树进行合法的红蓝二染色，再把刚才去掉的顶点和边加回去，给这个边适当的颜色以满足要求。</p><h4 id="No-8"><a class="header-anchor" href="#No-8">¶</a>No.8</h4><p>任意给一个8<em>8的01矩阵，你每次只能选一个3</em>3或者4*4的子矩阵并把里面的元素全部取反。是否总有办法把矩阵里的所有数全部变为1？</p><p>**答案：**不能。大矩阵中有36个3<em>3的小矩阵和25个4</em>4的小矩阵，因此总共有61种可能的操作。显然，给定一个操作序列，这些操作的先后顺序 是无关紧要的；另外，在一个操作序列中使用两种或两种以上相同的操作也是无用的。因此，实质不同的操作序列只有2^61种。但8*8的01矩阵一共有 2^64种，因此不是每种情况都有办法达到目的。</p><h4 id="No-9"><a class="header-anchor" href="#No-9">¶</a>No.9</h4><p>五个洞排成一排，其中一个洞里藏有一只狐狸。每个夜晚，狐狸都会跳到一个相邻的洞里；每个白天，你都只允许检查其中一个洞。怎样才能保证狐狸最终会被抓住？</p><p>**答案：**按照2, 3, 4, 2, 3, 4的顺序检查狐狸洞可以保证抓住狐狸。为了说明这个方案是可行的，用集合F表示狐狸可能出现的位置，初始时F = {1, 2, 3, 4, 5}。如果它不在2号洞，则第二天狐狸已经跑到了F = {2, 3, 4, 5}。如果此时它不在3号洞，则第三天狐狸一定跑到了F = {1, 3, 4, 5}。如果此时它不在4号洞，则再过一晚后F = {2, 4}。如果此时它不在2号洞，则再过一天F = {3, 5}。如果此时它不在3号洞，再过一天它就一定跑到4号洞了。</p><p>方案不是唯一的，下面这些方案都是可行的：</p><p>2, 3, 4, 4, 3, 2<br>4, 3, 2, 2, 3, 4<br>4, 3, 2, 4, 3, 2</p><h4 id="No-10"><a class="header-anchor" href="#No-10">¶</a>No.10</h4><p>一个经典老题是说，把一个3<em>3</em>3的立方体切成27个单位立方体，若每一刀切完后都允许重新摆放各个小块的位置，最少可以用几刀？答案仍然是6刀，因为 正中间那个单位立方体的6个面都是后来才切出来的，因此怎么也需要6刀。考虑这个问题：若把一个n<em>n</em>n的立方体切成一个个单位立方体，最少需要几刀？</p><p>**答案：**事实上，从一个更强的命题出发反而能使问题变得更简单。对于一个a<em>b</em>c的长方体，我们需要f(a)+f(b)+f©刀，其中 f(x)=⌈log(x)/log(2)⌉。只需要注意到，在整个过程中的任何一步，切完当前最大的块所需要的刀数也就等于整个过程还需要的刀数，因为其 它小块需要的刀数都不会超过最大块所需刀数，它们都可以与最大块一道并行处理。这表明，我们的最优决策即是让当前的最大块尽可能的小，也就是说要把当前的 最大块尽可能相等地切成两半。利用数学归纳法，我们可以很快得到本段开头的结论。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h4 id=&quot;No-1&quot;&gt;&lt;a class=&quot;header-anchor&quot; href=&quot;#No-1&quot;&gt;¶&lt;/a&gt;No.1&lt;/h4&gt;
&lt;p&gt;给一个瞎子52张扑克牌，并告诉他里面恰好有10张牌是正面朝上的。要求这个瞎子把牌分成两堆，使得每堆牌里正面朝上的牌的张数一样多。瞎子应该怎么</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>等待通知机制</title>
    <link href="https://gyl-coder.top/concurrency/waiting_for_notification/"/>
    <id>https://gyl-coder.top/concurrency/waiting_for_notification/</id>
    <published>2019-11-05T16:00:00.000Z</published>
    <updated>2020-09-28T14:52:37.634Z</updated>
    
    <content type="html"><![CDATA[<p>多线程环境中，经常出现这样一种场景。一个线程修改了一个对象的值，而另一个线程感知到了变化，然后进行相应的操作，整个过程开始于一个线程，最终结束于另一个线程。这就是传说中的生产者/消费者模型（前者是生产者，后者是消费者）。</p><p>而实现这种功能比较简单的方法就是让消费者线程不断的循环变量判断是否符合预期。如下所示</p><pre><code class="language-java">while (!isOK(...))&amp;#123;Thread.sleep(1000);&amp;#125;doIt();</code></pre><p>while 循环中设置不满足的条件，如果条件满足则退出循环（睡眠可以防止过快的“无效尝试”）</p><p>如果isOK方法的判断逻辑比较简单，操作耗时较短，而且并发冲突量不大的情况下，使用这种方案也未尝不可。但是如果判断逻辑比较复杂，或者并发冲突较大时。这种方案就不行了，while循环会执行很多很多次，CPU消耗较大。</p><p>针对这种问题，Java内置的<code>等待通知机制</code>能够较好的解决。当条件不满足时，线程阻塞自己，进入等待状态。当线程条件满足时，通知等待的线程重新执行。线程阻塞避免了循环等待带来的CPU消耗问题。</p><a id="more"></a><h2 id="就诊流程"><a class="header-anchor" href="#就诊流程">¶</a>就诊流程</h2><p>这里借用极客时间中<a href="https://time.geekbang.org/column/article/98923e784b3bd3957bae96f39c2ad28c/share?code=qM3%2Fe3xQXVhoZX1Ey1Edz9S8e4pFJgBCiihOxtiS5S0%3D">大佬文章</a>（文末有链接，名额十个，先到先得）中的一个例子来更好的理解一下等待通知机制。</p><p>我们去医院看病，一般都会经历以下流程：</p><ol><li>患者先去挂号，然后到就诊门口分诊，等待叫号。</li><li>当叫到自己的号时，患者就可以去找大夫了。</li><li>就诊过程中，大夫可能会让患者去做一些辅助检查，同时叫下一位患者。</li><li>当患者做完检查之后，拿到检测报告重新分诊，等待叫号。</li><li>当大夫在此叫到自己的号时，患者再去找大夫就诊。</li></ol><p>第一/二步中，患者去挂号分诊类似于线程去过去互斥锁的过程，当患者会叫到号时类似于拿到了锁</p><p>大夫让患者去做检查的操作类似于，线程没有满足条件。</p><p>患者去做检查类似于线程进入等待状态，然后大夫叫下一个患者，这个步骤我们在前面的<code>等待 - 通知机制</code>中忽略掉了，这个步骤对应到程序里，本质是线程释放持有的互斥锁。</p><p>患者做完检查，类似于线程要求的条件已经满足；患者拿检测报告重新分诊，类似于线程需要重新获取互斥锁，这个步骤我们在前面的等待 - 通知机制中也忽视了。</p><p>由此可以总结出：一个完整的等待 - 通知机制：线程首先获取互斥锁，当线程要求的条件不满足时，释放互斥锁，进入等待状态；当要求的条件满足时，通知等待的线程，重新获取互斥锁。</p><h2 id="用Synchronized实现等待通知机制"><a class="header-anchor" href="#用Synchronized实现等待通知机制">¶</a>用Synchronized实现等待通知机制</h2><p>通过synchronized配合wait(), notifyAll(), notify()方法来实现等待通知机制。</p><pre><code class="language-java">// 调用该方法的线程进入WAITING状态，只有等待另外线程的通知或被中断才返回，调用wait方法会释放锁wait();// 通知一个在对象上等待的线程从wait()方法返回，返回的前提是该线程获取到对象锁notify();// 通知所有等待在该对象上的线程notifyAll();</code></pre><p>下面通过一个具体实例来具体实现以下</p><pre><code class="language-java">public class WaitNotify &amp;#123;    static boolean flag = true;        static Object lock = new Object();            public static void main(String[] args) throws Exception &amp;#123;    new Thread(new Wait(), &quot;WaitThread&quot;).start();        Thread.sleep(1000);           new Thread(new Notify(), &quot;NotifyThread&quot;).start();        &amp;#125;        // 等待    static class Wait implements Runnable &amp;#123;            public void run() &amp;#123;                // 加锁，拥有lock的Monitor                synchronized (lock) &amp;#123;                   // 当条件不满足时，继续wait，同时释放了lock的锁                   while (flag) &amp;#123;                       try &amp;#123;                            System.out.println(Thread.currentThread().getName() + &quot; flag is true. wait &quot;);                           lock.wait();                        &amp;#125; catch (InterruptedException e) &amp;#123; &amp;#125;                    &amp;#125;                   // 条件满足时，完成工作    System.out.println(Thread.currentThread().getName() + &quot; flag is false. running &quot;);                &amp;#125;            &amp;#125;        &amp;#125;        // 通知    static class Notify implements Runnable &amp;#123;            public void run() &amp;#123;                // 加锁，拥有lock的Monitor                synchronized (lock) &amp;#123;                    // 获取lock的锁，然后进行通知，通知时不会释放lock的锁，                   // 直到当前线程释放了lock后，WaitThread才能从wait方法中返回                    System.out.println(Thread.currentThread().getName() + &quot; hold lock. notify &quot;);                    lock.notifyAll();                    flag = false;     try &amp;#123;Thread.sleep(2000);&amp;#125; catch (InterruptedException e) &amp;#123;e.printStackTrace();&amp;#125;     &amp;#125;        // 再次加锁                synchronized (lock) &amp;#123;                    System.out.println(Thread.currentThread().getName() + &quot; hold lock again. sleep &quot;);                    try &amp;#123;Thread.sleep(2000);&amp;#125; catch (InterruptedException e) &amp;#123;e.printStackTrace();&amp;#125;               &amp;#125;            &amp;#125;        &amp;#125;&amp;#125;</code></pre><p>在上面的实例中，等待线程(WaitThread)首先获得了对象锁，然后调用对象的wait()方法，从而放弃了锁，并进入对象的等待队列中，进入等待状态。由于等待线程释放了对象锁，通知线程(NotifyThread)随后获取了对象的锁，改变状态使满足条件，并调用对象的notify()方法，通知等待队列（互斥锁的等待队列）中的线程，告诉它条件曾经满足过。（这里notify()只能保证在通知时间点，条件是满足的。而被通知线程的执行时间点和通知时间点基本上不会重合，所以当线程执行的时候，很可能线程条件已经不满足了）等待线程从等待队列中移出，状态变为阻塞状态。通知线程释放锁之后，等待线程再次获取锁从wait()方法返回继续执行。</p><p>这个过程需要注意以下几点：</p><ol><li>使用wait(), notify(), notifyAll()时需要先对调用对象加锁。</li><li>调用wait()方法后，线程状态有RUNNING变为WAITING，并将当前线程放置到对象的等待队列</li><li>notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，需要调用notify()或 notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。</li><li>从wait()方法返回的前提是获得了调用对象的锁。</li></ol><h2 id="等待超时模式"><a class="header-anchor" href="#等待超时模式">¶</a>等待超时模式</h2><p>在开发的过程中经常会遇到这样的情况，调用一个方法时等待一段时间（一般来说是给<br>定一个时间段），如果该方法能够在给定的时间段之内得到结果，那么将结果立刻返回，反之，<br>超时返回默认结果或自定义处理。</p><p>而要在等待/通知模型中要加入超市等待逻辑，只需要做一些小小的改动。</p><p>假设超时时间段是T，那么可以推断出在当前时间now+T之后就会超时。</p><p>定义如下变量：</p><ul><li>等待持续时间：REMAINING=T。</li><li>超时时间：FUTURE=now+T。</li></ul><p>这时仅需要wait(REMAINING)即可，在wait(REMAINING)返回之后会将执行： REMAINING=FUTURE–now。如果REMAINING小于等于0，表示已经超时，直接退出，否则将 继续执行wait(REMAINING)。</p><p>相关实现如下</p><pre><code class="language-java">// 对当前对象加锁 public synchronized Object get(long mills) throws InterruptedException &amp;#123;       long future = System.currentTimeMillis() + mills;       long remaining = mills;       // 当超时大于0并且result返回值不满足要求       while ((result == null) &amp;&amp; remaining &gt; 0) &amp;#123;              wait(remaining);        remaining = future - System.currentTimeMillis();           &amp;#125;                  return result; &amp;#125;</code></pre><h2 id="一个简单的数据库连接池示例"><a class="header-anchor" href="#一个简单的数据库连接池示例">¶</a>一个简单的数据库连接池示例</h2><p>我们使用等待超时模式来构造一个简单的数据库连接池，在示例中模拟从连接池中获取、使用和释放连接的过程，而客户端获取连接的过程被设定为等待超时的模式，也就是在1000毫秒内如果无法获取到可用连接，将会返回给客户端一个null。设定连接池的大小为10个，然后通过调节客户端的线程数来模拟无法获取连接的场景。</p><p>首先看一下连接池的定义。它通过构造函数初始化连接的最大上限，通过一个双向队列来维护连接，调用方需要先调用fetchConnection(long)方法来指定在多少毫秒内超时获取连接，当连接使用完成后，需要调用releaseConnection(Connection)方法将连接放回线程池。</p><pre><code class="language-java">import java.sql.Connection;import java.util.LinkedList;public class ConnectionPool &amp;#123;    private LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    public ConnectionPool(int initialSize) &amp;#123;        if (initialSize &gt; 0) &amp;#123;            for (int i = 0; i &lt; initialSize; i++) &amp;#123;                pool.addLast(ConnectionDriver.createConnection()); &amp;#125;       &amp;#125;    &amp;#125;    public void releaseConnection(Connection connection) &amp;#123;        if (connection != null) &amp;#123;            synchronized (pool) &amp;#123;                // 连接释放后需要进行通知，这样其他消费者能够感知到连接池中已经归还了一个连接                pool.addLast(connection);                pool.notifyAll();            &amp;#125;        &amp;#125;    &amp;#125;    // 在mills内无法获取到连接，将会返回null    public Connection fetchConnection(long mills) throws InterruptedException &amp;#123;  synchronized (pool) &amp;#123;            // 完全超时            if (mills &lt;= 0) &amp;#123;                while (pool.isEmpty()) &amp;#123;                    pool.wait();                &amp;#125;                return pool.removeFirst();            &amp;#125; else &amp;#123;// 超过设置的时间mills，将推出while循环long future = System.currentTimeMillis() + mills;                long remaining = mills;                while (pool.isEmpty() &amp;&amp; remaining &gt; 0) &amp;#123;                    pool.wait(remaining);                    remaining = future - System.currentTimeMillis();                &amp;#125;  Connection result = null;                if (!pool.isEmpty()) &amp;#123;                    result = pool.removeFirst();                &amp;#125;                return result;            &amp;#125;        &amp;#125;    &amp;#125; &amp;#125;</code></pre><p>由于java.sql.Connection是一个接口，最终的实现是由数据库驱动提供方来实现的，考虑到只是个示例，我们通过动态代理构造了一个Connection，该Connection的代理实现仅仅是在commit()方法调用时休眠100毫秒.</p><pre><code class="language-java">import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.sql.Connection;import java.util.concurrent.TimeUnit;public class ConnectionDriver &amp;#123;   static class ConnectionHandler implements InvocationHandler &amp;#123;     // commit时会回调public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123;       if (method.getName().equals(&quot;commit&quot;)) &amp;#123;                TimeUnit.MILLISECONDS.sleep(100);            &amp;#125;            return null;        &amp;#125;    &amp;#125;    // 创建一个Connection的代理，在commit时休眠100毫秒    public static final Connection createConnection() &amp;#123;        return (Connection) Proxy.newProxyInstance(ConnectionDriver.class.getClassLoader(),  new Class[] &amp;#123; Connection.class &amp;#125;, new ConnectionHandler());    &amp;#125; &amp;#125;</code></pre><p>下面通过一个示例来测试简易数据库连接池的工作情况，模拟客户端ConnectionRunner获取、使用、最后释放连接的过程，当它使用时连接将会增加获取到连接的数量，反之，将会增加未获取到连接的数量。</p><pre><code class="language-java">import java.sql.Connection;import java.util.concurrent.CountDownLatch;import java.util.concurrent.atomic.AtomicInteger;public class Main &amp;#123;static ConnectionPool pool = new ConnectionPool(10);// 保证所有CountDownLatch能够同时开始static CountDownLatch start = new CountDownLatch(1);// 保证main线程等待所有ConnectionRunner结束之后才继续执行static CountDownLatch end;public static void main(String[] args) throws InterruptedException &amp;#123;// 线程数量，可以修改线程数量进行观察       int threadCount = 10;        end = new CountDownLatch(threadCount);        int count = 20;    // 成功的个数AtomicInteger got = new AtomicInteger();   // 失败的个数AtomicInteger notGot = new AtomicInteger();        for (int i = 0; i &lt; threadCount; i++) &amp;#123;            Thread thread = new Thread(new ConnetionRunner(count, got, notGot),&quot;ConnectionRunnerThread&quot;);            thread.start();        &amp;#125;      start.countDown();        end.await();    System.out.println(&quot;total invoke: &quot; + (threadCount * count));   System.out.println(&quot;got connection:  &quot; + got);    System.out.println(&quot;not got connection &quot; + notGot); &amp;#125;static class ConnetionRunner implements Runnable &amp;#123;        int count;        AtomicInteger got;        AtomicInteger notGot;        public ConnetionRunner(int count, AtomicInteger got, AtomicInteger notGot) &amp;#123;            this.count = count;            this.got = got;            this.notGot = notGot;        &amp;#125;        @Overridepublic void run() &amp;#123;            try &amp;#123;                start.await();            &amp;#125; catch (Exception ex) &amp;#123;&amp;#125;   while (count &gt; 0) &amp;#123;                try &amp;#123;                    // 从线程池中获取连接，如果1000ms内无法获取到，将会返回null                    // 分别统计连接获取的数量got和未获取到的数量notGot                    Connection connection = pool.fetchConnection(1000);                    if (connection != null) &amp;#123;                        try &amp;#123;                            connection.createStatement();                            connection.commit();                        &amp;#125; finally &amp;#123;                            pool.releaseConnection(connection);  // 成功个数+1got.incrementAndGet();                        &amp;#125;                    &amp;#125; else &amp;#123;  // 失败个数+1notGot.incrementAndGet();                    &amp;#125;                &amp;#125; catch (Exception ex) &amp;#123;                &amp;#125; finally &amp;#123;                count--;                &amp;#125;&amp;#125;            end.countDown();        &amp;#125;    &amp;#125; &amp;#125;</code></pre><p>上述示例中使用了CountDownLatch来确保ConnectionRunnerThread能够同时开始执行，并且在全部结束之后，才使main线程从等待状态中返回。</p><p>当前设定的场景是10个线程同时运行获取连接池（10个连接）中的连接，可以通过调节线程数量来观察未获取到连接的情况。线程数、总获取次数、获取到的数量、未获取到的数量以及未获取到的比率。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;多线程环境中，经常出现这样一种场景。一个线程修改了一个对象的值，而另一个线程感知到了变化，然后进行相应的操作，整个过程开始于一个线程，最终结束于另一个线程。这就是传说中的生产者/消费者模型（前者是生产者，后者是消费者）。&lt;/p&gt;
&lt;p&gt;而实现这种功能比较简单的方法就是让消费者线程不断的循环变量判断是否符合预期。如下所示&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;while (!isOK(...))&amp;amp;#123;
	Thread.sleep(1000);
&amp;amp;#125;
doIt();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;while 循环中设置不满足的条件，如果条件满足则退出循环（睡眠可以防止过快的“无效尝试”）&lt;/p&gt;
&lt;p&gt;如果isOK方法的判断逻辑比较简单，操作耗时较短，而且并发冲突量不大的情况下，使用这种方案也未尝不可。但是如果判断逻辑比较复杂，或者并发冲突较大时。这种方案就不行了，while循环会执行很多很多次，CPU消耗较大。&lt;/p&gt;
&lt;p&gt;针对这种问题，Java内置的&lt;code&gt;等待通知机制&lt;/code&gt;能够较好的解决。当条件不满足时，线程阻塞自己，进入等待状态。当线程条件满足时，通知等待的线程重新执行。线程阻塞避免了循环等待带来的CPU消耗问题。&lt;/p&gt;</summary>
    
    
    
    <category term="并发" scheme="https://gyl-coder.top/categories/%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="并发" scheme="https://gyl-coder.top/tags/%E5%B9%B6%E5%8F%91/"/>
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="等待通知机制" scheme="https://gyl-coder.top/tags/%E7%AD%89%E5%BE%85%E9%80%9A%E7%9F%A5%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>多个线程交替打印内容</title>
    <link href="https://gyl-coder.top/concurrency/alternate_printing/"/>
    <id>https://gyl-coder.top/concurrency/alternate_printing/</id>
    <published>2019-11-04T16:00:00.000Z</published>
    <updated>2020-09-28T14:52:28.379Z</updated>
    
    <content type="html"><![CDATA[<p><strong>需求：</strong> 启动两个线程，交替打印奇偶数。 效果如下所示</p><pre><code class="language-java">偶数线程：0奇数线程：1偶数线程：2...</code></pre><a id="more"></a><h2 id="两个线程交替打印"><a class="header-anchor" href="#两个线程交替打印">¶</a>两个线程交替打印</h2><h3 id="无锁实现"><a class="header-anchor" href="#无锁实现">¶</a>无锁实现</h3><p>不需要进行任何加锁，利用并发包中的AtomicInteger和volidate修饰符组合进行实现。</p><pre><code class="language-java">public class Thread_demo1 &amp;#123;    private static volatile Boolean flag = true;    private static AtomicInteger num = new AtomicInteger();    public static CountDownLatch latch = new CountDownLatch(2);    public static void main(String[] args) throws InterruptedException &amp;#123;        long start =  System.currentTimeMillis();        Thread thread1 = new Thread(new Runnable() &amp;#123;            @Override            public void run() &amp;#123;                while(num.get() &lt;= 10000)&amp;#123;                    if(!flag)&amp;#123;                        System.out.println(Thread.currentThread().getName()+&quot;: &quot; + num.getAndIncrement());                        flag = true;                    &amp;#125;                &amp;#125;                latch.countDown();            &amp;#125;        &amp;#125;, &quot;奇数线程&quot;);        Thread thread2 = new Thread(new Runnable() &amp;#123;            @Override            public void run() &amp;#123;                while(num.get() &lt;= 10000)&amp;#123;                    if(flag)&amp;#123;                        System.out.println(Thread.currentThread().getName()+ &quot;：&quot; + num.getAndIncrement());                        flag = false;                    &amp;#125;                &amp;#125;                latch.countDown();            &amp;#125;        &amp;#125;, &quot;偶数线程&quot;);        thread1.start();        thread2.start();        latch.await();        System.out.println(&quot;共耗时：&quot;+(System.currentTimeMillis() - start) + &quot;ms&quot;);    &amp;#125;&amp;#125;</code></pre><h3 id="加锁实现A"><a class="header-anchor" href="#加锁实现A">¶</a>加锁实现A</h3><p>通过一个boolean类型的变量来限制两个线程，分别只输出奇数和偶数。</p><pre><code class="language-java">public class Thread_demo2 &amp;#123;    private int count = 0;    private final Object lock = new Object();    public static CountDownLatch latch = new CountDownLatch(2);    public void go() throws InterruptedException &amp;#123;        long start = System.currentTimeMillis();        Thread thread1 = new Thread(() -&gt; &amp;#123;            while (count &lt; 10000) &amp;#123;                synchronized (lock) &amp;#123;                    if ((count &amp; 1) == 0) &amp;#123;                        System.out.println(Thread.currentThread().getName() + &quot;: &quot; + count ++);                    &amp;#125;                &amp;#125;            &amp;#125;            latch.countDown();        &amp;#125;, &quot;偶数线程&quot;);        Thread thread2 = new Thread(() -&gt; &amp;#123;            while (count &lt; 10000) &amp;#123;                synchronized (lock) &amp;#123;                    if ((count &amp; 1) == 1) &amp;#123;                        System.out.println(Thread.currentThread().getName() + &quot;: &quot; + count ++);                    &amp;#125;                &amp;#125;            &amp;#125;            latch.countDown();        &amp;#125;, &quot;奇数线程&quot;);        thread1.start();        thread2.start();        latch.await();        System.out.println(&quot;共耗时：&quot;+(System.currentTimeMillis() - start) + &quot;ms&quot;);    &amp;#125;    public static void main(String[] args) throws InterruptedException &amp;#123;        Thread_demo2 threaddemo2 = new Thread_demo2();        threaddemo2.go();    &amp;#125;&amp;#125;</code></pre><h3 id="加锁实现B"><a class="header-anchor" href="#加锁实现B">¶</a>加锁实现B</h3><p>通过同一个对象锁来实现。</p><pre><code class="language-java">public class Thread_demo3 &amp;#123;    private int count = 0;    private final Object lock = new Object();    public static CountDownLatch latch = new CountDownLatch(2);    public void go() throws InterruptedException &amp;#123;        long begin = System.currentTimeMillis();        new Thread(new RunnerTest(), &quot;偶数线程&quot;).start();        // 确保偶数线程线先获取到锁        Thread.sleep(1);        new Thread(new RunnerTest(), &quot;奇数线程&quot;).start();        latch.await();        System.out.println(System.currentTimeMillis() - begin);    &amp;#125;    class RunnerTest implements Runnable &amp;#123;        @Override        public void run() &amp;#123;            while (count &lt; 10000) &amp;#123;                synchronized (lock) &amp;#123;                    // 拿到锁就打印                    System.out.println(Thread.currentThread().getName() + &quot;: &quot; + count ++);                    // 唤醒其他线程                    lock.notifyAll();                    try &amp;#123;                        if (count &lt; 10000) &amp;#123;                            // 如果任务还没有结束，则让出当前的锁并休眠                            lock.wait();                        &amp;#125;                    &amp;#125; catch (InterruptedException e) &amp;#123;                        e.printStackTrace();                    &amp;#125;                &amp;#125;            &amp;#125;            latch.countDown();        &amp;#125;    &amp;#125;    public static void main(String[] args) throws InterruptedException &amp;#123;        Thread_demo3 threaddemo3 = new Thread_demo3();        threaddemo3.go();    &amp;#125;&amp;#125;</code></pre><h2 id="多个线程交替打印"><a class="header-anchor" href="#多个线程交替打印">¶</a>多个线程交替打印</h2><p><strong>需求：</strong> n个线程，交替打印数字。 效果如下所示</p><pre><code class="language-java">线程1：0线程2：1线程3：2线程1：3线程2：4线程3：5线程1：6...</code></pre><pre><code class="language-java">public class Demo implements Runnable &amp;#123;private static final Object LOCK = new Object();    /**     * 当前即将打印的数字     */    private static int current = 0;    /**     * 当前线程编号，从0开始     */    private int threadNo;    /**     * 线程数量     */    private int threadCount;    /**     * 打印的最大数值     */    private int maxInt;    public Demo(int threadNo, int threadCount, int maxInt) &amp;#123;        this.threadNo = threadNo;        this.threadCount = threadCount;        this.maxInt = maxInt;    &amp;#125;    @Override    public void run() &amp;#123;        while (true) &amp;#123;            synchronized (LOCK) &amp;#123;                // 判断是否轮到当前线程执行                while (current % threadCount != threadNo) &amp;#123;                    if (current &gt; maxInt) &amp;#123;                        break;                    &amp;#125;                    try &amp;#123;                        // 如果不是，则当前线程进入wait                        LOCK.wait();                    &amp;#125; catch (Exception e) &amp;#123;                        e.printStackTrace();                    &amp;#125;                &amp;#125;                // 最大值跳出循环                if (current &gt; maxInt) &amp;#123;                    break;                &amp;#125;                System.out.println(&quot;thread&quot; + threadNo + &quot; : &quot; + current);                current++;                // 唤醒其他wait线程                LOCK.notifyAll();            &amp;#125;        &amp;#125;    &amp;#125;    public static void main(String[] args) &amp;#123;        int threadCount = 3;        int max = 100;        for (int i = 0; i &lt; threadCount; i++) &amp;#123;            new Thread(new Demo(i, threadCount, max)).start();        &amp;#125;    &amp;#125;&amp;#125;</code></pre><p>可以看到，核心思想都是差不多的。都用的是<code>等待通知</code>机制。</p><p>这里我们需要注意一个问题。当threadCount（线程数量）比较大的时候，在执行notifyAll唤醒其他线程的时候，可能会出现线程抢到了锁但并不该自己执行，然后又进入wait的情况。比如现在有100个线程，现在是第一个线程在执行，他执行完之后需要第二个线程执行，但是第100个线程抢到了，发现不是自己然后又进入wait，然后第99个线程抢到了，发现不是自己然后又进入wait，然后第98,97…直到第3个线程都抢到了，最后才到第二个线程抢到同步锁，这里就会白白的多执行很多过程，虽然最后能完成目标。</p><p>解决办法多种多样，这里介绍一种基于<code>信号量</code>的实现方式。</p><pre><code class="language-java">public class Main &amp;#123;static int result = 0;    public static void main(String[] args) throws InterruptedException &amp;#123;        int N = 3;        Thread[] threads = new Thread[N];        final Semaphore[] syncObjects = new Semaphore[N];        for (int i = 0; i &lt; N; i++) &amp;#123;            syncObjects[i] = new Semaphore(1);            if (i != N-1)&amp;#123;                syncObjects[i].acquire();            &amp;#125;        &amp;#125;        for (int i = 0; i &lt; N; i++) &amp;#123;            final Semaphore lastSemphore = i == 0 ? syncObjects[N - 1] : syncObjects[i - 1];            final Semaphore curSemphore = syncObjects[i];            final int index = i;            threads[i] = new Thread(new Runnable() &amp;#123;                public void run() &amp;#123;                    try &amp;#123;                        while (true) &amp;#123;                        // 第一次执行时，由于最后一个信号量并没有执行acquire，所以这里不会阻塞                            lastSemphore.acquire();                            System.out.println(&quot;thread&quot; + index + &quot;: &quot; + result++);                            if (result &gt; 100)&amp;#123;                                System.exit(0);                            &amp;#125;                            // 释放下一个要执行的线程的                            curSemphore.release();                        &amp;#125;                    &amp;#125; catch (Exception e) &amp;#123;                        e.printStackTrace();                    &amp;#125;                &amp;#125;            &amp;#125;);            threads[i].start();        &amp;#125;    &amp;#125;&amp;#125;</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;需求：&lt;/strong&gt; 启动两个线程，交替打印奇偶数。 效果如下所示&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;偶数线程：0
奇数线程：1
偶数线程：2
...
&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="并发" scheme="https://gyl-coder.top/categories/%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="并发" scheme="https://gyl-coder.top/tags/%E5%B9%B6%E5%8F%91/"/>
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Lock &amp; Synchronized</title>
    <link href="https://gyl-coder.top/concurrency/lock_and_synchronized/"/>
    <id>https://gyl-coder.top/concurrency/lock_and_synchronized/</id>
    <published>2019-11-04T16:00:00.000Z</published>
    <updated>2020-09-28T14:52:32.162Z</updated>
    
    <content type="html"><![CDATA[<p>首先我们来考虑一个问题？</p><p>在Lock出现之前我们一直使用synchronized来实现同步访问。那为什么还要提供lock呢？</p><p>我们知道如果一个代码块被synchronized修饰了，当有一个线程获取了对应的锁，并执行该代码快时，其他线程就只能在一旁等待。</p><p>而获取锁的线程只有在<code>线程正常执行完该代码</code>或者<code>线程执行过程中发生异常</code>才会释放对锁的占有。</p><p>在synchronized这种机制下，程序就有可能出现如下问题：</p><ol><li>获取锁的线程由于要等待IO或其他原因被阻塞住了，但是又没有释放锁，其他线程只能等待。影响效率</li><li>相互没有冲突的多个线程不能并发执行</li><li>解决死锁的一个方案是<code>破坏不可抢占条件</code>synchronized 没有办法解决。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。</li></ol><p>正是由于这些因素的限制，需要开发出一种满足如下条件的同步机制。</p><ol><li>**能够响应中断。**synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A。</li><li>**支持超时。**如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。</li><li>**非阻塞地获取锁。**如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。</li></ol><a id="more"></a><h2 id="Lock"><a class="header-anchor" href="#Lock">¶</a>Lock</h2><p>下面我们看下lock接口的API</p><pre><code class="language-java">// 支持中断的 APIvoid lockInterruptibly()   throws InterruptedException;// 支持超时的 APIboolean tryLock(long time, TimeUnit unit)   throws InterruptedException;// 支持非阻塞获取锁的 APIboolean tryLock();void lock();void unlock();Condition newCondition();</code></pre><p>Java SDK 里面 Lock 的使用，有一个经典的范例，就是try{}finally{}，需要重点关注的是在 finally 里面释放锁。下面我们具体看下上面那几个方法的使用。</p><p>**lcok()**方法是平时比较常用的一个方法，用来获取锁。如果锁被其他线程获取，则进行等待。</p><p>由于在前面讲到如果采用Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一般来说，使用Lock必须在try{}catch{}块中进行，并且将释放锁的操作放在finally块中进行，以保证锁一定被被释放，防止死锁的发生。通常使用Lock来进行同步的话，是以下面这种形式去使用的：</p><pre><code class="language-java">Lock lock = ...;lock.lock();try&amp;#123;    //处理任务&amp;#125;catch(Exception e)&amp;#123;     &amp;#125;finally&amp;#123;    lock.unlock();   //释放锁&amp;#125;</code></pre><p>tryLock()方法是有返回值的，它表示用来尝试获取锁，如果获取成功，则返回true，如果获取失败（即锁已被其他线程获取），则返回false，也就说这个方法无论如何都会立即返回。在拿不到锁时不会一直在那等待。</p><p>tryLock(long time, TimeUnit unit)方法和tryLock()方法是类似的，只不过区别在于这个方法在拿不到锁时会等待一定的时间，在时间期限之内如果还拿不到锁，就返回false。如果如果一开始拿到锁或者在等待期间内拿到了锁，则返回true。</p><p>所以，一般情况下通过tryLock来获取锁时是这样使用的：</p><pre><code class="language-java">Lock lock = ...;if(lock.tryLock()) &amp;#123;     try&amp;#123;         //处理任务     &amp;#125;catch(Exception ex)&amp;#123;              &amp;#125;finally&amp;#123;         lock.unlock();   //释放锁     &amp;#125; &amp;#125;else &amp;#123;    //如果不能获取锁，则直接做其他事情&amp;#125;</code></pre><p>lockInterruptibly()方法比较特殊，当通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。也就使说，当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有在等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。</p><p>由于lockInterruptibly()的声明中抛出了异常，所以lock.lockInterruptibly()必须放在try块中或者在调用lockInterruptibly()的方法外声明抛出InterruptedException。</p><p>因此lockInterruptibly()一般的使用形式如下：</p><pre><code class="language-java">public void method() throws InterruptedException &amp;#123;    lock.lockInterruptibly();    try &amp;#123;       //.....    &amp;#125;    finally &amp;#123;        lock.unlock();    &amp;#125;  &amp;#125;</code></pre><p>注意，当一个线程获取了锁之后，是不会被interrupt()方法中断的。因为本身在前面的文章中讲过单独调用interrupt()方法不能中断正在运行过程中的线程，只能中断阻塞过程中的线程。</p><p>因此当通过lockInterruptibly()方法获取某个锁时，如果不能获取到，只有进行等待的情况下，是可以响应中断的。</p><p>而用synchronized修饰的话，当一个线程处于等待某个锁的状态，是无法被中断的，只有一直等待下去。</p><h2 id="Lock如果保证可见性"><a class="header-anchor" href="#Lock如果保证可见性">¶</a>Lock如果保证可见性</h2><p>synchronized 之所以能够保证可见性，也是因为有一条synchronized 相关的规则：synchronized 的解锁 Happens-Before 于后续对这个锁的加锁。那 Lock 靠什么保证可见性呢？例如在下面的代码中，线程 T1 对 value 进行了 +=1 操作，那后续的线程 T2 能够看到 value 的正确结果吗？</p><pre><code class="language-java">class X &amp;#123;  private final Lock rtl =  new ReentrantLock();  int value;  public void addOne() &amp;#123;    // 获取锁    rtl.lock();      try &amp;#123;      value+=1;    &amp;#125; finally &amp;#123;      // 保证锁能释放      rtl.unlock();    &amp;#125;  &amp;#125;&amp;#125;</code></pre><p>Lock利用volatile相关的Happens-Before规则来保证可见性。</p><p>Java SDK 里面的 ReentrantLock，内部持有一个volatile的成员变量state，获取锁的时候，会读写state的值；解锁的时候也会读写state的值。也就是说，在执行 value+=1 之前，程序先读写了一次 volatile变量state，在执行value+=1之后，又读写一次olatile变量state。相关的Happens-Before规则如下：</p><ul><li>顺序性规则：对于线程 T1，value+=1 Happens-Before释放锁的操作unlock（）；</li><li>volatile 变量规则：由于 state = 1 会先读取 state，所以线程 T1 的 unlock() 操作 Happens-Before 线程 T2 的 lock() 操作；</li><li>传递性规则：线程 T1 的 value+=1 Happen-Before线程T2的lock（）操作。</li></ul><pre><code class="language-java">class SampleLock &amp;#123;  volatile int state;  // 加锁  lock() &amp;#123;    // 省略代码无数    state = 1;  &amp;#125;  // 解锁  unlock() &amp;#123;    // 省略代码无数    state = 0;  &amp;#125;&amp;#125;</code></pre><p>总结来说，Lock和synchronized有以下几点不同：</p><p>1）Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；</p><p>2）synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；</p><p>3）Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；</p><p>4）通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。</p><p>5）Lock可以提高多个线程进行读操作的效率。</p><p>在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源非常激烈时（即有大量线程同时竞争），此时Lock的性能要远远优于synchronized。所以说，在具体使用时要根据适当情况选择。</p><p>Happens-Before相关规则介绍可看下<code>王宝令</code>大神的Java并发课程</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;首先我们来考虑一个问题？&lt;/p&gt;
&lt;p&gt;在Lock出现之前我们一直使用synchronized来实现同步访问。那为什么还要提供lock呢？&lt;/p&gt;
&lt;p&gt;我们知道如果一个代码块被synchronized修饰了，当有一个线程获取了对应的锁，并执行该代码快时，其他线程就只能在一旁等待。&lt;/p&gt;
&lt;p&gt;而获取锁的线程只有在&lt;code&gt;线程正常执行完该代码&lt;/code&gt;或者&lt;code&gt;线程执行过程中发生异常&lt;/code&gt;才会释放对锁的占有。&lt;/p&gt;
&lt;p&gt;在synchronized这种机制下，程序就有可能出现如下问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;获取锁的线程由于要等待IO或其他原因被阻塞住了，但是又没有释放锁，其他线程只能等待。影响效率&lt;/li&gt;
&lt;li&gt;相互没有冲突的多个线程不能并发执行&lt;/li&gt;
&lt;li&gt;解决死锁的一个方案是&lt;code&gt;破坏不可抢占条件&lt;/code&gt;synchronized 没有办法解决。原因是 synchronized 申请资源的时候，如果申请不到，线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程已经占有的资源。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;正是由于这些因素的限制，需要开发出一种满足如下条件的同步机制。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;**能够响应中断。**synchronized 的问题是，持有锁 A 后，如果尝试获取锁 B 失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会来唤醒阻塞的线程。但如果阻塞状态的线程能够响应中断信号，也就是说当我们给阻塞的线程发送中断信号的时候，能够唤醒它，那它就有机会释放曾经持有的锁 A。&lt;/li&gt;
&lt;li&gt;**支持超时。**如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。&lt;/li&gt;
&lt;li&gt;**非阻塞地获取锁。**如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。&lt;/li&gt;
&lt;/ol&gt;</summary>
    
    
    
    <category term="并发" scheme="https://gyl-coder.top/categories/%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="并发" scheme="https://gyl-coder.top/tags/%E5%B9%B6%E5%8F%91/"/>
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Why Concurrency ?</title>
    <link href="https://gyl-coder.top/concurrency/why_concurrency/"/>
    <id>https://gyl-coder.top/concurrency/why_concurrency/</id>
    <published>2019-11-04T16:00:00.000Z</published>
    <updated>2020-09-28T14:52:42.562Z</updated>
    
    <content type="html"><![CDATA[<p>一门技术的出现必然有其出现的道理，后来需要了解它出现的时代环境和因素，扩充自己的视野，发掘技术发展的经过。分析其优缺点，以便更好的运用。</p><p>一直以来，硬件的发展极其迅速，也有一个很著名的 <code>摩尔定律</code> ,然而事实证明摩尔定律的有效性超过半个世纪就失效了。为了进一步提升计算速度，放弃了一味追求单独的计算单元，将多个计算单元整合到一起，也就是形成了多核CPU。在多核CPU的环境下，并发编程的形式可以将多核CPU的计算能力发挥到极致，性能得到提升。</p><a id="more"></a><h2 id="并发带来的好处"><a class="header-anchor" href="#并发带来的好处">¶</a>并发带来的好处</h2><h3 id="性能上的提升"><a class="header-anchor" href="#性能上的提升">¶</a>性能上的提升</h3><p>提升多核CPU的利用率：一般来说一台主机上的会有多个CPU核心，我们可以创建多个线程，操作系统可以将多个线程分配给不同的CPU去执行，每个CPU执行一个线程，这样就提高了CPU的使用效率，如果使用单线程就只能有一个CPU核心被使用。</p><p>提升访问I/O时CPU的利用率：当一个线程要在网上下载一些东西的时候，这个线程将处于阻塞状态，这时CPU就不会再为这个线程分配CPU时间了，而其他进程可以不受任何影响地获得CPU时间。反过来如果没有使用并发，当前面的指令申请I/O资源的时候，整个进程就被挂起了，即使CPU处于空闲状态后面的指令也不能被执行。</p><p>降低系统的响应时间：当有多个请求需要被处理时。在单线程的环境中，所有请求需要排队进行处理。这样处在后面的请求将会等待较长的时间。多线程处理的话可以回避响应时间长的问题，所有请求轮流使用CPU资源，所有请求都可以较快的得到响应。</p><h3 id="提升系统容错能力"><a class="header-anchor" href="#提升系统容错能力">¶</a>提升系统容错能力</h3><p>一个线程可以不受其他线程的干扰独立运行，如果某个线程的代码里出现了Bug，这个线程可能抛出异常退出了，这时候其他线程可以不受任何影响继续执行，不至于导致整个系统都崩溃。</p><h2 id="并发的弊端"><a class="header-anchor" href="#并发的弊端">¶</a>并发的弊端</h2><h3 id="频繁的上下文切换"><a class="header-anchor" href="#频繁的上下文切换">¶</a>频繁的上下文切换</h3><p>时间片是CPU分配给各个线程的时间，因为时间非常短，所以CPU不断通过切换线程，让我们觉得多个线程是同时执行的，时间片一般是几十毫秒。而每次切换时，需要保存当前的状态起来，以便能够进行恢复先前状态，而这个切换时非常损耗性能，过于频繁反而无法发挥出多线程编程的优势。</p><p>通常减少上下文切换可以采用无锁并发编程，CAS算法，使用最少的线程和使用协程。</p><ul><li>无锁并发编程：可以参照concurrentHashMap锁分段的思想，不同的线程处理不同段的数据，这样在多线程竞争的条件下，可以减少上下文切换的时间。</li><li>CAS算法，利用Atomic下使用CAS算法来更新数据，使用了乐观锁，可以有效的减少一部分不必要的锁竞争带来的上下文切换</li><li>使用最少线程：避免创建不需要的线程，比如任务很少，但是创建了很多的线程，这样会造成大量的线程都处于等待状态</li><li>协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换</li></ul><h3 id="并发问题多易出错"><a class="header-anchor" href="#并发问题多易出错">¶</a>并发问题多易出错</h3><p>编写并发代码容易出错，多线程并发运行给执行过程带来了很多不确定性，因为只有同一个线程内部代码的执行顺序是固定的，而不同线程之间的代码执行顺序无法确定。当多个线程之间互相干扰时，问题就会接踵而至。编写多线程代码时，如果没有考虑全面很容易产生概率性的、难以复现的Bug</p><p>是否采用并发编程的模式，最终还是要结合自己的场景权衡利弊。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;一门技术的出现必然有其出现的道理，后来需要了解它出现的时代环境和因素，扩充自己的视野，发掘技术发展的经过。分析其优缺点，以便更好的运用。&lt;/p&gt;
&lt;p&gt;一直以来，硬件的发展极其迅速，也有一个很著名的 &lt;code&gt;摩尔定律&lt;/code&gt; ,然而事实证明摩尔定律的有效性超过半个世纪就失效了。为了进一步提升计算速度，放弃了一味追求单独的计算单元，将多个计算单元整合到一起，也就是形成了多核CPU。在多核CPU的环境下，并发编程的形式可以将多核CPU的计算能力发挥到极致，性能得到提升。&lt;/p&gt;</summary>
    
    
    
    <category term="并发" scheme="https://gyl-coder.top/categories/%E5%B9%B6%E5%8F%91/"/>
    
    
    <category term="并发" scheme="https://gyl-coder.top/tags/%E5%B9%B6%E5%8F%91/"/>
    
    <category term="Java" scheme="https://gyl-coder.top/tags/Java/"/>
    
    <category term="Concurrency" scheme="https://gyl-coder.top/tags/Concurrency/"/>
    
  </entry>
  
  <entry>
    <title>并发设计模式：Immutability 模式</title>
    <link href="https://gyl-coder.top/design-pattern/immutability/"/>
    <id>https://gyl-coder.top/design-pattern/immutability/</id>
    <published>2019-10-24T16:00:00.000Z</published>
    <updated>2020-09-28T14:52:18.257Z</updated>
    
    <content type="html"><![CDATA[<p>多个线程同时读写同一共享变量存在并发问题**，其中的必要条件之一就是 <code>读写</code> ，如果没有写，只存在读，是不会存在并发问题的。</p><p>如果让一个共享变量只有读操作，没有写操作，如此则可以解决并发问题。该理论的具体实现就是 <red>不变性（Immutability）模式</red> 。所谓<strong>不变性，简单来讲，就是对象一旦被创建之后，状态就不再发生变化</strong>。换句话说，就是变量一旦被赋值，就不允许修改了（没有写操作）；没有修改操作，也就是保持了不变性。</p><a id="more"></a><h2 id="实现具备不可变性的类"><a class="header-anchor" href="#实现具备不可变性的类">¶</a>实现具备不可变性的类</h2><p><strong>将一个类所有的属性都设置成 final 的，并且只允许存在只读方法，那么这个类基本上就具备不可变性了</strong>。更严格的做法是<strong>这个类本身也是 final 的</strong>，也就是不允许继承。因为子类可以覆盖父类的方法，有可能改变不可变性。</p><p>Java SDK 里很多类都具备不可变性，只是由于它们的使用太简单，最后反而被忽略了。例如经常用到的 String 和 Long、Integer、Double 等基础类型的包装类都具备不可变性，这些对象的线程安全性都是靠不可变性来保证的。如果你仔细翻看这些类的声明、属性和方法，你会发现它们都严格遵守不可变类的三点要求：<strong>类和属性都是 final 的，所有方法均是只读的</strong>。</p><p>看到这里你可能会疑惑，Java 的 String 方法也有类似字符替换操作，怎么能说所有方法都是只读的呢？下面通过 String 的源代码来看一哈。</p><p>下面的示例代码源自 Java 1.8 SDK。String 这个类以及它的属性 value[] 都是 final 的；而 replace() 方法的实现，就的确没有修改 value[]，而是将替换后的字符串作为返回值返回了。</p><pre><code class="language-java">public final class String &amp;#123;  private final char value[];  // 字符替换  String replace(char oldChar,       char newChar) &amp;#123;    // 无需替换，直接返回 this      if (oldChar == newChar)&amp;#123;      return this;    &amp;#125;    int len = value.length;    int i = -1;    /* avoid getfield opcode */    char[] val = value;     // 定位到需要替换的字符位置    while (++i &lt; len) &amp;#123;      if (val[i] == oldChar) &amp;#123;        break;      &amp;#125;    &amp;#125;    // 未找到 oldChar，无需替换    if (i &gt;= len) &amp;#123;      return this;    &amp;#125;     // 创建一个 buf[]，这是关键    // 用来保存替换后的字符串    char buf[] = new char[len];    for (int j = 0; j &lt; i; j++) &amp;#123;      buf[j] = val[j];    &amp;#125;    while (i &lt; len) &amp;#123;      char c = val[i];      buf[i] = (c == oldChar) ?         newChar : c;      i++;    &amp;#125;    // 创建一个新的字符串返回    // 原字符串不会发生任何变化    return new String(buf, true);  &amp;#125;&amp;#125;</code></pre><p>由上面的代码可以发现，String 是通过<strong>创建一个新的不可变对象</strong> 来实现 <strong>修改</strong> 的功能。如果 所有的修改操作都创建一个新的不可变对象，你可能会有这种担心：是不是创建的对象太多了，有点太浪费内存呢？是的，这样做的确有些浪费，那如何解决呢？</p><h2 id="利用享元模式避免创建重复对象"><a class="header-anchor" href="#利用享元模式避免创建重复对象">¶</a>利用享元模式避免创建重复对象</h2><p>利用享元模式可以减少创建对象的数量，从而减少内存占用。Java 语言里面 Long、Integer、Short、Byte 等这些基本数据类型的包装类都用到了享元模式。</p><p>下面以 Long 这个类作为例子，看看它是如何利用享元模式来优化对象的创建的。</p><p>享元模式本质上其实就是一个<green>对象池</green>，利用享元模式创建对象的逻辑也很简单：创建之前，首先去对象池里看看是不是存在；如果已经存在，就利用对象池里的对象；如果不存在，就会新创建一个对象，并且把这个新创建出来的对象放进对象池里。</p><p>Long 这个类并没有照搬享元模式，Long 内部维护了一个静态的对象池，仅缓存了 [-128,127] 之间的数字，这个对象池在 JVM 启动的时候就创建好了，而且这个对象池一直都不会变化，也就是说它是静态的。之所以采用这样的设计，是因为 Long 这个对象的状态共有 2 的 64 次方 种，实在太多，并不适合全部缓存，而 [-128,127] 之间的数字利用率最高。下面的示例代码出自 Java 1.8，valueOf() 方法就用到了 LongCache 这个缓存。</p><pre><code class="language-java">Long valueOf(long l) &amp;#123;  final int offset = 128;  // [-128,127] 直接的数字做了缓存  if (l &gt;= -128 &amp;&amp; l &lt;= 127) &amp;#123;     return LongCache      .cache[(int)l + offset];  &amp;#125;  return new Long(l);&amp;#125;// 缓存，等价于对象池// 仅缓存 [-128,127] 直接的数字static class LongCache &amp;#123;  static final Long cache[]     = new Long[-(-128) + 127 + 1];  static &amp;#123;    for(int i=0; i&lt;cache.length; i++)      cache[i] = new Long(i-128);  &amp;#125;&amp;#125;</code></pre><blockquote><p><red>注意</red>：** “Integer 和 String 类型的对象不适合做锁”，其实基本上所有的基础类型的包装类都不适合做锁，因为它们内部用到了享元模式，这会导致看上去私有的锁，其实是共有的。例如在下面代码中，本意是 A 用锁 al，B 用锁 bl，各自管理各自的，互不影响。但实际上 al 和 bl 是一个对象，结果 A 和 B 共用的是一把锁。</p></blockquote><pre><code class="language-java">class A &amp;#123;  Long al=Long.valueOf(1);  public void setAX()&amp;#123;    synchronized (al) &amp;#123;      // 省略代码无数    &amp;#125;  &amp;#125;&amp;#125;class B &amp;#123;  Long bl=Long.valueOf(1);  public void setBY()&amp;#123;    synchronized (bl) &amp;#123;      // 省略代码无数    &amp;#125;  &amp;#125;&amp;#125;</code></pre><h2 id="使用-Immutability-模式的注意事项"><a class="header-anchor" href="#使用-Immutability-模式的注意事项">¶</a>使用 Immutability 模式的注意事项</h2><p>在使用 Immutability 模式的时候，需要注意以下两点：</p><ol><li>对象的所有属性都是 final 的，并不能保证不可变性；</li><li>不可变对象也需要正确发布。</li></ol><p>在 Java 语言中，final 修饰的属性一旦被赋值，就不可以再修改，但是如果属性的类型是普通对象，那么这个普通对象的属性是可以被修改的。例如下面的代码中，Bar 的属性 foo 虽然是 final 的，依然可以通过 setAge() 方法来设置 foo 的属性 age。所以，<strong>在使用 Immutability 模式的时候一定要确认保持不变性的边界在哪里，是否要求属性对象也具备不可变性</strong>。</p><pre><code class="language-java">class Foo&amp;#123;  int age=0;  int ;&amp;#125;final class Bar &amp;#123;  final Foo foo;  void setAge(int a)&amp;#123;    foo.age=a;  &amp;#125;&amp;#125;</code></pre><p>下面我们再看看如何正确地发布不可变对象。不可变对象虽然是线程安全的，但是并不意味着引用这些不可变对象的对象就是线程安全的。例如在下面的代码中，Foo 具备不可变性，线程安全，但是类 Bar 并不是线程安全的，类 Bar 中持有对 Foo 的引用 foo，对 foo 这个引用的修改在多线程中并不能保证可见性和原子性。</p><pre><code class="language-java">//Foo 线程安全final class Foo&amp;#123;  final int age=0;  final int ;&amp;#125;//Bar 线程不安全class Bar &amp;#123;  Foo foo;  void setFoo(Foo f)&amp;#123;    this.foo=f;  &amp;#125;&amp;#125;</code></pre><p>如果你的程序仅仅需要 foo 保持可见性，无需保证原子性，那么可以将 foo 声明为 volatile 变量，这样就能保证可见性。如果你的程序需要保证原子性，那么可以通过原子类来实现。下面的示例代码是合理库存的原子化实现，你应该很熟悉了，其中就是用原子类解决了不可变对象引用的原子性问题。</p><pre><code class="language-java">public class SafeWM &amp;#123;  class WMRange&amp;#123;    final int upper;    final int lower;    WMRange(int upper,int lower)&amp;#123;    // 省略构造函数实现    &amp;#125;  &amp;#125;  final AtomicReference&lt;WMRange&gt;    rf = new AtomicReference&lt;&gt;(      new WMRange(0,0)    );  // 设置库存上限  void setUpper(int v)&amp;#123;    while(true)&amp;#123;      WMRange or = rf.get();      // 检查参数合法性      if(v &lt; or.lower)&amp;#123;        throw new IllegalArgumentException();      &amp;#125;      WMRange nr = new          WMRange(v, or.lower);      if(rf.compareAndSet(or, nr))&amp;#123;        return;      &amp;#125;    &amp;#125;  &amp;#125;&amp;#125;</code></pre><h2 id="总结"><a class="header-anchor" href="#总结">¶</a>总结</h2><p>具备不变性的对象，只有一种状态，这个状态由对象内部所有的不变属性共同决定。其实还有一种更简单的不变性对象，那就是<cyan>无状态</cyan>。无状态对象内部没有属性，只有方法。除了无状态的对象，你可能还听说过无状态的服务、无状态的协议等等。无状态有很多好处，最核心的一点就是性能。在多线程领域，无状态对象没有线程安全问题，无需同步处理，自然性能很好；在分布式领域，无状态意味着可以无限地水平扩展，所以分布式领域里面性能的瓶颈一定不是出在无状态的服务节点上。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;多个线程同时读写同一共享变量存在并发问题**，其中的必要条件之一就是 &lt;code&gt;读写&lt;/code&gt; ，如果没有写，只存在读，是不会存在并发问题的。&lt;/p&gt;
&lt;p&gt;如果让一个共享变量只有读操作，没有写操作，如此则可以解决并发问题。该理论的具体实现就是 &lt;red&gt;不变性（Immutability）模式&lt;/red&gt; 。所谓&lt;strong&gt;不变性，简单来讲，就是对象一旦被创建之后，状态就不再发生变化&lt;/strong&gt;。换句话说，就是变量一旦被赋值，就不允许修改了（没有写操作）；没有修改操作，也就是保持了不变性。&lt;/p&gt;</summary>
    
    
    
    <category term="设计模式" scheme="https://gyl-coder.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
    <category term="设计模式" scheme="https://gyl-coder.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    <category term="并发" scheme="https://gyl-coder.top/tags/%E5%B9%B6%E5%8F%91/"/>
    
    <category term="Immutability模式" scheme="https://gyl-coder.top/tags/Immutability%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>单例模式</title>
    <link href="https://gyl-coder.top/design-pattern/single-pattern/"/>
    <id>https://gyl-coder.top/design-pattern/single-pattern/</id>
    <published>2019-10-23T16:00:00.000Z</published>
    <updated>2020-09-28T14:53:18.522Z</updated>
    
    <content type="html"><![CDATA[<p>在介绍单例模式之前，我们先了解一下，什么是设计模式？<br>**设计模式（Design Pattern）：**是一套被反复使用，多数人知晓的，经过分类编目的，代码设计经验的总结。<br>**目的：**使用设计模式是为了可重用性代码，让代码更容易被他人理解，保证代码可靠性。</p><p>本文将会用到的关键词：</p><ul><li>单例：Singleton</li><li>实例：instance</li><li>同步：synchronized</li><li>类装载器：ClassLoader</li></ul><p><strong>单例模式：</strong><br>单例，顾名思义就是只能有一个、不能再出现第二个。就如同地球上没有两片一模一样的树叶一样。</p><p>在这里就是说：一个类只能有一个实例，并且整个项目系统都能访问该实例。</p><p>单例模式共分为两大类：</p><ul><li>懒汉模式：实例在第一次使用时创建</li><li>饿汉模式：实例在类装载时创建</li></ul><a id="more"></a><p><strong>单例模式UML图</strong></p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/design-pattern/5596129-7195be2372a2f898.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/gyl-coder/blogImgs/images/design-pattern/5596129-7195be2372a2f898.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h2 id="饿汉模式"><a class="header-anchor" href="#饿汉模式">¶</a>饿汉模式</h2><p>按照定义我们可以写出一个基本代码：</p><pre><code class="language-java">public class Singleton &amp;#123;// 使用private将构造方法私有化，以防外界通过该构造方法创建多个实例private Singleton() &amp;#123;&amp;#125;// 由于不能使用构造方法创建实例，所以需要在类的内部创建该类的唯一实例// 使用static修饰singleton 在外界可以通过类名调用该实例   类名.成员名static Singleton singleton = new Singleton();   // 1// 如果使用private封装该实例，则需要添加get方法实现对外界的开放private static Singleton instance = new Singleton();    // 2// 添加static，将该方法变成类所有   通过类名访问public static Singleton getInstance()&amp;#123;return instance;&amp;#125;//1和2选一种即可，推荐2&amp;#125;</code></pre><p>对于饿汉模式来说，这种写法已经很‘perfect’了，唯一的缺点就是，由于instance的初始化是在类加载时进行的，类加载是由ClassLoader来实现的，如果初始化太早，就会造成资源浪费。<br>当然，如果所需的单例占用的资源很少，并且也不依赖于其他数据，那么这种实现方式也是很好的。</p><h3 id="类装载的时机："><a class="header-anchor" href="#类装载的时机：">¶</a>类装载的时机：</h3><ul><li>new一个对象时</li><li>使用反射创建它的实例时</li><li>子类被加载时，如果父类还没有加载，就先加载父类</li><li>JVM启动时执行主类 会先被加载</li></ul><h2 id="懒汉模式"><a class="header-anchor" href="#懒汉模式">¶</a>懒汉模式</h2><p>懒汉模式的代码如下</p><pre><code class="language-java">// 代码一public class Singleton &amp;#123;    private static Singleton instance = null;    private Singleton()&amp;#123;    &amp;#125;    public static Singleton getInstance() &amp;#123;        if (instance == null) &amp;#123;            instance = new Singleton();         &amp;#125;                return instance;    &amp;#125;&amp;#125;</code></pre><p>每次获取instance之前先进行判断，如果instance为空就new一个出来，否则就直接返回已存在的instance。</p><p>这种写法在单线程的时候是没问题的。但是，当有多个线程一起工作的时候，如果有两个线程同时运行到  if (instance == null)，都判断为null（第一个线程判断为空之后，并没有继续向下执行，当第二个线程判断的时候instance依然为空），最终两个线程就各自会创建一个实例出来。这样就破环了单例模式 实例的唯一性</p><p>要想保证实例的唯一性就需要使用<strong>synchronized</strong>，加上一个同步锁</p><pre><code class="language-java">// 代码二public class Singleton &amp;#123;    private static Singleton instance = null;    private Singleton() &amp;#123;&amp;#125;    public static Singleton getInstance() &amp;#123;        synchronized(Singleton.class)&amp;#123;if (instance == null)instance = new Singleton();&amp;#125;return instance;    &amp;#125;&amp;#125;</code></pre><p>加上synchronized关键字之后，getInstance方法就会锁上了。如果有两个线程（T1、T2）同时执行到这个方法时，会有其中一个线程T1获得同步锁，得以继续执行，而另一个线程T2则需要等待，当第T1执行完毕getInstance之后（完成了null判断、对象创建、获得返回值之后），T2线程才会执行执行。</p><p>所以这段代码也就避免了<strong>代码一</strong>中，可能出现因为多线程导致多个实例的情况。但是，这种写法也有一个问题：给getInstance方法加锁，虽然避免了可能会出现的多个实例问题，但是会强制除T1之外的所有线程等待，实际上会对程序的执行效率造成负面影响。</p><h3 id="双重检查（Double-Check）"><a class="header-anchor" href="#双重检查（Double-Check）">¶</a>双重检查（Double-Check）</h3><p><strong>代码二</strong>相对于<strong>代码一</strong>的效率问题，其实是为了解决1%几率的问题，而使用了一个100%出现的防护盾。那有一个优化的思路，就是把100%出现的防护盾，也改为1%的几率出现，使之只出现在可能会导致多个实例出现的地方。<br>代码如下：</p><pre><code class="language-java">// 代码三public class Singleton &amp;#123;    private static Singleton instance = null;    private Singleton() &amp;#123;&amp;#125;    public static Singleton getInstance() &amp;#123;if (instance == null)&amp;#123;synchronized(Singleton.class)&amp;#123;if (instance == null)instance = new Singleton();&amp;#125;&amp;#125;return instance;    &amp;#125;&amp;#125;</code></pre><p>这段代码看起来有点复杂，注意其中有两次if(instance==null)的判断，这个叫做『双重检查 Double-Check』。</p><ul><li>第一个 if(instance==null)，其实是为了解决<strong>代码二</strong>中的效率问题，只有instance为null的时候，才进入synchronized的代码段大大减少了几率。</li><li>第二个if(instance==null)，则是跟<strong>代码二</strong>一样，是为了防止可能出现多个实例的情况。</li></ul><p>这段代码看起来已经完美无瑕了。当然，只是『看起来』，还是有小概率出现问题的。想要充分理解需要先弄清楚以下几个概念：原子操作、指令重排。</p><p><strong>原子操作</strong><br>简单来说，原子操作（atomic）就是不可分割的操作，在计算机中，就是指不会因为线程调度被打断的操作。比如，简单的赋值是一个原子操作：</p><pre><code class="language-java">m = 6; // 这是个原子操作</code></pre><p>假如m原先的值为0，那么对于这个操作，要么执行成功m变成了6，要么是没执行 m还是0，而不会出现诸如m=3这种中间态——即使是在并发的线程中。</p><p>但是，声明并赋值就不是一个原子操作：</p><pre><code class="language-java">int  n=6;//这不是一个原子操作</code></pre><p>对于这个语句，至少有两个操作：①声明一个变量n   ②给n赋值为6——这样就会有一个中间状态：变量n已经被声明了但是还没有被赋值的状态。这样，在多线程中，由于线程执行顺序的不确定性，如果两个线程都使用m，就可能会导致不稳定的结果出现。</p><p><strong>指令重排</strong><br>简单来说，就是计算机为了提高执行效率，会做的一些优化，在不影响最终结果的情况下，可能会对一些语句的执行顺序进行调整。比如，这一段代码：</p><pre><code class="language-java">int a ;   // 语句1 a = 8 ;   // 语句2int b = 9 ;     // 语句3int c = a + b ; // 语句4</code></pre><p>正常来说，对于顺序结构，执行的顺序是自上到下，也即1234。但是，由于指令重排<br>的原因，因为不影响最终的结果，所以，实际执行的顺序可能会变成3124或者1324。</p><p>由于语句3和4没有原子性的问题，语句3和语句4也可能会拆分成原子操作，再重排。——也就是说，对于非原子性的操作，在不影响最终结果的情况下，其拆分成的原子操作可能会被重新排列执行顺序。</p><p>OK，了解了原子操作和指令重排的概念之后，我们再继续看代码三的问题。</p><p>主要在于singleton = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。</p><p>1. 给 singleton 分配内存<br>　　2. 调用 Singleton 的构造函数来初始化成员变量，形成实例<br>　　3. 将singleton对象指向分配的内存空间（执行完这步 singleton才是非 null了）</p><p>在JVM的即时编译器中存在指令重排序的优化。<br>　　<br>也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后顺理成章地报错。<br>　　<br>再稍微解释一下，就是说，由于有一个『instance已经不为null但是仍没有完成初始化』的中间状态，而这个时候，如果有其他线程刚好运行到第一层if (instance ==null)这里，这里读取到的instance已经不为null了，所以就直接把这个中间状态的instance拿去用了，就会产生问题。这里的关键在于线程T1对instance的写操作没有完成，线程T2就执行了读操作。<br>　　<br><strong>对于代码三出现的问题，解决方案为：给instance的声明加上volatile关键字</strong><br>代码如下：</p><pre><code class="language-java">public class Singleton &amp;#123;    private static volatile Singleton instance = null;    private Singleton() &amp;#123;&amp;#125;    public static Singleton getInstance() &amp;#123;if (instance == null)&amp;#123;synchronized(Singleton.class)&amp;#123;if (instance == null)instance = new Singleton();&amp;#125;&amp;#125;return instance;    &amp;#125;&amp;#125;</code></pre><p><strong>volatile</strong>关键字的一个作用是禁止指令重排，把instance声明为volatile之后，对它的写操作就会有一个内存屏障，这样，在它的赋值完成之前，就不用会调用读操作。</p><p>注意：volatile阻止的不是singleton = new Singleton()这句话内部[1-2-3]的指令重排，而是保证了在一个写操作（[1-2-3]）完成之前，不会调用读操作（if (instance == null)）。</p><h2 id="其它方法"><a class="header-anchor" href="#其它方法">¶</a>其它方法</h2><h3 id="静态内部类"><a class="header-anchor" href="#静态内部类">¶</a>静态内部类</h3><pre><code class="language-java">public class Singleton &amp;#123;   private static class SingletonHolder &amp;#123;       private static final Singleton INSTANCE = new Singleton();   &amp;#125;   private Singleton ()&amp;#123;&amp;#125;   public static final Singleton getInstance() &amp;#123;       return SingletonHolder.INSTANCE;   &amp;#125;&amp;#125;</code></pre><p>这种写法的巧妙之处在于：对于内部类SingletonHolder，它是一个饿汉式的单例实现，在SingletonHolder初始化的时候会由ClassLoader来保证同步，使INSTANCE是一个真单例。</p><p>同时，由于SingletonHolder是一个内部类，只在外部类的Singleton的getInstance()中被使用，所以它被加载的时机也就是在getInstance()方法第一次被调用的时候。<br>　　<br>它利用了ClassLoader来保证了同步，同时又能让开发者控制类加载的时机。从内部看是一个饿汉式的单例，但是从外部看来，又的确是懒汉式的实现</p><h3 id="枚举"><a class="header-anchor" href="#枚举">¶</a>枚举</h3><pre><code class="language-java">public enum SingleInstance &amp;#123;  INSTANCE;   public void fun1() &amp;#123;       // do something   &amp;#125;&amp;#125;// 使用SingleInstance.INSTANCE.fun1();</code></pre><p>是不是很简单？而且因为自动序列化机制，保证了线程的绝对安全。三个词概括该方式：简单、高效、安全</p><p>这种写法在功能上与共有域方法相近，但是它更简洁，无偿地提供了序列化机制，绝对防止对此实例化，即使是在面对复杂的序列化或者反射攻击的时候。虽然这中方法还没有广泛采用，但是单元素的枚举类型已经成为实现Singleton的最佳方法。</p><div class="tag link"><a class="link-card" title="视频讲解" href="https://pan.baidu.com/s/1pWotEu9Z883hqWUM_Xu7vQ"><div class="left"><img src="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png" class="lazyload placeholder" data-srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div><div class="right"><p class="text">视频讲解</p><p class="url">https://pan.baidu.com/s/1pWotEu9Z883hqWUM_Xu7vQ</p></div></a></div><p>密码： <psw>lt0t</psw></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在介绍单例模式之前，我们先了解一下，什么是设计模式？&lt;br&gt;
**设计模式（Design Pattern）：**是一套被反复使用，多数人知晓的，经过分类编目的，代码设计经验的总结。&lt;br&gt;
**目的：**使用设计模式是为了可重用性代码，让代码更容易被他人理解，保证代码可靠性。&lt;/p&gt;
&lt;p&gt;本文将会用到的关键词：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单例：Singleton&lt;/li&gt;
&lt;li&gt;实例：instance&lt;/li&gt;
&lt;li&gt;同步：synchronized&lt;/li&gt;
&lt;li&gt;类装载器：ClassLoader&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;单例模式：&lt;/strong&gt;&lt;br&gt;
单例，顾名思义就是只能有一个、不能再出现第二个。就如同地球上没有两片一模一样的树叶一样。&lt;/p&gt;
&lt;p&gt;在这里就是说：一个类只能有一个实例，并且整个项目系统都能访问该实例。&lt;/p&gt;
&lt;p&gt;单例模式共分为两大类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;懒汉模式：实例在第一次使用时创建&lt;/li&gt;
&lt;li&gt;饿汉模式：实例在类装载时创建&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="设计模式" scheme="https://gyl-coder.top/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
    <category term="设计模式" scheme="https://gyl-coder.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    <category term="单例模式" scheme="https://gyl-coder.top/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>撸一个JSON解析器</title>
    <link href="https://gyl-coder.top/JSONParser/"/>
    <id>https://gyl-coder.top/JSONParser/</id>
    <published>2019-10-23T16:00:00.000Z</published>
    <updated>2020-09-28T14:22:26.801Z</updated>
    
    <content type="html"><![CDATA[<p>JSON(JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式。易于人阅读和编写。同时也易于机器解析和生成。采用完全独立于语言的文本格式，但是也使用了类似于 C 语言家族的习惯（包括 C, C++, C#, Java, JavaScript, Perl, Python 等）。这些特性使 JSON 成为理想的数据交换语言。</p><p>JSON 与 JS 的区别以及和 XML 的区别具体请参考<a href="https://baike.baidu.com/item/JSON/2462549?fr=aladdin">百度百科</a></p><a id="more"></a><p><strong>JSON 有两种结构：</strong></p><p>第一种：对象</p><blockquote><p>“名称 / 值” 对的集合不同的语言中，它被理解为对象（object），纪录（record），结构（struct），字典（dictionary），哈希表（hash table），有键列表（keyed list），或者关联数组 （associative array）。</p><p>对象是一个无序的 “‘名称 / 值’对” 集合。一个对象以 “{”（左括号）开始，“}”（右括号）结束。每个“名称” 后跟一个 “:”（冒号）；“‘名称 / 值’ 对” 之间使用“,”（逗号）分隔。</p></blockquote><pre><code>&amp;#123;&quot;姓名&quot;: &quot;张三&quot;, &quot;年龄&quot;: &quot;18&quot;&amp;#125;</code></pre><p>第二种：数组</p><blockquote><p>值的有序列表（An ordered list of values）。在大部分语言中，它被理解为数组（array）。</p><p>数组是值（value）的有序集合。一个数组以 “[”（左中括号）开始，“]”（右中括号）结束。值之间使用 “,”（逗号）分隔。</p><p>值（value）可以是双引号括起来的字符串（string）、数值 (number)、true、false、 null、对象（object）或者数组（array）。这些结构可以嵌套。</p></blockquote><pre><code>[    &amp;#123;     &quot;姓名&quot;: &quot;张三&quot;,                 &quot;年龄&quot;:&quot;18&quot;         &amp;#125;,                 &amp;#123;             &quot;姓名&quot;: &quot;里斯&quot;,                 &quot;年龄&quot;:&quot;19&quot;        &amp;#125;]</code></pre><p>通过上面的了解可以看出，JSON 存在以下几种数据类型（以 Java 做类比）：</p><table><thead><tr><th style="text-align:center">json</th><th style="text-align:center">java</th></tr></thead><tbody><tr><td style="text-align:center">string</td><td style="text-align:center">Java 中的 String</td></tr><tr><td style="text-align:center">number</td><td style="text-align:center">Java 中的 Long 或 Double</td></tr><tr><td style="text-align:center">true/false</td><td style="text-align:center">Java 中的 Boolean</td></tr><tr><td style="text-align:center">null</td><td style="text-align:center">Java 中的 null</td></tr><tr><td style="text-align:center">[array]</td><td style="text-align:center">Java 中的 List<Object> 或 Object[]</td></tr><tr><td style="text-align:center">{“key”:“value”}</td><td style="text-align:center">Java 中的 Map&lt;String, Object&gt;</td></tr></tbody></table><h2 id="解析-JSON"><a class="header-anchor" href="#解析-JSON">¶</a>解析 JSON</h2><h3 id="JSON-解析器的基本原理"><a class="header-anchor" href="#JSON-解析器的基本原理">¶</a>JSON 解析器的基本原理</h3><p>输入一串 JSON 字符串，输出一个 JSON 对象。</p><h3 id="步骤"><a class="header-anchor" href="#步骤">¶</a>步骤</h3><p>JSON 解析的过程主要分以下两步：</p><p>**第一步：**对于输入的一串 JSON 字符串我们需要将其解析成一组 token 流。</p><p>例如 JSON 字符串 {“姓名”: “张三”, “年龄”: “18”} 我们需要将它解析成</p><pre><code>&amp;#123;、 姓名、 :、 张三、 ,、 年龄、 :、 18、 &amp;#125;</code></pre><p>这样一组 token 流</p><p>**第二步：**根据得到的 token 流将其解析成对应的 JSON 对象（JSONObject）或者 JSON 数组（JSONArray）</p><p>下面我们来详细分析下这两个步骤：</p><h2 id="获取-token-流"><a class="header-anchor" href="#获取-token-流">¶</a>获取 token 流</h2><p>根据 JSON 格式的定义，token 可以分为以下几种类型</p><table><thead><tr><th style="text-align:center">token</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">NULL</td><td style="text-align:center">null</td></tr><tr><td style="text-align:center">NUMBER</td><td style="text-align:center">数字</td></tr><tr><td style="text-align:center">STRING</td><td style="text-align:center">字符串</td></tr><tr><td style="text-align:center">BOOLEAN</td><td style="text-align:center">true/false</td></tr><tr><td style="text-align:center">SEP_COLON</td><td style="text-align:center">:</td></tr><tr><td style="text-align:center">SEP_COMMA</td><td style="text-align:center">,</td></tr><tr><td style="text-align:center">BEGIN_OBJECT</td><td style="text-align:center">{</td></tr><tr><td style="text-align:center">END_OBJECT</td><td style="text-align:center">}</td></tr><tr><td style="text-align:center">BEGIN_ARRAY</td><td style="text-align:center">[</td></tr><tr><td style="text-align:center">END_ARRAY</td><td style="text-align:center">]</td></tr><tr><td style="text-align:center">END_DOCUMENT</td><td style="text-align:center">表示 JSON 数据结束</td></tr></tbody></table><p>根据以上的 JSON 类型，我们可以将其封装成 enum 类型的 <a href="https://github.com/gyl-coder/JSON-Parser/blob/master/src/main/java/com/json/demo/tokenizer/TokenType.java">TokenType</a></p><pre><code>package com.json.demo.tokenizer;/** BEGIN_OBJECT（&amp;#123;） END_OBJECT（&amp;#125;） BEGIN_ARRAY（[） END_ARRAY（]） NULL（null） NUMBER（数字） STRING（字符串） BOOLEAN（true/false） SEP_COLON（:） SEP_COMMA（,） END_DOCUMENT（表示JSON文档结束） */public enum TokenType &amp;#123;    BEGIN_OBJECT(1),    END_OBJECT(2),    BEGIN_ARRAY(4),    END_ARRAY(8),    NULL(16),    NUMBER(32),    STRING(64),    BOOLEAN(128),    SEP_COLON(256),    SEP_COMMA(512),    END_DOCUMENT(1024);    private int code;    // 每个类型的编号    TokenType(int code) &amp;#123;        this.code = code;    &amp;#125;    public int getTokenCode() &amp;#123;        return code;    &amp;#125;&amp;#125;</code></pre><p>在 TokenType 中我们为每一种类型都赋一个数字，目的是在 Parser 做一些优化操作（通过位运算来判断是否是期望出现的类型）</p><p>在进行第一步之前 JSON 串对计算机来说只是一串没有意义的字符而已。第一步的作用就是把这些无意义的字符串变成一个一个的 token，上面我们已经为每一种 token 定义了相应的类型和值。所以计算机能够区分不同的 token，并能以 token 为单位解读 JSON 数据。</p><p>下面我们封装一个 <a href="https://github.com/gyl-coder/JSON-Parser/blob/master/src/main/java/com/json/demo/tokenizer/Token.java">token</a> 类来存储每一个 <a href="https://github.com/gyl-coder/JSON-Parser/blob/master/src/main/java/com/json/demo/tokenizer/Token.java">token</a> 对应的值</p><pre><code>package com.json.demo.tokenizer;/** * 存储对应类型的字面量 */public class Token &amp;#123;    private TokenType tokenType;    private String value;    public Token(TokenType tokenType, String value) &amp;#123;        this.tokenType = tokenType;        this.value = value;    &amp;#125;    public TokenType getTokenType() &amp;#123;        return tokenType;    &amp;#125;    public void setTokenType(TokenType tokenType) &amp;#123;        this.tokenType = tokenType;    &amp;#125;    public String getValue() &amp;#123;        return value;    &amp;#125;    public void setValue(String value) &amp;#123;        this.value = value;    &amp;#125;    @Override    public String toString() &amp;#123;        return &quot;Token&amp;#123;&quot; +                &quot;tokenType=&quot; + tokenType +                &quot;, value='&quot; + value + '\'' +                '&amp;#125;';    &amp;#125;&amp;#125;</code></pre><p>在解析的过程中我们通过字符流来不断的读取字符，并且需要经常根据相应的字符来判断状态的跳转。所以我们需要自己封装一个 <a href="https://github.com/gyl-coder/JSON-Parser/blob/master/src/main/java/com/json/demo/tokenizer/ReaderChar.java">ReaderChar</a> 类，以便我们更好的操作字符流。</p><pre><code>package com.json.demo.tokenizer;import java.io.IOException;import java.io.Reader;public class ReaderChar &amp;#123;    private static final int BUFFER_SIZE = 1024;    private Reader reader;    private char[] buffer;    private int index;      // 下标    private int size;    public ReaderChar(Reader reader) &amp;#123;        this.reader = reader;        buffer = new char[BUFFER_SIZE];    &amp;#125;    /**     * 返回 pos 下标处的字符，并返回     * @return     */    public char peek() &amp;#123;        if (index - 1 &gt;= size) &amp;#123;            return (char) -1;        &amp;#125;        return buffer[Math.max(0, index - 1)];    &amp;#125;    /**     * 返回 pos 下标处的字符，并将 pos + 1，最后返回字符     * @return     * @throws IOException     */    public char next() throws IOException &amp;#123;        if (!hasMore()) &amp;#123;            return (char) -1;        &amp;#125;        return buffer[index++];    &amp;#125;    /**     * 下标回退     */    public void back() &amp;#123;        index = Math.max(0, --index);    &amp;#125;    /**     * 判断流是否结束     */    public boolean hasMore() throws IOException &amp;#123;        if (index &lt; size) &amp;#123;            return true;        &amp;#125;        fillBuffer();        return index &lt; size;    &amp;#125;    /**     * 填充buffer数组     * @throws IOException     */    void fillBuffer() throws IOException &amp;#123;        int n = reader.read(buffer);        if (n == -1) &amp;#123;            return;        &amp;#125;        index = 0;        size = n;    &amp;#125;&amp;#125;</code></pre><p>另外我们还需要一个 <a href="https://github.com/gyl-coder/JSON-Parser/blob/master/src/main/java/com/json/demo/tokenizer/TokenList.java">TokenList</a> 来存储解析出来的 token 流</p><pre><code>package com.json.demo.tokenizer;import java.util.ArrayList;import java.util.List;/** * 存储词法解析所得的token流 */public class TokenList &amp;#123;    private List&lt;Token&gt; tokens = new ArrayList&lt;Token&gt;();    private int index = 0;    public void add(Token token) &amp;#123;        tokens.add(token);    &amp;#125;    public Token peek() &amp;#123;        return index &lt; tokens.size() ? tokens.get(index) : null;    &amp;#125;    public Token peekPrevious() &amp;#123;        return index - 1 &lt; 0 ? null : tokens.get(index - 2);    &amp;#125;    public Token next() &amp;#123;        return tokens.get(index++);    &amp;#125;    public boolean hasMore() &amp;#123;        return index &lt; tokens.size();    &amp;#125;    @Override    public String toString() &amp;#123;        return &quot;TokenList&amp;#123;&quot; +                &quot;tokens=&quot; + tokens +                '&amp;#125;';    &amp;#125;&amp;#125;</code></pre><p>JSON 解析比其他文本解析要简单的地方在于，我们只需要根据下一个字符就可知道接下来它所期望读取的到的内容是什么样的。如果满足期望了，则返回 Token，否则返回错误。</p><p>为了方便程序出错时更好的 debug，程序中自定义了两个 exception 类来处理错误信息。（具体实现参考 <a href="https://github.com/gyl-coder/JSON-Parser/tree/master/src/main/java/com/json/demo/exception">exception</a> 包）</p><p>下面就是第一步中的重头戏（核心代码）：</p><pre><code>public TokenList getTokenStream(ReaderChar readerChar) throws IOException &amp;#123;        this.readerChar = readerChar;        tokenList = new TokenList();        // 词法解析，获取token流        tokenizer();        return tokenList;    &amp;#125;    /**     * 将JSON文件解析成token流     * @throws IOException     */    private void tokenizer() throws IOException &amp;#123;        Token token;        do &amp;#123;            token = start();            tokenList.add(token);        &amp;#125; while (token.getTokenType() != TokenType.END_DOCUMENT);    &amp;#125;    /**     * 解析过程的具体实现方法     * @return     * @throws IOException     * @throws JsonParseException     */    private Token start() throws IOException, JsonParseException &amp;#123;        char ch;        while (true)&amp;#123;   //先读一个字符，若为空白符（ASCII码在[0, 20H]上）则接着读，直到刚读的字符非空白符            if (!readerChar.hasMore()) &amp;#123;                return new Token(TokenType.END_DOCUMENT, null);            &amp;#125;            ch = readerChar.next();            if (!isWhiteSpace(ch)) &amp;#123;                break;            &amp;#125;        &amp;#125;        switch (ch) &amp;#123;            case '&amp;#123;':                return new Token(TokenType.BEGIN_OBJECT, String.valueOf(ch));            case '&amp;#125;':                return new Token(TokenType.END_OBJECT, String.valueOf(ch));            case '[':                return new Token(TokenType.BEGIN_ARRAY, String.valueOf(ch));            case ']':                return new Token(TokenType.END_ARRAY, String.valueOf(ch));            case ',':                return new Token(TokenType.SEP_COMMA, String.valueOf(ch));            case ':':                return new Token(TokenType.SEP_COLON, String.valueOf(ch));            case 'n':                return readNull();            case 't':            case 'f':                return readBoolean();            case '&quot;':                return readString();            case '-':                return readNumber();        &amp;#125;        if (isDigit(ch)) &amp;#123;            return readNumber();        &amp;#125;        throw new JsonParseException(&quot;Illegal character&quot;);    &amp;#125;</code></pre><p>在 <a href="https://github.com/gyl-coder/JSON-Parser/blob/master/src/main/java/com/json/demo/tokenizer/Tokenizer.java">start</a> 方法中，我们将每个处理方法都封装成了单独的函数。<strong>主要思想</strong>就是通过一个死循环不停的读取字符，然后再根据字符的期待值，执行不同的处理函数。</p><p>下面我们详解分析几个处理函数：</p><pre><code>private Token readString() throws IOException &amp;#123;        StringBuilder sb = new StringBuilder();        while(true) &amp;#123;            char ch = readerChar.next();            if (ch == '\\') &amp;#123;   // 处理转义字符                if (!isEscape()) &amp;#123;                    throw new JsonParseException(&quot;Invalid escape character&quot;);                &amp;#125;                sb.append('\\');                ch = readerChar.peek();                sb.append(ch);                if (ch == 'u') &amp;#123;   // 处理 Unicode 编码，形如 \u4e2d。且只支持 \u0000 ~ \uFFFF 范围内的编码                    for (int i = 0; i &lt; 4; i++) &amp;#123;                        ch = readerChar.next();                        if (isHex(ch)) &amp;#123;                            sb.append(ch);                        &amp;#125; else &amp;#123;                            throw new JsonParseException(&quot;Invalid character&quot;);                        &amp;#125;                    &amp;#125;                &amp;#125;            &amp;#125; else if (ch == '&quot;') &amp;#123;     // 碰到另一个双引号，则认为字符串解析结束，返回 Token                return new Token(TokenType.STRING, sb.toString());            &amp;#125; else if (ch == '\r' || ch == '\n') &amp;#123;     // 传入的 JSON 字符串不允许换行                throw new JsonParseException(&quot;Invalid character&quot;);            &amp;#125; else &amp;#123;                sb.append(ch);            &amp;#125;        &amp;#125;    &amp;#125;</code></pre><p>该方法也是通过一个死循环来读取字符，首先判断的是 JSON 中的转义字符。</p><p>JSON 中允许出现的有以下几种</p><pre><code>\&quot;\\\b\f\n\r\t\u four-hex-digits\/</code></pre><p>具体的处理方法封装在了 isEscape() 方法中，处理 Unicode 编码时要特别注意一下 u 的后面会出现四位十六进制数。当读取到一个双引号或者读取到了非法字符（'r’或’、‘n’）循环退出。</p><p>判断数字的时候也要特别小心，注意负数，frac，exp 等等情况。</p><p>通过上面的解析，我们可以得到一组 token，接下来我们需要以这组 token 作为输入，解析出相应的 JSON 对象</p><h2 id="解析出-JSON-对象"><a class="header-anchor" href="#解析出-JSON-对象">¶</a>解析出 JSON 对象</h2><p>解析之前我们需要定义出 JSON 对象（JSONObject）和 JSON 数组 (JSONArray) 的实体类。</p><pre><code>package com.json.demo.jsonstyle;import com.json.demo.exception.JsonTypeException;import com.json.demo.util.FormatUtil;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;/** * JSON的对象形式 * 对象是一个无序的“‘名称/值’对”集合。一个对象以“&amp;#123;”（左括号）开始，“&amp;#125;”（右括号）结束。每个“名称”后跟一个“:”（冒号）；“‘名称/值’ 对”之间使用“,”（逗号）分隔。 */public class JsonObject &amp;#123;    private Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();    public void put(String key, Object value) &amp;#123;        map.put(key, value);    &amp;#125;    public Object get(String key) &amp;#123;        return map.get(key);    &amp;#125;    ...    &amp;#125;package com.json.demo.jsonstyle;import com.json.demo.exception.JsonTypeException;import com.json.demo.util.FormatUtil;import java.util.ArrayList;import java.util.Iterator;import java.util.List;/** * JSON的数组形式 * 数组是值（value）的有序集合。一个数组以“[”（左中括号）开始，“]”（右中括号）结束。值之间使用“,”（逗号）分隔。 */public class JsonArray &amp;#123;    private List list = new ArrayList();    public void add(Object obj) &amp;#123;        list.add(obj);    &amp;#125;    public Object get(int index) &amp;#123;        return list.get(index);    &amp;#125;    public int size() &amp;#123;        return list.size();    &amp;#125;    ...&amp;#125;</code></pre><p>之后我们就可以写解析类了，由于代码较长，这里就不展示了。有兴趣的可以去 GitHub 上下载。实现逻辑比较简单，也易于理解。</p><p>解析类中的 parse 方法首先根据第一个 token 的类型选择调用 parseJsonObject（）或者 parseJsonArray（），进而返回 JSON 对象或者 JSON 数组。上面的解析方法中利用位运算来判断字符的期待值既提高了程序的执行效率也有助于提高代码的 ke’du’xi</p><p>完成之后我们可以写一个测试类来验证下我们的解析器的运行情况。我们可以自己定义一组 JSON 串也可以通过 HttpUtil 工具类从网上获取。最后通过 FormatUtil 类来规范我们输出。</p><p>具体效果如下图所示：</p><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://segmentfault.com/img/remote/1460000015430807?w=872&h=859" class="lazyload placeholder" data-srcset="https://segmentfault.com/img/remote/1460000015430807?w=872&h=859" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><div class="img-wrap"><div class="img-bg"><img class="img lazyload placeholder" src="https://segmentfault.com/img/remote/1460000015430808" class="lazyload placeholder" data-srcset="https://segmentfault.com/img/remote/1460000015430808" srcset="https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@3/img/placeholder/c617bfd2497fcea598e621413e315c368f8d8e.svg"/></div></div><h2 id="参考文章"><a class="header-anchor" href="#参考文章">¶</a>参考文章</h2><ul><li><a href="http://www.cnblogs.com/absfree/p/5502705.html">http://www.cnblogs.com/absfre…</a></li><li><a href="https://www.liaoxuefeng.com/article/0014211269349633dda29ee3f29413c91fa65c372585f23000?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io">https://www.liaoxuefeng.com/a…</a></li><li><a href="https://segmentfault.com/a/1190000010998941#articleHeader6">https://segmentfault.com/a/11…</a></li><li><a href="http://json.org/json-zh.html">http://json.org/json-zh.html</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;JSON(JavaScript Object Notation, JS 对象简谱) 是一种轻量级的数据交换格式。易于人阅读和编写。同时也易于机器解析和生成。采用完全独立于语言的文本格式，但是也使用了类似于 C 语言家族的习惯（包括 C, C++, C#, Java, JavaScript, Perl, Python 等）。这些特性使 JSON 成为理想的数据交换语言。&lt;/p&gt;
&lt;p&gt;JSON 与 JS 的区别以及和 XML 的区别具体请参考&lt;a href=&quot;https://baike.baidu.com/item/JSON/2462549?fr=aladdin&quot;&gt;百度百科&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Java" scheme="https://gyl-coder.top/categories/Java/"/>
    
    
    <category term="json" scheme="https://gyl-coder.top/tags/json/"/>
    
    <category term="json 解析器" scheme="https://gyl-coder.top/tags/json-%E8%A7%A3%E6%9E%90%E5%99%A8/"/>
    
  </entry>
  
</feed>
